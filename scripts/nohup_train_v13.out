nohup: ignoring input
Starting from scratch
Epoch 1 of 2000
Found 300 cases for training
   Iteration 1 of 100, loss = 0.024611137807369232   Iteration 2 of 100, loss = 0.035083383321762085   Iteration 3 of 100, loss = 0.03676193952560425   Iteration 4 of 100, loss = 0.03787430841475725   Iteration 5 of 100, loss = 0.03781872391700745   Iteration 6 of 100, loss = 0.037538373842835426   Iteration 7 of 100, loss = 0.03540566324123314   Iteration 8 of 100, loss = 0.03542733541689813   Iteration 9 of 100, loss = 0.035566739531026945   Iteration 10 of 100, loss = 0.0340650649741292   Iteration 11 of 100, loss = 0.03304005719043992   Iteration 12 of 100, loss = 0.032478247148295246   Iteration 13 of 100, loss = 0.03151239569370563   Iteration 14 of 100, loss = 0.031191235142094747   Iteration 15 of 100, loss = 0.0306324885537227   Iteration 16 of 100, loss = 0.029727222048677504   Iteration 17 of 100, loss = 0.029150281649302032   Iteration 18 of 100, loss = 0.02854607119742367   Iteration 19 of 100, loss = 0.027963488705848392   Iteration 20 of 100, loss = 0.027759658358991145   Iteration 21 of 100, loss = 0.027145144130502428   Iteration 22 of 100, loss = 0.027169222096827896   Iteration 23 of 100, loss = 0.02698952048693014   Iteration 24 of 100, loss = 0.026577675171817344   Iteration 25 of 100, loss = 0.026625618413090704   Iteration 26 of 100, loss = 0.02622430040859259   Iteration 27 of 100, loss = 0.02619789375199212   Iteration 28 of 100, loss = 0.025665946836982454   Iteration 29 of 100, loss = 0.025383597882143383   Iteration 30 of 100, loss = 0.024995456573863824   Iteration 31 of 100, loss = 0.024833274344282764   Iteration 32 of 100, loss = 0.02448043113690801   Iteration 33 of 100, loss = 0.024477965480676205   Iteration 34 of 100, loss = 0.024415976121364272   Iteration 35 of 100, loss = 0.024388512835970946   Iteration 36 of 100, loss = 0.024231175245303247   Iteration 37 of 100, loss = 0.0239099769324467   Iteration 38 of 100, loss = 0.02392873935107338   Iteration 39 of 100, loss = 0.023767584767670203   Iteration 40 of 100, loss = 0.023423078935593367   Iteration 41 of 100, loss = 0.02328675794528752   Iteration 42 of 100, loss = 0.02314207951227824   Iteration 43 of 100, loss = 0.02299900643180969   Iteration 44 of 100, loss = 0.02281272534111684   Iteration 45 of 100, loss = 0.022645749958852927   Iteration 46 of 100, loss = 0.02260011408235068   Iteration 47 of 100, loss = 0.022451587734704324   Iteration 48 of 100, loss = 0.02257152887371679   Iteration 49 of 100, loss = 0.022523094310748334   Iteration 50 of 100, loss = 0.022413593903183936   Iteration 51 of 100, loss = 0.022121571862668384   Iteration 52 of 100, loss = 0.022190549142228868   Iteration 53 of 100, loss = 0.022204365669134654   Iteration 54 of 100, loss = 0.02197849436628598   Iteration 55 of 100, loss = 0.021815453435886988   Iteration 56 of 100, loss = 0.021806239350033656   Iteration 57 of 100, loss = 0.02165526877108373   Iteration 58 of 100, loss = 0.021482564733716947   Iteration 59 of 100, loss = 0.021240106515460096   Iteration 60 of 100, loss = 0.021265517051021258   Iteration 61 of 100, loss = 0.02111638148055702   Iteration 62 of 100, loss = 0.020914281523155588   Iteration 63 of 100, loss = 0.020761176441160458   Iteration 64 of 100, loss = 0.02071460839943029   Iteration 65 of 100, loss = 0.020609865337610243   Iteration 66 of 100, loss = 0.020491776225919075   Iteration 67 of 100, loss = 0.020578486650292552   Iteration 68 of 100, loss = 0.02038725545657251   Iteration 69 of 100, loss = 0.020382807448344385   Iteration 70 of 100, loss = 0.020357670881120223   Iteration 71 of 100, loss = 0.02017339305217627   Iteration 72 of 100, loss = 0.02003484557563853   Iteration 73 of 100, loss = 0.020031009602985563   Iteration 74 of 100, loss = 0.020030656495962192   Iteration 75 of 100, loss = 0.019913822083423537   Iteration 76 of 100, loss = 0.01989012779545431   Iteration 77 of 100, loss = 0.019933067691548692   Iteration 78 of 100, loss = 0.019879930049706347   Iteration 79 of 100, loss = 0.019849379670723706   Iteration 80 of 100, loss = 0.019781245285412297   Iteration 81 of 100, loss = 0.019758194403285967   Iteration 82 of 100, loss = 0.019619411272110372   Iteration 83 of 100, loss = 0.0194770888964006   Iteration 84 of 100, loss = 0.01944791888707273   Iteration 85 of 100, loss = 0.019376449084238096   Iteration 86 of 100, loss = 0.01924768216409829   Iteration 87 of 100, loss = 0.019193005314546412   Iteration 88 of 100, loss = 0.01910121192287823   Iteration 89 of 100, loss = 0.019088187888055372   Iteration 90 of 100, loss = 0.019085286531804337   Iteration 91 of 100, loss = 0.019073096170489277   Iteration 92 of 100, loss = 0.018986901141824605   Iteration 93 of 100, loss = 0.018908041033653483   Iteration 94 of 100, loss = 0.018921970781137016   Iteration 95 of 100, loss = 0.018945222382286662   Iteration 96 of 100, loss = 0.018908731489015434   Iteration 97 of 100, loss = 0.01895637050290237   Iteration 98 of 100, loss = 0.018936550610565712   Iteration 99 of 100, loss = 0.018947482471250825   Iteration 100 of 100, loss = 0.018851099875755607
   End of epoch 1; saving model... 

Epoch 2 of 2000
   Iteration 1 of 100, loss = 0.009890585206449032   Iteration 2 of 100, loss = 0.009033911395817995   Iteration 3 of 100, loss = 0.008737790087858835   Iteration 4 of 100, loss = 0.008592596277594566   Iteration 5 of 100, loss = 0.007864161673933268   Iteration 6 of 100, loss = 0.009034041392927369   Iteration 7 of 100, loss = 0.010566937670643841   Iteration 8 of 100, loss = 0.011413737491238862   Iteration 9 of 100, loss = 0.01114484735040201   Iteration 10 of 100, loss = 0.011185722192749381   Iteration 11 of 100, loss = 0.010752941312437708   Iteration 12 of 100, loss = 0.010309124171423415   Iteration 13 of 100, loss = 0.010336545976595236   Iteration 14 of 100, loss = 0.010620429879054427   Iteration 15 of 100, loss = 0.0106516622317334   Iteration 16 of 100, loss = 0.01047414739150554   Iteration 17 of 100, loss = 0.010346692384165876   Iteration 18 of 100, loss = 0.010473370034661558   Iteration 19 of 100, loss = 0.010388364035047983   Iteration 20 of 100, loss = 0.010252036107704043   Iteration 21 of 100, loss = 0.010751421119840373   Iteration 22 of 100, loss = 0.010793066498908129   Iteration 23 of 100, loss = 0.010941478869189386   Iteration 24 of 100, loss = 0.010737623631333312   Iteration 25 of 100, loss = 0.011084843128919601   Iteration 26 of 100, loss = 0.011121880907851916   Iteration 27 of 100, loss = 0.011461073670674253   Iteration 28 of 100, loss = 0.011466535440246974   Iteration 29 of 100, loss = 0.011664898327455438   Iteration 30 of 100, loss = 0.011751621185491482   Iteration 31 of 100, loss = 0.011949461223858019   Iteration 32 of 100, loss = 0.012125827342970297   Iteration 33 of 100, loss = 0.012255674820731987   Iteration 34 of 100, loss = 0.012345771935275373   Iteration 35 of 100, loss = 0.012239480604018483   Iteration 36 of 100, loss = 0.012107060640119016   Iteration 37 of 100, loss = 0.01214035606716533   Iteration 38 of 100, loss = 0.012157850273835816   Iteration 39 of 100, loss = 0.0121445787521318   Iteration 40 of 100, loss = 0.011974266276229172   Iteration 41 of 100, loss = 0.01183706928589722   Iteration 42 of 100, loss = 0.011793961681957756   Iteration 43 of 100, loss = 0.011614270248385362   Iteration 44 of 100, loss = 0.011597195132212206   Iteration 45 of 100, loss = 0.011651916056871414   Iteration 46 of 100, loss = 0.011567923027779098   Iteration 47 of 100, loss = 0.01156941982620257   Iteration 48 of 100, loss = 0.011528049003876125   Iteration 49 of 100, loss = 0.01159577568688867   Iteration 50 of 100, loss = 0.011717676175758243   Iteration 51 of 100, loss = 0.011660883869683626   Iteration 52 of 100, loss = 0.011626564297610177   Iteration 53 of 100, loss = 0.011480680078197763   Iteration 54 of 100, loss = 0.01157612166436458   Iteration 55 of 100, loss = 0.011652544403279369   Iteration 56 of 100, loss = 0.01167272451233917   Iteration 57 of 100, loss = 0.01155900559796576   Iteration 58 of 100, loss = 0.011478546693728402   Iteration 59 of 100, loss = 0.011442851551445359   Iteration 60 of 100, loss = 0.0114817505935207   Iteration 61 of 100, loss = 0.011383563287739382   Iteration 62 of 100, loss = 0.011417034089625362   Iteration 63 of 100, loss = 0.011387756249556938   Iteration 64 of 100, loss = 0.011389235158276279   Iteration 65 of 100, loss = 0.011402897973759816   Iteration 66 of 100, loss = 0.01139781974735811   Iteration 67 of 100, loss = 0.011438380266581453   Iteration 68 of 100, loss = 0.011459978934213081   Iteration 69 of 100, loss = 0.011402980168012606   Iteration 70 of 100, loss = 0.011447734199464321   Iteration 71 of 100, loss = 0.011428540113421393   Iteration 72 of 100, loss = 0.011338673868320055   Iteration 73 of 100, loss = 0.011302391169210002   Iteration 74 of 100, loss = 0.011313363771281532   Iteration 75 of 100, loss = 0.011342852786183357   Iteration 76 of 100, loss = 0.011258804239332676   Iteration 77 of 100, loss = 0.011241863868743568   Iteration 78 of 100, loss = 0.011232583843267117   Iteration 79 of 100, loss = 0.01120755874516466   Iteration 80 of 100, loss = 0.011274633056018502   Iteration 81 of 100, loss = 0.011211374142195708   Iteration 82 of 100, loss = 0.011187009161292779   Iteration 83 of 100, loss = 0.0112643443519272   Iteration 84 of 100, loss = 0.011222004092165403   Iteration 85 of 100, loss = 0.011300800105228144   Iteration 86 of 100, loss = 0.011343784760250601   Iteration 87 of 100, loss = 0.01133872228192872   Iteration 88 of 100, loss = 0.011340372349050913   Iteration 89 of 100, loss = 0.011304618141959223   Iteration 90 of 100, loss = 0.011367901518113083   Iteration 91 of 100, loss = 0.01141083129978442   Iteration 92 of 100, loss = 0.011492674279472103   Iteration 93 of 100, loss = 0.011574542290100487   Iteration 94 of 100, loss = 0.011654263401919223   Iteration 95 of 100, loss = 0.011688848457446223   Iteration 96 of 100, loss = 0.011677722058569392   Iteration 97 of 100, loss = 0.01173141448921764   Iteration 98 of 100, loss = 0.011717646591821495   Iteration 99 of 100, loss = 0.011686781543598633   Iteration 100 of 100, loss = 0.011711732586845755
   End of epoch 2; saving model... 

Epoch 3 of 2000
   Iteration 1 of 100, loss = 0.014635580591857433   Iteration 2 of 100, loss = 0.011723450850695372   Iteration 3 of 100, loss = 0.011257952700058619   Iteration 4 of 100, loss = 0.009961623465642333   Iteration 5 of 100, loss = 0.010911127179861068   Iteration 6 of 100, loss = 0.010453200278182825   Iteration 7 of 100, loss = 0.010387073404022626   Iteration 8 of 100, loss = 0.010713901952840388   Iteration 9 of 100, loss = 0.010458383398751417   Iteration 10 of 100, loss = 0.010517433937638997   Iteration 11 of 100, loss = 0.010486351495439356   Iteration 12 of 100, loss = 0.010916446490834156   Iteration 13 of 100, loss = 0.010955574349142037   Iteration 14 of 100, loss = 0.011360459229243653   Iteration 15 of 100, loss = 0.011328618290523689   Iteration 16 of 100, loss = 0.011068462335970253   Iteration 17 of 100, loss = 0.010741151732337825   Iteration 18 of 100, loss = 0.010629298243050775   Iteration 19 of 100, loss = 0.010563925864469064   Iteration 20 of 100, loss = 0.010472737182863057   Iteration 21 of 100, loss = 0.010706632154151088   Iteration 22 of 100, loss = 0.0105939747299999   Iteration 23 of 100, loss = 0.010715905840144209   Iteration 24 of 100, loss = 0.010506216688857725   Iteration 25 of 100, loss = 0.010580481458455325   Iteration 26 of 100, loss = 0.010580554909001175   Iteration 27 of 100, loss = 0.010642529689465408   Iteration 28 of 100, loss = 0.01049626713419067   Iteration 29 of 100, loss = 0.010475734040012648   Iteration 30 of 100, loss = 0.010615611153965195   Iteration 31 of 100, loss = 0.010641750924649739   Iteration 32 of 100, loss = 0.010755096984212287   Iteration 33 of 100, loss = 0.010795644724346472   Iteration 34 of 100, loss = 0.010695102515027803   Iteration 35 of 100, loss = 0.010708163864910603   Iteration 36 of 100, loss = 0.010604494807517363   Iteration 37 of 100, loss = 0.010597074517627826   Iteration 38 of 100, loss = 0.010658658170876535   Iteration 39 of 100, loss = 0.010689216391302837   Iteration 40 of 100, loss = 0.010684241901617497   Iteration 41 of 100, loss = 0.010909250676177623   Iteration 42 of 100, loss = 0.01093090807885996   Iteration 43 of 100, loss = 0.010940913641608731   Iteration 44 of 100, loss = 0.011003144244155423   Iteration 45 of 100, loss = 0.011013340422262747   Iteration 46 of 100, loss = 0.011056221950718242   Iteration 47 of 100, loss = 0.011052319968238156   Iteration 48 of 100, loss = 0.01100913979462348   Iteration 49 of 100, loss = 0.011033659354232403   Iteration 50 of 100, loss = 0.01096388596110046   Iteration 51 of 100, loss = 0.010917019053344048   Iteration 52 of 100, loss = 0.010924081309125401   Iteration 53 of 100, loss = 0.010894455358315751   Iteration 54 of 100, loss = 0.010972359088352986   Iteration 55 of 100, loss = 0.01089165522293611   Iteration 56 of 100, loss = 0.010779653002308416   Iteration 57 of 100, loss = 0.010768944454755177   Iteration 58 of 100, loss = 0.010837739550283757   Iteration 59 of 100, loss = 0.010833000614292036   Iteration 60 of 100, loss = 0.010835827429157991   Iteration 61 of 100, loss = 0.010858140893463717   Iteration 62 of 100, loss = 0.010813808887295665   Iteration 63 of 100, loss = 0.010818237061834051   Iteration 64 of 100, loss = 0.010753252085123677   Iteration 65 of 100, loss = 0.010713598225265741   Iteration 66 of 100, loss = 0.010640598657174092   Iteration 67 of 100, loss = 0.01060513346525493   Iteration 68 of 100, loss = 0.010554869953707299   Iteration 69 of 100, loss = 0.010496540487730417   Iteration 70 of 100, loss = 0.010520958747448666   Iteration 71 of 100, loss = 0.010497970657396905   Iteration 72 of 100, loss = 0.010430246041828973   Iteration 73 of 100, loss = 0.0104304185354036   Iteration 74 of 100, loss = 0.010371799826168933   Iteration 75 of 100, loss = 0.010322499933342139   Iteration 76 of 100, loss = 0.010346515912954745   Iteration 77 of 100, loss = 0.010288623113233548   Iteration 78 of 100, loss = 0.010378205492041813   Iteration 79 of 100, loss = 0.010340392230007845   Iteration 80 of 100, loss = 0.010360876383492723   Iteration 81 of 100, loss = 0.010377339058682138   Iteration 82 of 100, loss = 0.010368213369851796   Iteration 83 of 100, loss = 0.010372532705540758   Iteration 84 of 100, loss = 0.010302621388940938   Iteration 85 of 100, loss = 0.01033257163294098   Iteration 86 of 100, loss = 0.010371207611548692   Iteration 87 of 100, loss = 0.010363825794908849   Iteration 88 of 100, loss = 0.010373462928162719   Iteration 89 of 100, loss = 0.010390754072309544   Iteration 90 of 100, loss = 0.010324271214711998   Iteration 91 of 100, loss = 0.010284963805883467   Iteration 92 of 100, loss = 0.01026089165015551   Iteration 93 of 100, loss = 0.010246613498536809   Iteration 94 of 100, loss = 0.010284361850589197   Iteration 95 of 100, loss = 0.010321216662659456   Iteration 96 of 100, loss = 0.010314385324212102   Iteration 97 of 100, loss = 0.010322911352802491   Iteration 98 of 100, loss = 0.010293506423239502   Iteration 99 of 100, loss = 0.010224509175227147   Iteration 100 of 100, loss = 0.01025341865606606
   End of epoch 3; saving model... 

Epoch 4 of 2000
   Iteration 1 of 100, loss = 0.008925623260438442   Iteration 2 of 100, loss = 0.01183478394523263   Iteration 3 of 100, loss = 0.009336173223952452   Iteration 4 of 100, loss = 0.008659987710416317   Iteration 5 of 100, loss = 0.00934800673276186   Iteration 6 of 100, loss = 0.008998592228939136   Iteration 7 of 100, loss = 0.009160472080111504   Iteration 8 of 100, loss = 0.009979879017919302   Iteration 9 of 100, loss = 0.009582982036388583   Iteration 10 of 100, loss = 0.009298602724447847   Iteration 11 of 100, loss = 0.009625173808837479   Iteration 12 of 100, loss = 0.009688397985883057   Iteration 13 of 100, loss = 0.009649832983716177   Iteration 14 of 100, loss = 0.009472394861014826   Iteration 15 of 100, loss = 0.009856397689630588   Iteration 16 of 100, loss = 0.009927641978720203   Iteration 17 of 100, loss = 0.009838565170545788   Iteration 18 of 100, loss = 0.010033796205081873   Iteration 19 of 100, loss = 0.009953934968890328   Iteration 20 of 100, loss = 0.010115086077712476   Iteration 21 of 100, loss = 0.01024529357839908   Iteration 22 of 100, loss = 0.010200926293195649   Iteration 23 of 100, loss = 0.010241088032236566   Iteration 24 of 100, loss = 0.010275100027987113   Iteration 25 of 100, loss = 0.010311312731355429   Iteration 26 of 100, loss = 0.010307504885041943   Iteration 27 of 100, loss = 0.010305086892374136   Iteration 28 of 100, loss = 0.010212963629913117   Iteration 29 of 100, loss = 0.010299714137639466   Iteration 30 of 100, loss = 0.010208068260302147   Iteration 31 of 100, loss = 0.010243918115813886   Iteration 32 of 100, loss = 0.010123936779564247   Iteration 33 of 100, loss = 0.010148179406921068   Iteration 34 of 100, loss = 0.01020980325034436   Iteration 35 of 100, loss = 0.010119413025677204   Iteration 36 of 100, loss = 0.010190113344126277   Iteration 37 of 100, loss = 0.01003502928526015   Iteration 38 of 100, loss = 0.010053544256247972   Iteration 39 of 100, loss = 0.010115774706579171   Iteration 40 of 100, loss = 0.0099849842954427   Iteration 41 of 100, loss = 0.00986748013827132   Iteration 42 of 100, loss = 0.00987455186744531   Iteration 43 of 100, loss = 0.009831643273490806   Iteration 44 of 100, loss = 0.009882200022482059   Iteration 45 of 100, loss = 0.009836577003200848   Iteration 46 of 100, loss = 0.009898390054054882   Iteration 47 of 100, loss = 0.009906342431427316   Iteration 48 of 100, loss = 0.010027939938784888   Iteration 49 of 100, loss = 0.010091520826883462   Iteration 50 of 100, loss = 0.009983042217791081   Iteration 51 of 100, loss = 0.009977841950660827   Iteration 52 of 100, loss = 0.01006359624891327   Iteration 53 of 100, loss = 0.010077167372658567   Iteration 54 of 100, loss = 0.010065339936840313   Iteration 55 of 100, loss = 0.010037081485444849   Iteration 56 of 100, loss = 0.010032563270734889   Iteration 57 of 100, loss = 0.01003351837004486   Iteration 58 of 100, loss = 0.010130954199823839   Iteration 59 of 100, loss = 0.010192021916983492   Iteration 60 of 100, loss = 0.010252313377956549   Iteration 61 of 100, loss = 0.010185104558152741   Iteration 62 of 100, loss = 0.010182338488859034   Iteration 63 of 100, loss = 0.01010590944705265   Iteration 64 of 100, loss = 0.010063420937513001   Iteration 65 of 100, loss = 0.010085454396903514   Iteration 66 of 100, loss = 0.010093146314223608   Iteration 67 of 100, loss = 0.010083764847089996   Iteration 68 of 100, loss = 0.010050002752584131   Iteration 69 of 100, loss = 0.010068115137139524   Iteration 70 of 100, loss = 0.01008324345706829   Iteration 71 of 100, loss = 0.009994780726757057   Iteration 72 of 100, loss = 0.01001379427099083   Iteration 73 of 100, loss = 0.010003253399738914   Iteration 74 of 100, loss = 0.010030760093139031   Iteration 75 of 100, loss = 0.010046621824925144   Iteration 76 of 100, loss = 0.009995437720422879   Iteration 77 of 100, loss = 0.009980711580991938   Iteration 78 of 100, loss = 0.010053462566783985   Iteration 79 of 100, loss = 0.010159596426506774   Iteration 80 of 100, loss = 0.010085473445360548   Iteration 81 of 100, loss = 0.010004790048517379   Iteration 82 of 100, loss = 0.010011162185791607   Iteration 83 of 100, loss = 0.010023646805637393   Iteration 84 of 100, loss = 0.00999500339440558   Iteration 85 of 100, loss = 0.00994124875184806   Iteration 86 of 100, loss = 0.009919204697727637   Iteration 87 of 100, loss = 0.009904925414393174   Iteration 88 of 100, loss = 0.009857668268854137   Iteration 89 of 100, loss = 0.009833568191741792   Iteration 90 of 100, loss = 0.009831599536765781   Iteration 91 of 100, loss = 0.009878626848049053   Iteration 92 of 100, loss = 0.00988140385142406   Iteration 93 of 100, loss = 0.009893476630070357   Iteration 94 of 100, loss = 0.009850912814107823   Iteration 95 of 100, loss = 0.009803830030815381   Iteration 96 of 100, loss = 0.009818045017406499   Iteration 97 of 100, loss = 0.009828085418233705   Iteration 98 of 100, loss = 0.009823276321593749   Iteration 99 of 100, loss = 0.009867619462029048   Iteration 100 of 100, loss = 0.009838627364952118
   End of epoch 4; saving model... 

Epoch 5 of 2000
   Iteration 1 of 100, loss = 0.012726032175123692   Iteration 2 of 100, loss = 0.009619714692234993   Iteration 3 of 100, loss = 0.0085837262061735   Iteration 4 of 100, loss = 0.008265655487775803   Iteration 5 of 100, loss = 0.008950960822403431   Iteration 6 of 100, loss = 0.009107686889668306   Iteration 7 of 100, loss = 0.00966464408806392   Iteration 8 of 100, loss = 0.009822503430768847   Iteration 9 of 100, loss = 0.009573435824778345   Iteration 10 of 100, loss = 0.009686446283012629   Iteration 11 of 100, loss = 0.00914881342429329   Iteration 12 of 100, loss = 0.009073627938050777   Iteration 13 of 100, loss = 0.009273668733210517   Iteration 14 of 100, loss = 0.008990942018239625   Iteration 15 of 100, loss = 0.009136689004177849   Iteration 16 of 100, loss = 0.009431104976101778   Iteration 17 of 100, loss = 0.009714584290871726   Iteration 18 of 100, loss = 0.009533568375950886   Iteration 19 of 100, loss = 0.009616055170466242   Iteration 20 of 100, loss = 0.00975596884964034   Iteration 21 of 100, loss = 0.009808728815100733   Iteration 22 of 100, loss = 0.009593263660049573   Iteration 23 of 100, loss = 0.009755466345940595   Iteration 24 of 100, loss = 0.009872513949327791   Iteration 25 of 100, loss = 0.009659968735650181   Iteration 26 of 100, loss = 0.009686503711586388   Iteration 27 of 100, loss = 0.009822883513859577   Iteration 28 of 100, loss = 0.009958799803696041   Iteration 29 of 100, loss = 0.00972957390456878   Iteration 30 of 100, loss = 0.009609778380642335   Iteration 31 of 100, loss = 0.009668700397014618   Iteration 32 of 100, loss = 0.009714522719150409   Iteration 33 of 100, loss = 0.009709877780441082   Iteration 34 of 100, loss = 0.009817944702637546   Iteration 35 of 100, loss = 0.009700952430388756   Iteration 36 of 100, loss = 0.009655651804577146   Iteration 37 of 100, loss = 0.009584074198092157   Iteration 38 of 100, loss = 0.009432514718929795   Iteration 39 of 100, loss = 0.009505209136897555   Iteration 40 of 100, loss = 0.009636118734488264   Iteration 41 of 100, loss = 0.009719325257919548   Iteration 42 of 100, loss = 0.00962964205315248   Iteration 43 of 100, loss = 0.009570769776135336   Iteration 44 of 100, loss = 0.009432936060792681   Iteration 45 of 100, loss = 0.009542517689988017   Iteration 46 of 100, loss = 0.009728005960705164   Iteration 47 of 100, loss = 0.00970392794586084   Iteration 48 of 100, loss = 0.009782179428536134   Iteration 49 of 100, loss = 0.009723415336932759   Iteration 50 of 100, loss = 0.009686413486488164   Iteration 51 of 100, loss = 0.009704410486544171   Iteration 52 of 100, loss = 0.00971342820692091   Iteration 53 of 100, loss = 0.009689298427646171   Iteration 54 of 100, loss = 0.009708506162968223   Iteration 55 of 100, loss = 0.009675705470991405   Iteration 56 of 100, loss = 0.009620163252943062   Iteration 57 of 100, loss = 0.009678037195842256   Iteration 58 of 100, loss = 0.009646718546844506   Iteration 59 of 100, loss = 0.009600313273810987   Iteration 60 of 100, loss = 0.009593436917445313   Iteration 61 of 100, loss = 0.009558186435033797   Iteration 62 of 100, loss = 0.009488251732452022   Iteration 63 of 100, loss = 0.009434071639257054   Iteration 64 of 100, loss = 0.009398643804161111   Iteration 65 of 100, loss = 0.009383286453353672   Iteration 66 of 100, loss = 0.009416644591979231   Iteration 67 of 100, loss = 0.009344755501639265   Iteration 68 of 100, loss = 0.009333881847423446   Iteration 69 of 100, loss = 0.009277876685845895   Iteration 70 of 100, loss = 0.009200852560544653   Iteration 71 of 100, loss = 0.009133825213058104   Iteration 72 of 100, loss = 0.009093435264528833   Iteration 73 of 100, loss = 0.009013200446657122   Iteration 74 of 100, loss = 0.008994554924602443   Iteration 75 of 100, loss = 0.009024006215234597   Iteration 76 of 100, loss = 0.009031907581773243   Iteration 77 of 100, loss = 0.00906466759209122   Iteration 78 of 100, loss = 0.009138083909280025   Iteration 79 of 100, loss = 0.00912886019796133   Iteration 80 of 100, loss = 0.009069461183389648   Iteration 81 of 100, loss = 0.009080810616091813   Iteration 82 of 100, loss = 0.009067732778309686   Iteration 83 of 100, loss = 0.009089759276080203   Iteration 84 of 100, loss = 0.009095926297872904   Iteration 85 of 100, loss = 0.00907435039167895   Iteration 86 of 100, loss = 0.00908388213666026   Iteration 87 of 100, loss = 0.009040396719443044   Iteration 88 of 100, loss = 0.009036817847200755   Iteration 89 of 100, loss = 0.00904972165341625   Iteration 90 of 100, loss = 0.009075064424218402   Iteration 91 of 100, loss = 0.009100020162065278   Iteration 92 of 100, loss = 0.009039399171065863   Iteration 93 of 100, loss = 0.008993442703579222   Iteration 94 of 100, loss = 0.009025294494696278   Iteration 95 of 100, loss = 0.009109711492630212   Iteration 96 of 100, loss = 0.009086963126416473   Iteration 97 of 100, loss = 0.009089445875304723   Iteration 98 of 100, loss = 0.009072350981949391   Iteration 99 of 100, loss = 0.009091038132236913   Iteration 100 of 100, loss = 0.00908645526273176
   End of epoch 5; saving model... 

Epoch 6 of 2000
   Iteration 1 of 100, loss = 0.013746720738708973   Iteration 2 of 100, loss = 0.013523089699447155   Iteration 3 of 100, loss = 0.011026825134952864   Iteration 4 of 100, loss = 0.011329199420288205   Iteration 5 of 100, loss = 0.010806885547935963   Iteration 6 of 100, loss = 0.010079773298154274   Iteration 7 of 100, loss = 0.009709238806473357   Iteration 8 of 100, loss = 0.009858467557933182   Iteration 9 of 100, loss = 0.010019783603234423   Iteration 10 of 100, loss = 0.010688337543979288   Iteration 11 of 100, loss = 0.010791659143499353   Iteration 12 of 100, loss = 0.010451879158305625   Iteration 13 of 100, loss = 0.010885250503913714   Iteration 14 of 100, loss = 0.010614047226096903   Iteration 15 of 100, loss = 0.010715810519953569   Iteration 16 of 100, loss = 0.010447986802319065   Iteration 17 of 100, loss = 0.010245437514694297   Iteration 18 of 100, loss = 0.009878345700498257   Iteration 19 of 100, loss = 0.009756833474200807   Iteration 20 of 100, loss = 0.00951984025305137   Iteration 21 of 100, loss = 0.009303399838418477   Iteration 22 of 100, loss = 0.009091352229006588   Iteration 23 of 100, loss = 0.008982197634632821   Iteration 24 of 100, loss = 0.009140023544508344   Iteration 25 of 100, loss = 0.008948122905567289   Iteration 26 of 100, loss = 0.008848155696446506   Iteration 27 of 100, loss = 0.008686332816809968   Iteration 28 of 100, loss = 0.00861289702256077   Iteration 29 of 100, loss = 0.008525002675516338   Iteration 30 of 100, loss = 0.00853948794150104   Iteration 31 of 100, loss = 0.008535646705798084   Iteration 32 of 100, loss = 0.008419901823799592   Iteration 33 of 100, loss = 0.008458282255257169   Iteration 34 of 100, loss = 0.008852295817204696   Iteration 35 of 100, loss = 0.008944416092708707   Iteration 36 of 100, loss = 0.009043188707437366   Iteration 37 of 100, loss = 0.009043445930237303   Iteration 38 of 100, loss = 0.008903911668121031   Iteration 39 of 100, loss = 0.008847111143553868   Iteration 40 of 100, loss = 0.008869644463993609   Iteration 41 of 100, loss = 0.008876767622806677   Iteration 42 of 100, loss = 0.008839397025959832   Iteration 43 of 100, loss = 0.008784094749581675   Iteration 44 of 100, loss = 0.008799678868275474   Iteration 45 of 100, loss = 0.008756860035161178   Iteration 46 of 100, loss = 0.008792929574037376   Iteration 47 of 100, loss = 0.008723116529352487   Iteration 48 of 100, loss = 0.008730735872328902   Iteration 49 of 100, loss = 0.008742619809523528   Iteration 50 of 100, loss = 0.008833682602271438   Iteration 51 of 100, loss = 0.00879970632091749   Iteration 52 of 100, loss = 0.008749088326182503   Iteration 53 of 100, loss = 0.008724587495034596   Iteration 54 of 100, loss = 0.008696775788579273   Iteration 55 of 100, loss = 0.008656549995595758   Iteration 56 of 100, loss = 0.008595681591292046   Iteration 57 of 100, loss = 0.008502263404232891   Iteration 58 of 100, loss = 0.008503022932864982   Iteration 59 of 100, loss = 0.008466496353306003   Iteration 60 of 100, loss = 0.008451798007202645   Iteration 61 of 100, loss = 0.008370389329788626   Iteration 62 of 100, loss = 0.008302061998796078   Iteration 63 of 100, loss = 0.008365295147375456   Iteration 64 of 100, loss = 0.008340117798070423   Iteration 65 of 100, loss = 0.008307769479086766   Iteration 66 of 100, loss = 0.008319942802755219   Iteration 67 of 100, loss = 0.008306450933329206   Iteration 68 of 100, loss = 0.008427590035888203   Iteration 69 of 100, loss = 0.008416882432673288   Iteration 70 of 100, loss = 0.008371434214391878   Iteration 71 of 100, loss = 0.008422070733783111   Iteration 72 of 100, loss = 0.008500732377999358   Iteration 73 of 100, loss = 0.0085155456645848   Iteration 74 of 100, loss = 0.008502418477390264   Iteration 75 of 100, loss = 0.008517678293089071   Iteration 76 of 100, loss = 0.008455581301333089   Iteration 77 of 100, loss = 0.008470856088709521   Iteration 78 of 100, loss = 0.008458303675676385   Iteration 79 of 100, loss = 0.008502023960640537   Iteration 80 of 100, loss = 0.008547471970086918   Iteration 81 of 100, loss = 0.008512180787223725   Iteration 82 of 100, loss = 0.008484659443904714   Iteration 83 of 100, loss = 0.008512050429561052   Iteration 84 of 100, loss = 0.00850596068249572   Iteration 85 of 100, loss = 0.008512965217232705   Iteration 86 of 100, loss = 0.00848333740087096   Iteration 87 of 100, loss = 0.00846300115701796   Iteration 88 of 100, loss = 0.008496634429320693   Iteration 89 of 100, loss = 0.008584633469581604   Iteration 90 of 100, loss = 0.008623917535361316   Iteration 91 of 100, loss = 0.008588270222829594   Iteration 92 of 100, loss = 0.008548369433771333   Iteration 93 of 100, loss = 0.008565973144985976   Iteration 94 of 100, loss = 0.008523819641150693   Iteration 95 of 100, loss = 0.008521394225719727   Iteration 96 of 100, loss = 0.008520996440590048   Iteration 97 of 100, loss = 0.008523213849931034   Iteration 98 of 100, loss = 0.008511445570585072   Iteration 99 of 100, loss = 0.00849206324177559   Iteration 100 of 100, loss = 0.008472772710956634
   End of epoch 6; saving model... 

Epoch 7 of 2000
   Iteration 1 of 100, loss = 0.007504279259592295   Iteration 2 of 100, loss = 0.00887787458486855   Iteration 3 of 100, loss = 0.008365238240609566   Iteration 4 of 100, loss = 0.007450520526617765   Iteration 5 of 100, loss = 0.007479626219719648   Iteration 6 of 100, loss = 0.008758117832864324   Iteration 7 of 100, loss = 0.009477442196969475   Iteration 8 of 100, loss = 0.009591655165422708   Iteration 9 of 100, loss = 0.009587146600501405   Iteration 10 of 100, loss = 0.009237223491072654   Iteration 11 of 100, loss = 0.009291105141693895   Iteration 12 of 100, loss = 0.009336769813671708   Iteration 13 of 100, loss = 0.009201612323522568   Iteration 14 of 100, loss = 0.009262950159609318   Iteration 15 of 100, loss = 0.008936583437025547   Iteration 16 of 100, loss = 0.009154614992439747   Iteration 17 of 100, loss = 0.008971212404396604   Iteration 18 of 100, loss = 0.008933282172721293   Iteration 19 of 100, loss = 0.008969284520533524   Iteration 20 of 100, loss = 0.00874674052465707   Iteration 21 of 100, loss = 0.008756508052881275   Iteration 22 of 100, loss = 0.008541578998450528   Iteration 23 of 100, loss = 0.008653029819707508   Iteration 24 of 100, loss = 0.008659857073022673   Iteration 25 of 100, loss = 0.008723451141268015   Iteration 26 of 100, loss = 0.008747672823329385   Iteration 27 of 100, loss = 0.008807472108552853   Iteration 28 of 100, loss = 0.008841598955249148   Iteration 29 of 100, loss = 0.00886708724408828   Iteration 30 of 100, loss = 0.008789226909478505   Iteration 31 of 100, loss = 0.008723383183561025   Iteration 32 of 100, loss = 0.008831039638607763   Iteration 33 of 100, loss = 0.008789382564524809   Iteration 34 of 100, loss = 0.008804395466166385   Iteration 35 of 100, loss = 0.00877542548945972   Iteration 36 of 100, loss = 0.008802869253688388   Iteration 37 of 100, loss = 0.008833472793166703   Iteration 38 of 100, loss = 0.008830947654419824   Iteration 39 of 100, loss = 0.008858387597287312   Iteration 40 of 100, loss = 0.008959491341374814   Iteration 41 of 100, loss = 0.008927008364258743   Iteration 42 of 100, loss = 0.008784766669296437   Iteration 43 of 100, loss = 0.008907313962185453   Iteration 44 of 100, loss = 0.008894261718854646   Iteration 45 of 100, loss = 0.008848139410838484   Iteration 46 of 100, loss = 0.008979849451545464   Iteration 47 of 100, loss = 0.008986211198560417   Iteration 48 of 100, loss = 0.00898690389294643   Iteration 49 of 100, loss = 0.008908345644381277   Iteration 50 of 100, loss = 0.00897466994356364   Iteration 51 of 100, loss = 0.008980150969114666   Iteration 52 of 100, loss = 0.008979709115989793   Iteration 53 of 100, loss = 0.008925025030654276   Iteration 54 of 100, loss = 0.008927577446835736   Iteration 55 of 100, loss = 0.008850002216852525   Iteration 56 of 100, loss = 0.008856038774995665   Iteration 57 of 100, loss = 0.00886721867790217   Iteration 58 of 100, loss = 0.008902044400797579   Iteration 59 of 100, loss = 0.008965501368393079   Iteration 60 of 100, loss = 0.008944537036586552   Iteration 61 of 100, loss = 0.008947356310138693   Iteration 62 of 100, loss = 0.008943896676834312   Iteration 63 of 100, loss = 0.008916308959236457   Iteration 64 of 100, loss = 0.008942325632233405   Iteration 65 of 100, loss = 0.008882998635705847   Iteration 66 of 100, loss = 0.008926925394034974   Iteration 67 of 100, loss = 0.008949189144534185   Iteration 68 of 100, loss = 0.008890278846271993   Iteration 69 of 100, loss = 0.008844047167297938   Iteration 70 of 100, loss = 0.008887274686380156   Iteration 71 of 100, loss = 0.008847793515010829   Iteration 72 of 100, loss = 0.008869579207384959   Iteration 73 of 100, loss = 0.008846870901012053   Iteration 74 of 100, loss = 0.008796430944867834   Iteration 75 of 100, loss = 0.008770324559882282   Iteration 76 of 100, loss = 0.008764800257172044   Iteration 77 of 100, loss = 0.008782942957764902   Iteration 78 of 100, loss = 0.008839241823014349   Iteration 79 of 100, loss = 0.008910330492838086   Iteration 80 of 100, loss = 0.008921138555160723   Iteration 81 of 100, loss = 0.00887969895955865   Iteration 82 of 100, loss = 0.008915169014050284   Iteration 83 of 100, loss = 0.008887142181418926   Iteration 84 of 100, loss = 0.008867218577679956   Iteration 85 of 100, loss = 0.008829117618391618   Iteration 86 of 100, loss = 0.008857997001668567   Iteration 87 of 100, loss = 0.008865708942878348   Iteration 88 of 100, loss = 0.008940577779536728   Iteration 89 of 100, loss = 0.008960676376885746   Iteration 90 of 100, loss = 0.008944180527598494   Iteration 91 of 100, loss = 0.008923156424886086   Iteration 92 of 100, loss = 0.008866291192016039   Iteration 93 of 100, loss = 0.008888223801829642   Iteration 94 of 100, loss = 0.008854049785518424   Iteration 95 of 100, loss = 0.008835234544485024   Iteration 96 of 100, loss = 0.008786866982215239   Iteration 97 of 100, loss = 0.00878902913320848   Iteration 98 of 100, loss = 0.008767082220494595   Iteration 99 of 100, loss = 0.008769030576910485   Iteration 100 of 100, loss = 0.008759287183638663
   End of epoch 7; saving model... 

Epoch 8 of 2000
   Iteration 1 of 100, loss = 0.00982787273824215   Iteration 2 of 100, loss = 0.00926355179399252   Iteration 3 of 100, loss = 0.011129761735598246   Iteration 4 of 100, loss = 0.011173201957717538   Iteration 5 of 100, loss = 0.010333472676575185   Iteration 6 of 100, loss = 0.00954113838573297   Iteration 7 of 100, loss = 0.009276336857250758   Iteration 8 of 100, loss = 0.008639484934974462   Iteration 9 of 100, loss = 0.008201817361017069   Iteration 10 of 100, loss = 0.008503669966012239   Iteration 11 of 100, loss = 0.00878111162984913   Iteration 12 of 100, loss = 0.008845866580183307   Iteration 13 of 100, loss = 0.009237070854466695   Iteration 14 of 100, loss = 0.009342326183936425   Iteration 15 of 100, loss = 0.009521901607513428   Iteration 16 of 100, loss = 0.009445211908314377   Iteration 17 of 100, loss = 0.009577671065926552   Iteration 18 of 100, loss = 0.009563110406614013   Iteration 19 of 100, loss = 0.009610527097002455   Iteration 20 of 100, loss = 0.009322781546507031   Iteration 21 of 100, loss = 0.009205509453923219   Iteration 22 of 100, loss = 0.009201429096389224   Iteration 23 of 100, loss = 0.009104944310029563   Iteration 24 of 100, loss = 0.008867684635333717   Iteration 25 of 100, loss = 0.009030943959951401   Iteration 26 of 100, loss = 0.009026514975210795   Iteration 27 of 100, loss = 0.00932036571342636   Iteration 28 of 100, loss = 0.009316967234813742   Iteration 29 of 100, loss = 0.009205355614038378   Iteration 30 of 100, loss = 0.009035089736183484   Iteration 31 of 100, loss = 0.008911245367339542   Iteration 32 of 100, loss = 0.008761324133956805   Iteration 33 of 100, loss = 0.008768275972794403   Iteration 34 of 100, loss = 0.00879223839215496   Iteration 35 of 100, loss = 0.008903557620942592   Iteration 36 of 100, loss = 0.009040154076905714   Iteration 37 of 100, loss = 0.008981239050626755   Iteration 38 of 100, loss = 0.008818692588982614   Iteration 39 of 100, loss = 0.008912875161816677   Iteration 40 of 100, loss = 0.008798266714438795   Iteration 41 of 100, loss = 0.008795515270676554   Iteration 42 of 100, loss = 0.00876431727027964   Iteration 43 of 100, loss = 0.00866632648678713   Iteration 44 of 100, loss = 0.00869005960835652   Iteration 45 of 100, loss = 0.008702427645524343   Iteration 46 of 100, loss = 0.008796063818685387   Iteration 47 of 100, loss = 0.0087668242507634   Iteration 48 of 100, loss = 0.008692541140286872   Iteration 49 of 100, loss = 0.008698427935644073   Iteration 50 of 100, loss = 0.008711215872317553   Iteration 51 of 100, loss = 0.008639366448144703   Iteration 52 of 100, loss = 0.0086406965722115   Iteration 53 of 100, loss = 0.008673670833473498   Iteration 54 of 100, loss = 0.00874394101642624   Iteration 55 of 100, loss = 0.008729660485617139   Iteration 56 of 100, loss = 0.008787232958379068   Iteration 57 of 100, loss = 0.008836914956765739   Iteration 58 of 100, loss = 0.008850028666121692   Iteration 59 of 100, loss = 0.008836901359954628   Iteration 60 of 100, loss = 0.008882881755319734   Iteration 61 of 100, loss = 0.008935997377103959   Iteration 62 of 100, loss = 0.008944121151862125   Iteration 63 of 100, loss = 0.008862515904068474   Iteration 64 of 100, loss = 0.00885851417115191   Iteration 65 of 100, loss = 0.008857755857304885   Iteration 66 of 100, loss = 0.008834899240878947   Iteration 67 of 100, loss = 0.008920479670111368   Iteration 68 of 100, loss = 0.008955100996365003   Iteration 69 of 100, loss = 0.008906638911128908   Iteration 70 of 100, loss = 0.008878293347411923   Iteration 71 of 100, loss = 0.008871308127811678   Iteration 72 of 100, loss = 0.00886597107293912   Iteration 73 of 100, loss = 0.008834082741698581   Iteration 74 of 100, loss = 0.008826678524397918   Iteration 75 of 100, loss = 0.008860522080212832   Iteration 76 of 100, loss = 0.00881258985885468   Iteration 77 of 100, loss = 0.008797734467820688   Iteration 78 of 100, loss = 0.008749629454448437   Iteration 79 of 100, loss = 0.008759384656537183   Iteration 80 of 100, loss = 0.008743080758722498   Iteration 81 of 100, loss = 0.008690128229374502   Iteration 82 of 100, loss = 0.00871301285649945   Iteration 83 of 100, loss = 0.008683771719729685   Iteration 84 of 100, loss = 0.008706298440561764   Iteration 85 of 100, loss = 0.008665204322075142   Iteration 86 of 100, loss = 0.008709222673936638   Iteration 87 of 100, loss = 0.00871196071264045   Iteration 88 of 100, loss = 0.00866603764006868   Iteration 89 of 100, loss = 0.008688997922025704   Iteration 90 of 100, loss = 0.008687530235490865   Iteration 91 of 100, loss = 0.00866995880810114   Iteration 92 of 100, loss = 0.008647451865608278   Iteration 93 of 100, loss = 0.008597244703841786   Iteration 94 of 100, loss = 0.008646795154608627   Iteration 95 of 100, loss = 0.008623928091439761   Iteration 96 of 100, loss = 0.008581629503169097   Iteration 97 of 100, loss = 0.008659419282003469   Iteration 98 of 100, loss = 0.0086420658662231   Iteration 99 of 100, loss = 0.00861505436889752   Iteration 100 of 100, loss = 0.008590807942673563
   End of epoch 8; saving model... 

Epoch 9 of 2000
   Iteration 1 of 100, loss = 0.005885726306587458   Iteration 2 of 100, loss = 0.007902816170826554   Iteration 3 of 100, loss = 0.011536947917193174   Iteration 4 of 100, loss = 0.010589122772216797   Iteration 5 of 100, loss = 0.009303942788392305   Iteration 6 of 100, loss = 0.009443448313201467   Iteration 7 of 100, loss = 0.008629380060093743   Iteration 8 of 100, loss = 0.0079795565106906   Iteration 9 of 100, loss = 0.007896241628461413   Iteration 10 of 100, loss = 0.008051346521824598   Iteration 11 of 100, loss = 0.00804492382502014   Iteration 12 of 100, loss = 0.007803715571450691   Iteration 13 of 100, loss = 0.007895308081060648   Iteration 14 of 100, loss = 0.007562339405662247   Iteration 15 of 100, loss = 0.00771133325373133   Iteration 16 of 100, loss = 0.007538665988249704   Iteration 17 of 100, loss = 0.007307360455503359   Iteration 18 of 100, loss = 0.007349121086816821   Iteration 19 of 100, loss = 0.007429537914791389   Iteration 20 of 100, loss = 0.007618868409190327   Iteration 21 of 100, loss = 0.007506496993647445   Iteration 22 of 100, loss = 0.007617991385896775   Iteration 23 of 100, loss = 0.007864642979415215   Iteration 24 of 100, loss = 0.007996293609418595   Iteration 25 of 100, loss = 0.007902647079899907   Iteration 26 of 100, loss = 0.007935513213921625   Iteration 27 of 100, loss = 0.007955828828185244   Iteration 28 of 100, loss = 0.007859688643033482   Iteration 29 of 100, loss = 0.007940652515289599   Iteration 30 of 100, loss = 0.008034917673406501   Iteration 31 of 100, loss = 0.007928672915084227   Iteration 32 of 100, loss = 0.008011453704966698   Iteration 33 of 100, loss = 0.007969758071174676   Iteration 34 of 100, loss = 0.007948284030563253   Iteration 35 of 100, loss = 0.008038209531722323   Iteration 36 of 100, loss = 0.008035878747856865   Iteration 37 of 100, loss = 0.008006862358416657   Iteration 38 of 100, loss = 0.008005296780825838   Iteration 39 of 100, loss = 0.007948236796670618   Iteration 40 of 100, loss = 0.0078682386840228   Iteration 41 of 100, loss = 0.007894792690555133   Iteration 42 of 100, loss = 0.007899875758171436   Iteration 43 of 100, loss = 0.007864026845497795   Iteration 44 of 100, loss = 0.007899245072621852   Iteration 45 of 100, loss = 0.007936788096817003   Iteration 46 of 100, loss = 0.008001107332782576   Iteration 47 of 100, loss = 0.007978807792979036   Iteration 48 of 100, loss = 0.008060267248462575   Iteration 49 of 100, loss = 0.008032328235365602   Iteration 50 of 100, loss = 0.008069726000539958   Iteration 51 of 100, loss = 0.00813729929116865   Iteration 52 of 100, loss = 0.008110034794439204   Iteration 53 of 100, loss = 0.008214693301234324   Iteration 54 of 100, loss = 0.008211981587077456   Iteration 55 of 100, loss = 0.008197394178502938   Iteration 56 of 100, loss = 0.00818744647300004   Iteration 57 of 100, loss = 0.008266900482244398   Iteration 58 of 100, loss = 0.008219922374901843   Iteration 59 of 100, loss = 0.008198382573644235   Iteration 60 of 100, loss = 0.00815503978713726   Iteration 61 of 100, loss = 0.008122120850307286   Iteration 62 of 100, loss = 0.008048382921955519   Iteration 63 of 100, loss = 0.008094785812621316   Iteration 64 of 100, loss = 0.00803795531464857   Iteration 65 of 100, loss = 0.00801232628739224   Iteration 66 of 100, loss = 0.007942711715727593   Iteration 67 of 100, loss = 0.007971427382539902   Iteration 68 of 100, loss = 0.007931652430938008   Iteration 69 of 100, loss = 0.007937215788262909   Iteration 70 of 100, loss = 0.00795629289932549   Iteration 71 of 100, loss = 0.007889049681900462   Iteration 72 of 100, loss = 0.007838903560898162   Iteration 73 of 100, loss = 0.007832511082572276   Iteration 74 of 100, loss = 0.007794902681977161   Iteration 75 of 100, loss = 0.007748115469391147   Iteration 76 of 100, loss = 0.007797590674415819   Iteration 77 of 100, loss = 0.0077707329795199944   Iteration 78 of 100, loss = 0.00774535699449002   Iteration 79 of 100, loss = 0.0077378648551346   Iteration 80 of 100, loss = 0.007733459261362441   Iteration 81 of 100, loss = 0.007746694589401653   Iteration 82 of 100, loss = 0.007742917991425024   Iteration 83 of 100, loss = 0.007788766655195729   Iteration 84 of 100, loss = 0.007816388047233756   Iteration 85 of 100, loss = 0.007832468166837797   Iteration 86 of 100, loss = 0.007856465884224447   Iteration 87 of 100, loss = 0.007823374933274141   Iteration 88 of 100, loss = 0.007833736797858199   Iteration 89 of 100, loss = 0.00781967685809045   Iteration 90 of 100, loss = 0.007823413571653266   Iteration 91 of 100, loss = 0.007834149056349646   Iteration 92 of 100, loss = 0.00781925685916339   Iteration 93 of 100, loss = 0.007826973256024142   Iteration 94 of 100, loss = 0.007841140668383463   Iteration 95 of 100, loss = 0.007812957296540078   Iteration 96 of 100, loss = 0.007828626885990767   Iteration 97 of 100, loss = 0.00788336859526324   Iteration 98 of 100, loss = 0.00785759293084622   Iteration 99 of 100, loss = 0.007929055718705058   Iteration 100 of 100, loss = 0.007899790278170258
   End of epoch 9; saving model... 

Epoch 10 of 2000
   Iteration 1 of 100, loss = 0.005465060006827116   Iteration 2 of 100, loss = 0.0050557011272758245   Iteration 3 of 100, loss = 0.006953687562296788   Iteration 4 of 100, loss = 0.007758113672025502   Iteration 5 of 100, loss = 0.007649582903832197   Iteration 6 of 100, loss = 0.007306884586190184   Iteration 7 of 100, loss = 0.007372070037360702   Iteration 8 of 100, loss = 0.007643870136234909   Iteration 9 of 100, loss = 0.00785204048992859   Iteration 10 of 100, loss = 0.007859644619747997   Iteration 11 of 100, loss = 0.007778557356108318   Iteration 12 of 100, loss = 0.007577062817290425   Iteration 13 of 100, loss = 0.007655891016698801   Iteration 14 of 100, loss = 0.007527797815522977   Iteration 15 of 100, loss = 0.007395054617275795   Iteration 16 of 100, loss = 0.00733652850612998   Iteration 17 of 100, loss = 0.007490090751910911   Iteration 18 of 100, loss = 0.007778754199130667   Iteration 19 of 100, loss = 0.007615650660897556   Iteration 20 of 100, loss = 0.007966570276767015   Iteration 21 of 100, loss = 0.00810212752826157   Iteration 22 of 100, loss = 0.008151817474175583   Iteration 23 of 100, loss = 0.00804420447219973   Iteration 24 of 100, loss = 0.00815460248850286   Iteration 25 of 100, loss = 0.00803286112844944   Iteration 26 of 100, loss = 0.007991690546847306   Iteration 27 of 100, loss = 0.00806846148851845   Iteration 28 of 100, loss = 0.007943321651379977   Iteration 29 of 100, loss = 0.008076594211161137   Iteration 30 of 100, loss = 0.00813650464018186   Iteration 31 of 100, loss = 0.008088323077367197   Iteration 32 of 100, loss = 0.007974509106134064   Iteration 33 of 100, loss = 0.007954843017752424   Iteration 34 of 100, loss = 0.007960039916831781   Iteration 35 of 100, loss = 0.007960645628294774   Iteration 36 of 100, loss = 0.007994812848563824   Iteration 37 of 100, loss = 0.007957343427414025   Iteration 38 of 100, loss = 0.007966662475251053   Iteration 39 of 100, loss = 0.007925340643104834   Iteration 40 of 100, loss = 0.007933968678116798   Iteration 41 of 100, loss = 0.007892045839803248   Iteration 42 of 100, loss = 0.007814383012286964   Iteration 43 of 100, loss = 0.007699332622334708   Iteration 44 of 100, loss = 0.007691386610862206   Iteration 45 of 100, loss = 0.007684862137668663   Iteration 46 of 100, loss = 0.007662181813350838   Iteration 47 of 100, loss = 0.0076156143554823195   Iteration 48 of 100, loss = 0.007549225294496864   Iteration 49 of 100, loss = 0.007653615798573105   Iteration 50 of 100, loss = 0.007637346033006907   Iteration 51 of 100, loss = 0.0075896099008911965   Iteration 52 of 100, loss = 0.0076073679016329925   Iteration 53 of 100, loss = 0.0075807987782612165   Iteration 54 of 100, loss = 0.007577215450712376   Iteration 55 of 100, loss = 0.007564128469675779   Iteration 56 of 100, loss = 0.007633087532927415   Iteration 57 of 100, loss = 0.007687237808121401   Iteration 58 of 100, loss = 0.0076717087870527955   Iteration 59 of 100, loss = 0.007632062107450881   Iteration 60 of 100, loss = 0.007545242477984478   Iteration 61 of 100, loss = 0.007529768379038719   Iteration 62 of 100, loss = 0.007499101417770069   Iteration 63 of 100, loss = 0.007520587771155295   Iteration 64 of 100, loss = 0.007534163636591984   Iteration 65 of 100, loss = 0.007557077372733217   Iteration 66 of 100, loss = 0.007563249853608961   Iteration 67 of 100, loss = 0.007689430138596625   Iteration 68 of 100, loss = 0.0077141315148978986   Iteration 69 of 100, loss = 0.007730392141915534   Iteration 70 of 100, loss = 0.007708824542351067   Iteration 71 of 100, loss = 0.007681032475477583   Iteration 72 of 100, loss = 0.00777265259077669   Iteration 73 of 100, loss = 0.0077544104990434565   Iteration 74 of 100, loss = 0.007726825304908326   Iteration 75 of 100, loss = 0.007760676837836703   Iteration 76 of 100, loss = 0.007795620179661599   Iteration 77 of 100, loss = 0.007778352480260776   Iteration 78 of 100, loss = 0.007769938752365609   Iteration 79 of 100, loss = 0.007810913724824786   Iteration 80 of 100, loss = 0.007851573408697732   Iteration 81 of 100, loss = 0.007837666678644809   Iteration 82 of 100, loss = 0.007814155195885134   Iteration 83 of 100, loss = 0.007774380010451718   Iteration 84 of 100, loss = 0.007789171896764033   Iteration 85 of 100, loss = 0.007775197230169878   Iteration 86 of 100, loss = 0.007775020095259818   Iteration 87 of 100, loss = 0.007755742025636564   Iteration 88 of 100, loss = 0.007712136104766449   Iteration 89 of 100, loss = 0.007710458645387814   Iteration 90 of 100, loss = 0.007730619937905835   Iteration 91 of 100, loss = 0.007749947675780117   Iteration 92 of 100, loss = 0.007785186624539126   Iteration 93 of 100, loss = 0.007816183047809748   Iteration 94 of 100, loss = 0.007827322412420935   Iteration 95 of 100, loss = 0.007791066941756167   Iteration 96 of 100, loss = 0.007833618755588153   Iteration 97 of 100, loss = 0.00780064344991805   Iteration 98 of 100, loss = 0.00777859670081537   Iteration 99 of 100, loss = 0.0077569343201402165   Iteration 100 of 100, loss = 0.007837766723241657
   End of epoch 10; saving model... 

Epoch 11 of 2000
   Iteration 1 of 100, loss = 0.012403512373566628   Iteration 2 of 100, loss = 0.0102657750248909   Iteration 3 of 100, loss = 0.00857310788705945   Iteration 4 of 100, loss = 0.008537135901860893   Iteration 5 of 100, loss = 0.009893473517149688   Iteration 6 of 100, loss = 0.008863213976534704   Iteration 7 of 100, loss = 0.00874329574539193   Iteration 8 of 100, loss = 0.008681844134116545   Iteration 9 of 100, loss = 0.00852393620233569   Iteration 10 of 100, loss = 0.008904379443265498   Iteration 11 of 100, loss = 0.008727179226380858   Iteration 12 of 100, loss = 0.009117178056233874   Iteration 13 of 100, loss = 0.00916130573918613   Iteration 14 of 100, loss = 0.009239955522519137   Iteration 15 of 100, loss = 0.009066241653636098   Iteration 16 of 100, loss = 0.00881393467716407   Iteration 17 of 100, loss = 0.008535606526386212   Iteration 18 of 100, loss = 0.008691331850261323   Iteration 19 of 100, loss = 0.008716328768059611   Iteration 20 of 100, loss = 0.00899893428431824   Iteration 21 of 100, loss = 0.008867961143897403   Iteration 22 of 100, loss = 0.008693797122263773   Iteration 23 of 100, loss = 0.00859300580645061   Iteration 24 of 100, loss = 0.008547775709303096   Iteration 25 of 100, loss = 0.008487368384376168   Iteration 26 of 100, loss = 0.008338502348543933   Iteration 27 of 100, loss = 0.008393279544112307   Iteration 28 of 100, loss = 0.008290070499892213   Iteration 29 of 100, loss = 0.008224331669445181   Iteration 30 of 100, loss = 0.008665025661078593   Iteration 31 of 100, loss = 0.00869273901316187   Iteration 32 of 100, loss = 0.008509555962518789   Iteration 33 of 100, loss = 0.008525466899189985   Iteration 34 of 100, loss = 0.008373284808305256   Iteration 35 of 100, loss = 0.008374719973653555   Iteration 36 of 100, loss = 0.00839475771257033   Iteration 37 of 100, loss = 0.008338606828269927   Iteration 38 of 100, loss = 0.00825145992597467   Iteration 39 of 100, loss = 0.008199470463949136   Iteration 40 of 100, loss = 0.008221512718591839   Iteration 41 of 100, loss = 0.008229366537728688   Iteration 42 of 100, loss = 0.00828431831628439   Iteration 43 of 100, loss = 0.008273840676126786   Iteration 44 of 100, loss = 0.008316909227604892   Iteration 45 of 100, loss = 0.008253370660046737   Iteration 46 of 100, loss = 0.008280702198491148   Iteration 47 of 100, loss = 0.008152202594074164   Iteration 48 of 100, loss = 0.008050629742986834   Iteration 49 of 100, loss = 0.008152459453487275   Iteration 50 of 100, loss = 0.008234934164211154   Iteration 51 of 100, loss = 0.008236234907206952   Iteration 52 of 100, loss = 0.008257276262156665   Iteration 53 of 100, loss = 0.008304659198126141   Iteration 54 of 100, loss = 0.00834851074722354   Iteration 55 of 100, loss = 0.008353017380630429   Iteration 56 of 100, loss = 0.00829825724940747   Iteration 57 of 100, loss = 0.008228844211420469   Iteration 58 of 100, loss = 0.008228891673658428   Iteration 59 of 100, loss = 0.008250225256433931   Iteration 60 of 100, loss = 0.008369550853967667   Iteration 61 of 100, loss = 0.008335023935212463   Iteration 62 of 100, loss = 0.008260337369246107   Iteration 63 of 100, loss = 0.008211904756044821   Iteration 64 of 100, loss = 0.00829324590813485   Iteration 65 of 100, loss = 0.008235612486560757   Iteration 66 of 100, loss = 0.008236691077014037   Iteration 67 of 100, loss = 0.008252622910650141   Iteration 68 of 100, loss = 0.008223106348476209   Iteration 69 of 100, loss = 0.008220159978457335   Iteration 70 of 100, loss = 0.008163555056255843   Iteration 71 of 100, loss = 0.008147013560593339   Iteration 72 of 100, loss = 0.008184346386567794   Iteration 73 of 100, loss = 0.008189010896324499   Iteration 74 of 100, loss = 0.008170428512794143   Iteration 75 of 100, loss = 0.0081828102003783   Iteration 76 of 100, loss = 0.008188045268118577   Iteration 77 of 100, loss = 0.008180878666386782   Iteration 78 of 100, loss = 0.008178303636109026   Iteration 79 of 100, loss = 0.00817915190989741   Iteration 80 of 100, loss = 0.008192325601703488   Iteration 81 of 100, loss = 0.0081569241836989   Iteration 82 of 100, loss = 0.008149580839771504   Iteration 83 of 100, loss = 0.008147642378280142   Iteration 84 of 100, loss = 0.008173650111226985   Iteration 85 of 100, loss = 0.008198377547566506   Iteration 86 of 100, loss = 0.008166828834408418   Iteration 87 of 100, loss = 0.008181725813332817   Iteration 88 of 100, loss = 0.008167043902424419   Iteration 89 of 100, loss = 0.008151482866574706   Iteration 90 of 100, loss = 0.008129096887488332   Iteration 91 of 100, loss = 0.008145777536760811   Iteration 92 of 100, loss = 0.008121969833787854   Iteration 93 of 100, loss = 0.008156457382644857   Iteration 94 of 100, loss = 0.008128904209947808   Iteration 95 of 100, loss = 0.008094437378703764   Iteration 96 of 100, loss = 0.008071884539579818   Iteration 97 of 100, loss = 0.008060073948071636   Iteration 98 of 100, loss = 0.008048678579626187   Iteration 99 of 100, loss = 0.008020907863880497   Iteration 100 of 100, loss = 0.007991600173991174
   End of epoch 11; saving model... 

Epoch 12 of 2000
   Iteration 1 of 100, loss = 0.006709279026836157   Iteration 2 of 100, loss = 0.008072211174294353   Iteration 3 of 100, loss = 0.00903152534738183   Iteration 4 of 100, loss = 0.009499425417743623   Iteration 5 of 100, loss = 0.00902589811012149   Iteration 6 of 100, loss = 0.009135643563543757   Iteration 7 of 100, loss = 0.009152935086084264   Iteration 8 of 100, loss = 0.008927655755542219   Iteration 9 of 100, loss = 0.008655616082251072   Iteration 10 of 100, loss = 0.009120206627994776   Iteration 11 of 100, loss = 0.008846781555224548   Iteration 12 of 100, loss = 0.00863431894686073   Iteration 13 of 100, loss = 0.00845383802572122   Iteration 14 of 100, loss = 0.008177838121939982   Iteration 15 of 100, loss = 0.008188158925622701   Iteration 16 of 100, loss = 0.008288325770990923   Iteration 17 of 100, loss = 0.008301618700737463   Iteration 18 of 100, loss = 0.00828658310799963   Iteration 19 of 100, loss = 0.008286409055520045   Iteration 20 of 100, loss = 0.008147640526294709   Iteration 21 of 100, loss = 0.008013348272513775   Iteration 22 of 100, loss = 0.00785888212902302   Iteration 23 of 100, loss = 0.007759928440108248   Iteration 24 of 100, loss = 0.007642076505968968   Iteration 25 of 100, loss = 0.007468335852026939   Iteration 26 of 100, loss = 0.007532766053023247   Iteration 27 of 100, loss = 0.007571143788044099   Iteration 28 of 100, loss = 0.007496057793364993   Iteration 29 of 100, loss = 0.00741779923053651   Iteration 30 of 100, loss = 0.007385825521002213   Iteration 31 of 100, loss = 0.007475453428924084   Iteration 32 of 100, loss = 0.007812389900209382   Iteration 33 of 100, loss = 0.0077421237206594514   Iteration 34 of 100, loss = 0.007830045665340388   Iteration 35 of 100, loss = 0.007796487637928554   Iteration 36 of 100, loss = 0.007701053348783817   Iteration 37 of 100, loss = 0.00762718717089376   Iteration 38 of 100, loss = 0.007563001684550392   Iteration 39 of 100, loss = 0.00764133825372809   Iteration 40 of 100, loss = 0.0076711399597115815   Iteration 41 of 100, loss = 0.0078109042696291354   Iteration 42 of 100, loss = 0.007882691686972976   Iteration 43 of 100, loss = 0.007874643679188435   Iteration 44 of 100, loss = 0.00794225375549021   Iteration 45 of 100, loss = 0.007909439317882062   Iteration 46 of 100, loss = 0.007851722559122287   Iteration 47 of 100, loss = 0.00786014296550383   Iteration 48 of 100, loss = 0.007910014314499373   Iteration 49 of 100, loss = 0.007994951917884909   Iteration 50 of 100, loss = 0.007976184114813805   Iteration 51 of 100, loss = 0.00800124059120814   Iteration 52 of 100, loss = 0.008122066895549115   Iteration 53 of 100, loss = 0.008062851764613166   Iteration 54 of 100, loss = 0.007992384118821335   Iteration 55 of 100, loss = 0.008025766037065875   Iteration 56 of 100, loss = 0.008067679233915572   Iteration 57 of 100, loss = 0.008079190534261758   Iteration 58 of 100, loss = 0.008018466507502157   Iteration 59 of 100, loss = 0.008041638983571428   Iteration 60 of 100, loss = 0.008063977172908684   Iteration 61 of 100, loss = 0.007991314327466439   Iteration 62 of 100, loss = 0.007958903138886296   Iteration 63 of 100, loss = 0.008021242587664535   Iteration 64 of 100, loss = 0.00797863520347164   Iteration 65 of 100, loss = 0.007999438495160296   Iteration 66 of 100, loss = 0.007938048643568023   Iteration 67 of 100, loss = 0.007936101723045333   Iteration 68 of 100, loss = 0.007958785750601879   Iteration 69 of 100, loss = 0.007977117672967523   Iteration 70 of 100, loss = 0.007948055919925017   Iteration 71 of 100, loss = 0.007963243875206567   Iteration 72 of 100, loss = 0.007889175648516458   Iteration 73 of 100, loss = 0.007859829593169158   Iteration 74 of 100, loss = 0.007809337313488327   Iteration 75 of 100, loss = 0.007869780172283451   Iteration 76 of 100, loss = 0.007922508910077772   Iteration 77 of 100, loss = 0.007936057994480838   Iteration 78 of 100, loss = 0.007934702545380553   Iteration 79 of 100, loss = 0.007919123051452297   Iteration 80 of 100, loss = 0.00800551928987261   Iteration 81 of 100, loss = 0.008031889632413233   Iteration 82 of 100, loss = 0.008032678544135174   Iteration 83 of 100, loss = 0.007993219310911485   Iteration 84 of 100, loss = 0.007984249262205725   Iteration 85 of 100, loss = 0.007966077867347527   Iteration 86 of 100, loss = 0.007902877849288458   Iteration 87 of 100, loss = 0.007880742779408378   Iteration 88 of 100, loss = 0.007821346469096501   Iteration 89 of 100, loss = 0.007811276388637135   Iteration 90 of 100, loss = 0.00784788607723183   Iteration 91 of 100, loss = 0.007855899028152554   Iteration 92 of 100, loss = 0.007859692271069987   Iteration 93 of 100, loss = 0.007861840698908093   Iteration 94 of 100, loss = 0.007855114081200766   Iteration 95 of 100, loss = 0.007831432748782008   Iteration 96 of 100, loss = 0.007825762460318705   Iteration 97 of 100, loss = 0.007795453234815721   Iteration 98 of 100, loss = 0.007808517617154486   Iteration 99 of 100, loss = 0.007805168732172913   Iteration 100 of 100, loss = 0.007815921409055591
   End of epoch 12; saving model... 

Epoch 13 of 2000
   Iteration 1 of 100, loss = 0.008367033675312996   Iteration 2 of 100, loss = 0.006180006079375744   Iteration 3 of 100, loss = 0.007695609082778295   Iteration 4 of 100, loss = 0.00793320732191205   Iteration 5 of 100, loss = 0.007701919041574001   Iteration 6 of 100, loss = 0.008708719008912643   Iteration 7 of 100, loss = 0.008600539926971709   Iteration 8 of 100, loss = 0.008418213808909059   Iteration 9 of 100, loss = 0.00823279180460506   Iteration 10 of 100, loss = 0.007872544508427382   Iteration 11 of 100, loss = 0.0077627554366534405   Iteration 12 of 100, loss = 0.0077633373051260906   Iteration 13 of 100, loss = 0.0074973550553505235   Iteration 14 of 100, loss = 0.0076727440713771754   Iteration 15 of 100, loss = 0.007607407433291276   Iteration 16 of 100, loss = 0.007407969853375107   Iteration 17 of 100, loss = 0.007334359674988424   Iteration 18 of 100, loss = 0.007369865792699986   Iteration 19 of 100, loss = 0.007400202589403642   Iteration 20 of 100, loss = 0.00746386160608381   Iteration 21 of 100, loss = 0.007393221969583205   Iteration 22 of 100, loss = 0.0074608412105590105   Iteration 23 of 100, loss = 0.007320067723808082   Iteration 24 of 100, loss = 0.007580632848354678   Iteration 25 of 100, loss = 0.007565121613442898   Iteration 26 of 100, loss = 0.0076613109558820724   Iteration 27 of 100, loss = 0.00773693959194201   Iteration 28 of 100, loss = 0.00758919889007562   Iteration 29 of 100, loss = 0.00759273357207662   Iteration 30 of 100, loss = 0.007686279752912621   Iteration 31 of 100, loss = 0.007666911096161892   Iteration 32 of 100, loss = 0.007737579355307389   Iteration 33 of 100, loss = 0.0075994712992035075   Iteration 34 of 100, loss = 0.007633160655934583   Iteration 35 of 100, loss = 0.007642743490370256   Iteration 36 of 100, loss = 0.007695173165605714   Iteration 37 of 100, loss = 0.007633429177961237   Iteration 38 of 100, loss = 0.0075560184501993815   Iteration 39 of 100, loss = 0.007526752461368839   Iteration 40 of 100, loss = 0.00760501382756047   Iteration 41 of 100, loss = 0.007666950789848115   Iteration 42 of 100, loss = 0.007825829349236474   Iteration 43 of 100, loss = 0.007839261851988213   Iteration 44 of 100, loss = 0.007819148939399218   Iteration 45 of 100, loss = 0.007902843520666163   Iteration 46 of 100, loss = 0.007884477816886552   Iteration 47 of 100, loss = 0.00787040622449143   Iteration 48 of 100, loss = 0.007826466360711493   Iteration 49 of 100, loss = 0.007897015029032315   Iteration 50 of 100, loss = 0.00785122716333717   Iteration 51 of 100, loss = 0.007852281420948166   Iteration 52 of 100, loss = 0.007779088547417464   Iteration 53 of 100, loss = 0.0077184364595011155   Iteration 54 of 100, loss = 0.0076599262818625126   Iteration 55 of 100, loss = 0.007734598316760225   Iteration 56 of 100, loss = 0.0077152408152219975   Iteration 57 of 100, loss = 0.007670755232602619   Iteration 58 of 100, loss = 0.007636342643246311   Iteration 59 of 100, loss = 0.007589582910256113   Iteration 60 of 100, loss = 0.007520166082152476   Iteration 61 of 100, loss = 0.007508397625270682   Iteration 62 of 100, loss = 0.007514080772506854   Iteration 63 of 100, loss = 0.0075368870914514574   Iteration 64 of 100, loss = 0.007522674739448121   Iteration 65 of 100, loss = 0.007525387997380816   Iteration 66 of 100, loss = 0.007462368505498903   Iteration 67 of 100, loss = 0.0074413461895631765   Iteration 68 of 100, loss = 0.007381015898906352   Iteration 69 of 100, loss = 0.007351694402514377   Iteration 70 of 100, loss = 0.007345449541961508   Iteration 71 of 100, loss = 0.007345247203746522   Iteration 72 of 100, loss = 0.0073404487306510825   Iteration 73 of 100, loss = 0.007333432365693662   Iteration 74 of 100, loss = 0.007315188460681285   Iteration 75 of 100, loss = 0.007257786964376767   Iteration 76 of 100, loss = 0.007288844483953558   Iteration 77 of 100, loss = 0.007241844943446385   Iteration 78 of 100, loss = 0.0072552713696868755   Iteration 79 of 100, loss = 0.007450268362189019   Iteration 80 of 100, loss = 0.007479563349625096   Iteration 81 of 100, loss = 0.0074681728721860755   Iteration 82 of 100, loss = 0.007478952617952373   Iteration 83 of 100, loss = 0.007456810825156519   Iteration 84 of 100, loss = 0.007529043819799665   Iteration 85 of 100, loss = 0.007510434370487928   Iteration 86 of 100, loss = 0.007527296198531985   Iteration 87 of 100, loss = 0.007500425072108534   Iteration 88 of 100, loss = 0.007468091726133769   Iteration 89 of 100, loss = 0.007413102549322871   Iteration 90 of 100, loss = 0.0073809814587649375   Iteration 91 of 100, loss = 0.007357035952896535   Iteration 92 of 100, loss = 0.007361540398762926   Iteration 93 of 100, loss = 0.007408011123858472   Iteration 94 of 100, loss = 0.0074246797730472495   Iteration 95 of 100, loss = 0.007402389521073354   Iteration 96 of 100, loss = 0.007401062869272816   Iteration 97 of 100, loss = 0.007376850198608698   Iteration 98 of 100, loss = 0.007346574696997295   Iteration 99 of 100, loss = 0.0073337455308347035   Iteration 100 of 100, loss = 0.007287775189615786
   End of epoch 13; saving model... 

Epoch 14 of 2000
   Iteration 1 of 100, loss = 0.007168740965425968   Iteration 2 of 100, loss = 0.007444911869242787   Iteration 3 of 100, loss = 0.006479798816144466   Iteration 4 of 100, loss = 0.006021504756063223   Iteration 5 of 100, loss = 0.006634332053363323   Iteration 6 of 100, loss = 0.006655018776655197   Iteration 7 of 100, loss = 0.006314990775925773   Iteration 8 of 100, loss = 0.00740707665681839   Iteration 9 of 100, loss = 0.0077387384242481655   Iteration 10 of 100, loss = 0.007960765808820724   Iteration 11 of 100, loss = 0.007777007296681404   Iteration 12 of 100, loss = 0.007804296910762787   Iteration 13 of 100, loss = 0.007917019896782361   Iteration 14 of 100, loss = 0.007897834958774703   Iteration 15 of 100, loss = 0.007701520187159379   Iteration 16 of 100, loss = 0.007963488867972046   Iteration 17 of 100, loss = 0.007913460133268553   Iteration 18 of 100, loss = 0.0079539745218224   Iteration 19 of 100, loss = 0.008028130243091207   Iteration 20 of 100, loss = 0.008291267836466432   Iteration 21 of 100, loss = 0.008464607676225049   Iteration 22 of 100, loss = 0.008398788473145529   Iteration 23 of 100, loss = 0.00834084476303795   Iteration 24 of 100, loss = 0.008345604757778347   Iteration 25 of 100, loss = 0.008242903705686332   Iteration 26 of 100, loss = 0.008108736893448692   Iteration 27 of 100, loss = 0.008161640501822586   Iteration 28 of 100, loss = 0.008276072380665158   Iteration 29 of 100, loss = 0.008321963009777767   Iteration 30 of 100, loss = 0.00821956512518227   Iteration 31 of 100, loss = 0.008148119935104925   Iteration 32 of 100, loss = 0.008067209375440143   Iteration 33 of 100, loss = 0.008080360606651415   Iteration 34 of 100, loss = 0.008015723981182365   Iteration 35 of 100, loss = 0.00798119544716818   Iteration 36 of 100, loss = 0.007965218224045303   Iteration 37 of 100, loss = 0.00806150001448554   Iteration 38 of 100, loss = 0.008086822926998138   Iteration 39 of 100, loss = 0.008016845712868067   Iteration 40 of 100, loss = 0.007945587486028671   Iteration 41 of 100, loss = 0.007870541874137594   Iteration 42 of 100, loss = 0.007860636560335046   Iteration 43 of 100, loss = 0.007860259975978109   Iteration 44 of 100, loss = 0.007961735192855651   Iteration 45 of 100, loss = 0.00796798813260264   Iteration 46 of 100, loss = 0.00799397265781527   Iteration 47 of 100, loss = 0.007957738586404223   Iteration 48 of 100, loss = 0.007950764644192532   Iteration 49 of 100, loss = 0.008015663809694198   Iteration 50 of 100, loss = 0.008023595763370394   Iteration 51 of 100, loss = 0.00798183964455829   Iteration 52 of 100, loss = 0.0080146505139195   Iteration 53 of 100, loss = 0.007993351597830935   Iteration 54 of 100, loss = 0.007960064293540738   Iteration 55 of 100, loss = 0.00795406335964799   Iteration 56 of 100, loss = 0.007919321510209036   Iteration 57 of 100, loss = 0.007988416810372942   Iteration 58 of 100, loss = 0.007997546642055285   Iteration 59 of 100, loss = 0.007977041423762753   Iteration 60 of 100, loss = 0.00800878283722947   Iteration 61 of 100, loss = 0.008051024711706111   Iteration 62 of 100, loss = 0.008050867889617239   Iteration 63 of 100, loss = 0.008017922049417855   Iteration 64 of 100, loss = 0.00800110262207454   Iteration 65 of 100, loss = 0.008025201732436052   Iteration 66 of 100, loss = 0.007997721017366557   Iteration 67 of 100, loss = 0.008044101610612957   Iteration 68 of 100, loss = 0.007984055480098022   Iteration 69 of 100, loss = 0.007948207884918953   Iteration 70 of 100, loss = 0.007952414519552673   Iteration 71 of 100, loss = 0.00796533433694235   Iteration 72 of 100, loss = 0.007943289238028228   Iteration 73 of 100, loss = 0.007924918818912685   Iteration 74 of 100, loss = 0.00793039597998801   Iteration 75 of 100, loss = 0.007941932448496421   Iteration 76 of 100, loss = 0.00790288935930125   Iteration 77 of 100, loss = 0.007830071538178758   Iteration 78 of 100, loss = 0.00785180774386017   Iteration 79 of 100, loss = 0.007820869651564125   Iteration 80 of 100, loss = 0.007780976701178588   Iteration 81 of 100, loss = 0.007756947289669403   Iteration 82 of 100, loss = 0.0077579968819031266   Iteration 83 of 100, loss = 0.007751064871561276   Iteration 84 of 100, loss = 0.007779265479517302   Iteration 85 of 100, loss = 0.007776815824977615   Iteration 86 of 100, loss = 0.007774556188324336   Iteration 87 of 100, loss = 0.007763120567897099   Iteration 88 of 100, loss = 0.007759714178973809   Iteration 89 of 100, loss = 0.007764143406235603   Iteration 90 of 100, loss = 0.0077600997846780555   Iteration 91 of 100, loss = 0.007768300257029606   Iteration 92 of 100, loss = 0.0077771907545747644   Iteration 93 of 100, loss = 0.007793041554489924   Iteration 94 of 100, loss = 0.007808317388209732   Iteration 95 of 100, loss = 0.007786931305829632   Iteration 96 of 100, loss = 0.007780574672021127   Iteration 97 of 100, loss = 0.007747321483227857   Iteration 98 of 100, loss = 0.007744264088057894   Iteration 99 of 100, loss = 0.007732659533638695   Iteration 100 of 100, loss = 0.007760965835768729
   End of epoch 14; saving model... 

Epoch 15 of 2000
   Iteration 1 of 100, loss = 0.004110550042241812   Iteration 2 of 100, loss = 0.006561247399076819   Iteration 3 of 100, loss = 0.009177956885347763   Iteration 4 of 100, loss = 0.009510744479484856   Iteration 5 of 100, loss = 0.009353286307305097   Iteration 6 of 100, loss = 0.008614775026217103   Iteration 7 of 100, loss = 0.008403550500848464   Iteration 8 of 100, loss = 0.00850386923411861   Iteration 9 of 100, loss = 0.00792050876447724   Iteration 10 of 100, loss = 0.007749482407234609   Iteration 11 of 100, loss = 0.00752316976220093   Iteration 12 of 100, loss = 0.007504839314303051   Iteration 13 of 100, loss = 0.007840193539428024   Iteration 14 of 100, loss = 0.008024039561860263   Iteration 15 of 100, loss = 0.008138875182097157   Iteration 16 of 100, loss = 0.007924864490632899   Iteration 17 of 100, loss = 0.007754942580290577   Iteration 18 of 100, loss = 0.007768669644267195   Iteration 19 of 100, loss = 0.007694855173069395   Iteration 20 of 100, loss = 0.007669519924093038   Iteration 21 of 100, loss = 0.007874597540302645   Iteration 22 of 100, loss = 0.007709690189751034   Iteration 23 of 100, loss = 0.007777230520530239   Iteration 24 of 100, loss = 0.007649301502776022   Iteration 25 of 100, loss = 0.007508520307019353   Iteration 26 of 100, loss = 0.007458452789041285   Iteration 27 of 100, loss = 0.007419284648710379   Iteration 28 of 100, loss = 0.007355801686311939   Iteration 29 of 100, loss = 0.007365319259657428   Iteration 30 of 100, loss = 0.0073653268084550895   Iteration 31 of 100, loss = 0.007296642416246956   Iteration 32 of 100, loss = 0.00736668046010891   Iteration 33 of 100, loss = 0.007455095430045869   Iteration 34 of 100, loss = 0.0074346762164221964   Iteration 35 of 100, loss = 0.007544180198705622   Iteration 36 of 100, loss = 0.007524983795721912   Iteration 37 of 100, loss = 0.007531520488948838   Iteration 38 of 100, loss = 0.007589265416180224   Iteration 39 of 100, loss = 0.007581336405844643   Iteration 40 of 100, loss = 0.007582132244715467   Iteration 41 of 100, loss = 0.007545820477123304   Iteration 42 of 100, loss = 0.007641854712606541   Iteration 43 of 100, loss = 0.007632926913238195   Iteration 44 of 100, loss = 0.007619318250693719   Iteration 45 of 100, loss = 0.007558616276623474   Iteration 46 of 100, loss = 0.007498827899563248   Iteration 47 of 100, loss = 0.007481292440020975   Iteration 48 of 100, loss = 0.0075243353833987685   Iteration 49 of 100, loss = 0.007581961906648108   Iteration 50 of 100, loss = 0.007638152386061847   Iteration 51 of 100, loss = 0.007710340501302306   Iteration 52 of 100, loss = 0.007679829181422695   Iteration 53 of 100, loss = 0.007618725225153678   Iteration 54 of 100, loss = 0.0075844453380408666   Iteration 55 of 100, loss = 0.007610701316628944   Iteration 56 of 100, loss = 0.00757592571816141   Iteration 57 of 100, loss = 0.007564280880615115   Iteration 58 of 100, loss = 0.007585295006343773   Iteration 59 of 100, loss = 0.007591502058272392   Iteration 60 of 100, loss = 0.00753076501423493   Iteration 61 of 100, loss = 0.007482936808106596   Iteration 62 of 100, loss = 0.007506291205514102   Iteration 63 of 100, loss = 0.0074490162041333935   Iteration 64 of 100, loss = 0.007411145154037513   Iteration 65 of 100, loss = 0.007436937609544167   Iteration 66 of 100, loss = 0.007476326318062616   Iteration 67 of 100, loss = 0.007472241776925859   Iteration 68 of 100, loss = 0.007418446619447102   Iteration 69 of 100, loss = 0.007440205697186183   Iteration 70 of 100, loss = 0.007391329655157668   Iteration 71 of 100, loss = 0.00745640763304603   Iteration 72 of 100, loss = 0.007464829314914014   Iteration 73 of 100, loss = 0.007472336955674707   Iteration 74 of 100, loss = 0.007472129916218487   Iteration 75 of 100, loss = 0.007436135113239289   Iteration 76 of 100, loss = 0.007428516995308823   Iteration 77 of 100, loss = 0.007451705555975824   Iteration 78 of 100, loss = 0.0074501276935617896   Iteration 79 of 100, loss = 0.007432232988125916   Iteration 80 of 100, loss = 0.007408268906874582   Iteration 81 of 100, loss = 0.007524139506535398   Iteration 82 of 100, loss = 0.007533730331399455   Iteration 83 of 100, loss = 0.007592746679368149   Iteration 84 of 100, loss = 0.007641680067449454   Iteration 85 of 100, loss = 0.007636207577717655   Iteration 86 of 100, loss = 0.0076547267814275136   Iteration 87 of 100, loss = 0.0076336065981665565   Iteration 88 of 100, loss = 0.007606143343516372   Iteration 89 of 100, loss = 0.0076228592837794444   Iteration 90 of 100, loss = 0.007625223675535785   Iteration 91 of 100, loss = 0.007647381297179631   Iteration 92 of 100, loss = 0.0076610831361587925   Iteration 93 of 100, loss = 0.007678358114614922   Iteration 94 of 100, loss = 0.007687716021578997   Iteration 95 of 100, loss = 0.007698789376177286   Iteration 96 of 100, loss = 0.0077034891583025455   Iteration 97 of 100, loss = 0.007696988459522884   Iteration 98 of 100, loss = 0.00769406253452964   Iteration 99 of 100, loss = 0.007708813811680584   Iteration 100 of 100, loss = 0.0077166926255449655
   End of epoch 15; saving model... 

Epoch 16 of 2000
   Iteration 1 of 100, loss = 0.0044090826995670795   Iteration 2 of 100, loss = 0.004549085628241301   Iteration 3 of 100, loss = 0.005772624785701434   Iteration 4 of 100, loss = 0.005799105623736978   Iteration 5 of 100, loss = 0.0061558658257126805   Iteration 6 of 100, loss = 0.006113084964454174   Iteration 7 of 100, loss = 0.00686306187084743   Iteration 8 of 100, loss = 0.006609535135794431   Iteration 9 of 100, loss = 0.006813884454054965   Iteration 10 of 100, loss = 0.006522415718063712   Iteration 11 of 100, loss = 0.006628060840408911   Iteration 12 of 100, loss = 0.006772173607411484   Iteration 13 of 100, loss = 0.006856942012046392   Iteration 14 of 100, loss = 0.006757364275732211   Iteration 15 of 100, loss = 0.0067686767627795534   Iteration 16 of 100, loss = 0.006662768952082843   Iteration 17 of 100, loss = 0.0068558616125408344   Iteration 18 of 100, loss = 0.0065913627493298715   Iteration 19 of 100, loss = 0.006486262072269854   Iteration 20 of 100, loss = 0.006316137860994786   Iteration 21 of 100, loss = 0.00626807853889962   Iteration 22 of 100, loss = 0.006307470135983418   Iteration 23 of 100, loss = 0.006319259465469614   Iteration 24 of 100, loss = 0.006289068580372259   Iteration 25 of 100, loss = 0.006306834416463971   Iteration 26 of 100, loss = 0.006418047732530305   Iteration 27 of 100, loss = 0.006435274689768751   Iteration 28 of 100, loss = 0.006448816200385669   Iteration 29 of 100, loss = 0.0066831552760739776   Iteration 30 of 100, loss = 0.00679617995241036   Iteration 31 of 100, loss = 0.006780494597830599   Iteration 32 of 100, loss = 0.00682754455920076   Iteration 33 of 100, loss = 0.0067660822885844745   Iteration 34 of 100, loss = 0.006762468632694115   Iteration 35 of 100, loss = 0.006749978761321732   Iteration 36 of 100, loss = 0.006796213248485906   Iteration 37 of 100, loss = 0.006801721973445367   Iteration 38 of 100, loss = 0.006778595485038271   Iteration 39 of 100, loss = 0.006943903009717663   Iteration 40 of 100, loss = 0.0069482303399126975   Iteration 41 of 100, loss = 0.006938376515058846   Iteration 42 of 100, loss = 0.00690290984320676   Iteration 43 of 100, loss = 0.006893016674101006   Iteration 44 of 100, loss = 0.006859207626389848   Iteration 45 of 100, loss = 0.006828881132726868   Iteration 46 of 100, loss = 0.006886593263555804   Iteration 47 of 100, loss = 0.0069445513456346504   Iteration 48 of 100, loss = 0.006886676763921666   Iteration 49 of 100, loss = 0.006914426339790225   Iteration 50 of 100, loss = 0.006858724406920373   Iteration 51 of 100, loss = 0.006913178559283123   Iteration 52 of 100, loss = 0.0068883493659086525   Iteration 53 of 100, loss = 0.0069309068219911936   Iteration 54 of 100, loss = 0.0069854858340005635   Iteration 55 of 100, loss = 0.0070998620792207395   Iteration 56 of 100, loss = 0.00710205384945896   Iteration 57 of 100, loss = 0.007131743101860609   Iteration 58 of 100, loss = 0.007185635867464389   Iteration 59 of 100, loss = 0.0071411192993301965   Iteration 60 of 100, loss = 0.007143318136998763   Iteration 61 of 100, loss = 0.007120320355886074   Iteration 62 of 100, loss = 0.007099614993128325   Iteration 63 of 100, loss = 0.00704998604672414   Iteration 64 of 100, loss = 0.007012927922914969   Iteration 65 of 100, loss = 0.0069708881004212   Iteration 66 of 100, loss = 0.006995596947628214   Iteration 67 of 100, loss = 0.006983421913195235   Iteration 68 of 100, loss = 0.0070143963847145   Iteration 69 of 100, loss = 0.007042094920019525   Iteration 70 of 100, loss = 0.006985291718904461   Iteration 71 of 100, loss = 0.007003904136658554   Iteration 72 of 100, loss = 0.007024777665113409   Iteration 73 of 100, loss = 0.006989160214538035   Iteration 74 of 100, loss = 0.007027103722951299   Iteration 75 of 100, loss = 0.007046259809285403   Iteration 76 of 100, loss = 0.0070879031033990415   Iteration 77 of 100, loss = 0.0070706517254183815   Iteration 78 of 100, loss = 0.0070821447775532035   Iteration 79 of 100, loss = 0.007153616687636586   Iteration 80 of 100, loss = 0.007119227258954197   Iteration 81 of 100, loss = 0.007130966694266708   Iteration 82 of 100, loss = 0.007148593584666165   Iteration 83 of 100, loss = 0.007137586654399533   Iteration 84 of 100, loss = 0.007180270583679278   Iteration 85 of 100, loss = 0.007195947133004666   Iteration 86 of 100, loss = 0.0072229969921673454   Iteration 87 of 100, loss = 0.007209402701721109   Iteration 88 of 100, loss = 0.00720363599777391   Iteration 89 of 100, loss = 0.007189285700743118   Iteration 90 of 100, loss = 0.007178742200550106   Iteration 91 of 100, loss = 0.007159238287176077   Iteration 92 of 100, loss = 0.0071717023940594945   Iteration 93 of 100, loss = 0.007168726990580238   Iteration 94 of 100, loss = 0.007145437298025539   Iteration 95 of 100, loss = 0.007131180907354543   Iteration 96 of 100, loss = 0.007140452590344164   Iteration 97 of 100, loss = 0.00712194247651346   Iteration 98 of 100, loss = 0.007096528503283554   Iteration 99 of 100, loss = 0.007072018050221783   Iteration 100 of 100, loss = 0.007089027124457061
   End of epoch 16; saving model... 

Epoch 17 of 2000
   Iteration 1 of 100, loss = 0.011985408142209053   Iteration 2 of 100, loss = 0.009062957251444459   Iteration 3 of 100, loss = 0.00817110730955998   Iteration 4 of 100, loss = 0.008783608675003052   Iteration 5 of 100, loss = 0.008567942306399345   Iteration 6 of 100, loss = 0.008370921015739441   Iteration 7 of 100, loss = 0.008440755972904819   Iteration 8 of 100, loss = 0.008017749059945345   Iteration 9 of 100, loss = 0.008086789088944593   Iteration 10 of 100, loss = 0.007827450754120946   Iteration 11 of 100, loss = 0.007870354477993467   Iteration 12 of 100, loss = 0.007826756685972214   Iteration 13 of 100, loss = 0.007743691452420675   Iteration 14 of 100, loss = 0.007625925753797803   Iteration 15 of 100, loss = 0.007557738572359085   Iteration 16 of 100, loss = 0.0073701895016711205   Iteration 17 of 100, loss = 0.0072935195913647905   Iteration 18 of 100, loss = 0.007186023078651892   Iteration 19 of 100, loss = 0.007178610117223702   Iteration 20 of 100, loss = 0.007264752988703549   Iteration 21 of 100, loss = 0.007193104120060092   Iteration 22 of 100, loss = 0.007207395784048872   Iteration 23 of 100, loss = 0.007197019785804593   Iteration 24 of 100, loss = 0.0071634865016676486   Iteration 25 of 100, loss = 0.007096396200358868   Iteration 26 of 100, loss = 0.006981755463549724   Iteration 27 of 100, loss = 0.007036048987949336   Iteration 28 of 100, loss = 0.0069379426006759915   Iteration 29 of 100, loss = 0.00705170352011919   Iteration 30 of 100, loss = 0.007123669950912396   Iteration 31 of 100, loss = 0.007226020518329835   Iteration 32 of 100, loss = 0.007401273323921487   Iteration 33 of 100, loss = 0.007508073256097056   Iteration 34 of 100, loss = 0.007413954569903367   Iteration 35 of 100, loss = 0.007349188146846635   Iteration 36 of 100, loss = 0.007331801707752877   Iteration 37 of 100, loss = 0.007240860081101592   Iteration 38 of 100, loss = 0.007224023746522634   Iteration 39 of 100, loss = 0.007217724258318925   Iteration 40 of 100, loss = 0.007262706430628896   Iteration 41 of 100, loss = 0.007270040240411352   Iteration 42 of 100, loss = 0.007281459757082519   Iteration 43 of 100, loss = 0.007272113461134045   Iteration 44 of 100, loss = 0.007277929954315451   Iteration 45 of 100, loss = 0.007301536129994525   Iteration 46 of 100, loss = 0.007395210240603141   Iteration 47 of 100, loss = 0.007319084081323223   Iteration 48 of 100, loss = 0.007251908372078712   Iteration 49 of 100, loss = 0.007260093227865136   Iteration 50 of 100, loss = 0.007193582411855459   Iteration 51 of 100, loss = 0.007243745357674711   Iteration 52 of 100, loss = 0.007289700299644699   Iteration 53 of 100, loss = 0.007329356891788401   Iteration 54 of 100, loss = 0.007338175498363044   Iteration 55 of 100, loss = 0.007336525737561963   Iteration 56 of 100, loss = 0.007272311918703573   Iteration 57 of 100, loss = 0.007256407266188609   Iteration 58 of 100, loss = 0.00720504784539085   Iteration 59 of 100, loss = 0.007250025592176086   Iteration 60 of 100, loss = 0.007268200993227462   Iteration 61 of 100, loss = 0.007271769517635713   Iteration 62 of 100, loss = 0.007306051034961016   Iteration 63 of 100, loss = 0.007295670342587289   Iteration 64 of 100, loss = 0.007271603906701785   Iteration 65 of 100, loss = 0.0072626091110018585   Iteration 66 of 100, loss = 0.007292190467882337   Iteration 67 of 100, loss = 0.007232133577119058   Iteration 68 of 100, loss = 0.007204207625952275   Iteration 69 of 100, loss = 0.007188310475507076   Iteration 70 of 100, loss = 0.007129695100177612   Iteration 71 of 100, loss = 0.007238379817351069   Iteration 72 of 100, loss = 0.007308410422410816   Iteration 73 of 100, loss = 0.007363998784032995   Iteration 74 of 100, loss = 0.007360645097906928   Iteration 75 of 100, loss = 0.007326892005900542   Iteration 76 of 100, loss = 0.007292916385554953   Iteration 77 of 100, loss = 0.007362993942065673   Iteration 78 of 100, loss = 0.007432201578735541   Iteration 79 of 100, loss = 0.007412110213661873   Iteration 80 of 100, loss = 0.007396117877215147   Iteration 81 of 100, loss = 0.007354411629982936   Iteration 82 of 100, loss = 0.007359724071603723   Iteration 83 of 100, loss = 0.007341803332050163   Iteration 84 of 100, loss = 0.00742867749760903   Iteration 85 of 100, loss = 0.007463858375216232   Iteration 86 of 100, loss = 0.007444285094564737   Iteration 87 of 100, loss = 0.007410272789969184   Iteration 88 of 100, loss = 0.007452562075658617   Iteration 89 of 100, loss = 0.007436231207730395   Iteration 90 of 100, loss = 0.007423150684270594   Iteration 91 of 100, loss = 0.007422724539147956   Iteration 92 of 100, loss = 0.007423444843405615   Iteration 93 of 100, loss = 0.007457698535134075   Iteration 94 of 100, loss = 0.00751481400406424   Iteration 95 of 100, loss = 0.007486522315364135   Iteration 96 of 100, loss = 0.007512235334919144   Iteration 97 of 100, loss = 0.007495128439220879   Iteration 98 of 100, loss = 0.00746673945698659   Iteration 99 of 100, loss = 0.007479600170909455   Iteration 100 of 100, loss = 0.00747947403229773
   End of epoch 17; saving model... 

Epoch 18 of 2000
   Iteration 1 of 100, loss = 0.013023492880165577   Iteration 2 of 100, loss = 0.012057182379066944   Iteration 3 of 100, loss = 0.010974940843880177   Iteration 4 of 100, loss = 0.010346963070333004   Iteration 5 of 100, loss = 0.01053907312452793   Iteration 6 of 100, loss = 0.009216769482009113   Iteration 7 of 100, loss = 0.008736970934218593   Iteration 8 of 100, loss = 0.009584276675013825   Iteration 9 of 100, loss = 0.009156220307987597   Iteration 10 of 100, loss = 0.00884554146323353   Iteration 11 of 100, loss = 0.00832995660179718   Iteration 12 of 100, loss = 0.008177156346694877   Iteration 13 of 100, loss = 0.007970019440668134   Iteration 14 of 100, loss = 0.008191030588932335   Iteration 15 of 100, loss = 0.008286243847881755   Iteration 16 of 100, loss = 0.00811210558458697   Iteration 17 of 100, loss = 0.007988476454663803   Iteration 18 of 100, loss = 0.008187444764189422   Iteration 19 of 100, loss = 0.008310076474261126   Iteration 20 of 100, loss = 0.008171538158785551   Iteration 21 of 100, loss = 0.007943251236741031   Iteration 22 of 100, loss = 0.007961093257604674   Iteration 23 of 100, loss = 0.007981242875204138   Iteration 24 of 100, loss = 0.008153875649441034   Iteration 25 of 100, loss = 0.00803248856216669   Iteration 26 of 100, loss = 0.007876094681425737   Iteration 27 of 100, loss = 0.007683243947448554   Iteration 28 of 100, loss = 0.007619704103230366   Iteration 29 of 100, loss = 0.007675681375609389   Iteration 30 of 100, loss = 0.007926217854643862   Iteration 31 of 100, loss = 0.007914216392823765   Iteration 32 of 100, loss = 0.007968088451889344   Iteration 33 of 100, loss = 0.007895158533232681   Iteration 34 of 100, loss = 0.007908137775409748   Iteration 35 of 100, loss = 0.007884302588977984   Iteration 36 of 100, loss = 0.007788217574771907   Iteration 37 of 100, loss = 0.007701993630443876   Iteration 38 of 100, loss = 0.007685529349959995   Iteration 39 of 100, loss = 0.007706082581231992   Iteration 40 of 100, loss = 0.007656580500770361   Iteration 41 of 100, loss = 0.007640369656700187   Iteration 42 of 100, loss = 0.007744759044033431   Iteration 43 of 100, loss = 0.007726549116764651   Iteration 44 of 100, loss = 0.007662109385075217   Iteration 45 of 100, loss = 0.007714967336505651   Iteration 46 of 100, loss = 0.007634777666838921   Iteration 47 of 100, loss = 0.007674641520815327   Iteration 48 of 100, loss = 0.0076495297156119095   Iteration 49 of 100, loss = 0.007617020485352496   Iteration 50 of 100, loss = 0.007565137818455696   Iteration 51 of 100, loss = 0.0075814634671106055   Iteration 52 of 100, loss = 0.007566249150281342   Iteration 53 of 100, loss = 0.007584708540717948   Iteration 54 of 100, loss = 0.007557208908514844   Iteration 55 of 100, loss = 0.007572368583218618   Iteration 56 of 100, loss = 0.007522846330955092   Iteration 57 of 100, loss = 0.007475282155434813   Iteration 58 of 100, loss = 0.007419763429989588   Iteration 59 of 100, loss = 0.007386156160510697   Iteration 60 of 100, loss = 0.007427558916000028   Iteration 61 of 100, loss = 0.007350911142029723   Iteration 62 of 100, loss = 0.007332605422444401   Iteration 63 of 100, loss = 0.00732704960844583   Iteration 64 of 100, loss = 0.007349738407356199   Iteration 65 of 100, loss = 0.007334329653531313   Iteration 66 of 100, loss = 0.007300427733835849   Iteration 67 of 100, loss = 0.0072951429287221896   Iteration 68 of 100, loss = 0.007294665563248974   Iteration 69 of 100, loss = 0.0072924752476746625   Iteration 70 of 100, loss = 0.0072902887194816555   Iteration 71 of 100, loss = 0.0073373832110263095   Iteration 72 of 100, loss = 0.007349456498761558   Iteration 73 of 100, loss = 0.007369192106623764   Iteration 74 of 100, loss = 0.007400651393156196   Iteration 75 of 100, loss = 0.007368266545236111   Iteration 76 of 100, loss = 0.007388087859573333   Iteration 77 of 100, loss = 0.0074327289332430085   Iteration 78 of 100, loss = 0.007439546884061434   Iteration 79 of 100, loss = 0.007448155102850516   Iteration 80 of 100, loss = 0.007498449878767133   Iteration 81 of 100, loss = 0.007502517823911744   Iteration 82 of 100, loss = 0.007494630377239934   Iteration 83 of 100, loss = 0.007522573879729193   Iteration 84 of 100, loss = 0.007478508092130401   Iteration 85 of 100, loss = 0.007504896022488966   Iteration 86 of 100, loss = 0.00754685417564889   Iteration 87 of 100, loss = 0.007523947938655813   Iteration 88 of 100, loss = 0.0075434507479340855   Iteration 89 of 100, loss = 0.007540402303481203   Iteration 90 of 100, loss = 0.007555290722909073   Iteration 91 of 100, loss = 0.007574202715429467   Iteration 92 of 100, loss = 0.007626980641836543   Iteration 93 of 100, loss = 0.007658286428239237   Iteration 94 of 100, loss = 0.007634119801916816   Iteration 95 of 100, loss = 0.007616202888618175   Iteration 96 of 100, loss = 0.007644156394235324   Iteration 97 of 100, loss = 0.007593775854551608   Iteration 98 of 100, loss = 0.007593101280152189   Iteration 99 of 100, loss = 0.007618619872238299   Iteration 100 of 100, loss = 0.0075815089326351885
   End of epoch 18; saving model... 

Epoch 19 of 2000
   Iteration 1 of 100, loss = 0.005786264315247536   Iteration 2 of 100, loss = 0.005205696215853095   Iteration 3 of 100, loss = 0.00505510438233614   Iteration 4 of 100, loss = 0.005303285084664822   Iteration 5 of 100, loss = 0.0054031630977988245   Iteration 6 of 100, loss = 0.006501764835168918   Iteration 7 of 100, loss = 0.0065485165853585514   Iteration 8 of 100, loss = 0.006533218955155462   Iteration 9 of 100, loss = 0.007217222359031439   Iteration 10 of 100, loss = 0.007115042489022017   Iteration 11 of 100, loss = 0.006982130972160535   Iteration 12 of 100, loss = 0.006748314558838804   Iteration 13 of 100, loss = 0.00689491185431297   Iteration 14 of 100, loss = 0.006704399960913828   Iteration 15 of 100, loss = 0.006758433983971675   Iteration 16 of 100, loss = 0.00665452700923197   Iteration 17 of 100, loss = 0.006945650230216629   Iteration 18 of 100, loss = 0.006977105720175637   Iteration 19 of 100, loss = 0.007102825629868005   Iteration 20 of 100, loss = 0.0071087580174207686   Iteration 21 of 100, loss = 0.007231887651696091   Iteration 22 of 100, loss = 0.007101179968396371   Iteration 23 of 100, loss = 0.007083758489107308   Iteration 24 of 100, loss = 0.007137759608061363   Iteration 25 of 100, loss = 0.007117204647511244   Iteration 26 of 100, loss = 0.007030891254544258   Iteration 27 of 100, loss = 0.0071441323185960455   Iteration 28 of 100, loss = 0.00721550383605063   Iteration 29 of 100, loss = 0.007130706939717819   Iteration 30 of 100, loss = 0.007067279781525334   Iteration 31 of 100, loss = 0.007148718356244987   Iteration 32 of 100, loss = 0.0071304877928923815   Iteration 33 of 100, loss = 0.0069980181429083604   Iteration 34 of 100, loss = 0.006930032162927091   Iteration 35 of 100, loss = 0.006800988456234336   Iteration 36 of 100, loss = 0.006967757757390953   Iteration 37 of 100, loss = 0.006983849654175542   Iteration 38 of 100, loss = 0.006967928217674948   Iteration 39 of 100, loss = 0.006917230540122359   Iteration 40 of 100, loss = 0.0069887682038825005   Iteration 41 of 100, loss = 0.006905343673169249   Iteration 42 of 100, loss = 0.006965163291343266   Iteration 43 of 100, loss = 0.007114570582458793   Iteration 44 of 100, loss = 0.007076397014316171   Iteration 45 of 100, loss = 0.007125596727968918   Iteration 46 of 100, loss = 0.007130036054624487   Iteration 47 of 100, loss = 0.007062030941287571   Iteration 48 of 100, loss = 0.007085161036229692   Iteration 49 of 100, loss = 0.007010491198993155   Iteration 50 of 100, loss = 0.007011400577612221   Iteration 51 of 100, loss = 0.007010881775332724   Iteration 52 of 100, loss = 0.007011907215480908   Iteration 53 of 100, loss = 0.0069931696019715295   Iteration 54 of 100, loss = 0.007008499418454313   Iteration 55 of 100, loss = 0.007063674660060894   Iteration 56 of 100, loss = 0.007114350916318861   Iteration 57 of 100, loss = 0.007146182931600171   Iteration 58 of 100, loss = 0.007176613551564515   Iteration 59 of 100, loss = 0.007133838014235183   Iteration 60 of 100, loss = 0.007113520370330662   Iteration 61 of 100, loss = 0.007109700522736692   Iteration 62 of 100, loss = 0.0070867795955329655   Iteration 63 of 100, loss = 0.007082764107349609   Iteration 64 of 100, loss = 0.007061047483148286   Iteration 65 of 100, loss = 0.007018171763047576   Iteration 66 of 100, loss = 0.007006787077636655   Iteration 67 of 100, loss = 0.007059649331495166   Iteration 68 of 100, loss = 0.007082789797363255   Iteration 69 of 100, loss = 0.007054769741101325   Iteration 70 of 100, loss = 0.007110976836910205   Iteration 71 of 100, loss = 0.007077115151742605   Iteration 72 of 100, loss = 0.007042102059737469   Iteration 73 of 100, loss = 0.007023431261848301   Iteration 74 of 100, loss = 0.007002684076920756   Iteration 75 of 100, loss = 0.006990817086771131   Iteration 76 of 100, loss = 0.007027647026054757   Iteration 77 of 100, loss = 0.007102905769602625   Iteration 78 of 100, loss = 0.007139591795678895   Iteration 79 of 100, loss = 0.00712871626667867   Iteration 80 of 100, loss = 0.00722484483558219   Iteration 81 of 100, loss = 0.007266470596171272   Iteration 82 of 100, loss = 0.0072169986087828875   Iteration 83 of 100, loss = 0.007226482319858778   Iteration 84 of 100, loss = 0.007205837151213061   Iteration 85 of 100, loss = 0.00718619186869439   Iteration 86 of 100, loss = 0.007182959640441939   Iteration 87 of 100, loss = 0.007194537722944528   Iteration 88 of 100, loss = 0.007225328283807771   Iteration 89 of 100, loss = 0.007210235561380226   Iteration 90 of 100, loss = 0.007246588553405471   Iteration 91 of 100, loss = 0.007233996343399797   Iteration 92 of 100, loss = 0.0072402080784187365   Iteration 93 of 100, loss = 0.007266493233781989   Iteration 94 of 100, loss = 0.0072448109177515865   Iteration 95 of 100, loss = 0.007246747828627887   Iteration 96 of 100, loss = 0.0072552034398540854   Iteration 97 of 100, loss = 0.007242325160498779   Iteration 98 of 100, loss = 0.00725397035688618   Iteration 99 of 100, loss = 0.007281738723806962   Iteration 100 of 100, loss = 0.007303483593277633
   End of epoch 19; saving model... 

Epoch 20 of 2000
   Iteration 1 of 100, loss = 0.007478212006390095   Iteration 2 of 100, loss = 0.007607859559357166   Iteration 3 of 100, loss = 0.006877040180067222   Iteration 4 of 100, loss = 0.009517690865322948   Iteration 5 of 100, loss = 0.009444283694028855   Iteration 6 of 100, loss = 0.008720981189981103   Iteration 7 of 100, loss = 0.009119945378707988   Iteration 8 of 100, loss = 0.009237832331564277   Iteration 9 of 100, loss = 0.009395838145994477   Iteration 10 of 100, loss = 0.009163330495357513   Iteration 11 of 100, loss = 0.00897220458666032   Iteration 12 of 100, loss = 0.00872238865122199   Iteration 13 of 100, loss = 0.008804767106014948   Iteration 14 of 100, loss = 0.008678302534722857   Iteration 15 of 100, loss = 0.00841305007537206   Iteration 16 of 100, loss = 0.008316985942656174   Iteration 17 of 100, loss = 0.008562245762304348   Iteration 18 of 100, loss = 0.008536873411180245   Iteration 19 of 100, loss = 0.008296518880677851   Iteration 20 of 100, loss = 0.008056318550370634   Iteration 21 of 100, loss = 0.008091325849472057   Iteration 22 of 100, loss = 0.007978554561056873   Iteration 23 of 100, loss = 0.007840111892184486   Iteration 24 of 100, loss = 0.0077643124386668205   Iteration 25 of 100, loss = 0.007654471956193447   Iteration 26 of 100, loss = 0.007454575379737294   Iteration 27 of 100, loss = 0.007457027125551745   Iteration 28 of 100, loss = 0.0074319683481007814   Iteration 29 of 100, loss = 0.00732724574105493   Iteration 30 of 100, loss = 0.007275099338342746   Iteration 31 of 100, loss = 0.007286075247271407   Iteration 32 of 100, loss = 0.007308254382223822   Iteration 33 of 100, loss = 0.0072702757985980224   Iteration 34 of 100, loss = 0.007312830825171927   Iteration 35 of 100, loss = 0.007515199495745557   Iteration 36 of 100, loss = 0.007686673831712041   Iteration 37 of 100, loss = 0.007769900965630202   Iteration 38 of 100, loss = 0.007676544611489302   Iteration 39 of 100, loss = 0.007660507355840542   Iteration 40 of 100, loss = 0.007666869706008583   Iteration 41 of 100, loss = 0.007621488318119834   Iteration 42 of 100, loss = 0.007609909522302803   Iteration 43 of 100, loss = 0.007520898516008327   Iteration 44 of 100, loss = 0.00750555312895978   Iteration 45 of 100, loss = 0.007496923135800494   Iteration 46 of 100, loss = 0.007756891872976785   Iteration 47 of 100, loss = 0.007705782936450014   Iteration 48 of 100, loss = 0.007764737820252776   Iteration 49 of 100, loss = 0.007769311208049862   Iteration 50 of 100, loss = 0.0077738197892904285   Iteration 51 of 100, loss = 0.0077114244466464895   Iteration 52 of 100, loss = 0.007621216825030457   Iteration 53 of 100, loss = 0.007703748272450746   Iteration 54 of 100, loss = 0.0076520551660063645   Iteration 55 of 100, loss = 0.007649615470489318   Iteration 56 of 100, loss = 0.007592092854403225   Iteration 57 of 100, loss = 0.007665823691671616   Iteration 58 of 100, loss = 0.007616700664772813   Iteration 59 of 100, loss = 0.00756624112521314   Iteration 60 of 100, loss = 0.007576751107505212   Iteration 61 of 100, loss = 0.00750054290029602   Iteration 62 of 100, loss = 0.007446695569782487   Iteration 63 of 100, loss = 0.0074159093422903905   Iteration 64 of 100, loss = 0.0073498001584084705   Iteration 65 of 100, loss = 0.007370061241090298   Iteration 66 of 100, loss = 0.007353459894092697   Iteration 67 of 100, loss = 0.007328408179498876   Iteration 68 of 100, loss = 0.00730602873270126   Iteration 69 of 100, loss = 0.007302994853344517   Iteration 70 of 100, loss = 0.007292786832632763   Iteration 71 of 100, loss = 0.007382367547391586   Iteration 72 of 100, loss = 0.007350897047823916   Iteration 73 of 100, loss = 0.007331522392134552   Iteration 74 of 100, loss = 0.007314852023547566   Iteration 75 of 100, loss = 0.0072729164051512874   Iteration 76 of 100, loss = 0.007279196453868951   Iteration 77 of 100, loss = 0.007328590142310827   Iteration 78 of 100, loss = 0.0074109488035528324   Iteration 79 of 100, loss = 0.007469057795131886   Iteration 80 of 100, loss = 0.0074996511393692344   Iteration 81 of 100, loss = 0.0074494970203549775   Iteration 82 of 100, loss = 0.007492163638788752   Iteration 83 of 100, loss = 0.0075006517188915284   Iteration 84 of 100, loss = 0.007498169899918139   Iteration 85 of 100, loss = 0.0074960636303705325   Iteration 86 of 100, loss = 0.007476202677935362   Iteration 87 of 100, loss = 0.007473153784742643   Iteration 88 of 100, loss = 0.007485509082801978   Iteration 89 of 100, loss = 0.007495810785278511   Iteration 90 of 100, loss = 0.007466187172879776   Iteration 91 of 100, loss = 0.007452947210397694   Iteration 92 of 100, loss = 0.007479555894742193   Iteration 93 of 100, loss = 0.007468509828291272   Iteration 94 of 100, loss = 0.007476393906201454   Iteration 95 of 100, loss = 0.007473146145869243   Iteration 96 of 100, loss = 0.007451241748640314   Iteration 97 of 100, loss = 0.007490308504052383   Iteration 98 of 100, loss = 0.0075413099186000775   Iteration 99 of 100, loss = 0.007570614041102053   Iteration 100 of 100, loss = 0.007562001878395677
   End of epoch 20; saving model... 

Epoch 21 of 2000
   Iteration 1 of 100, loss = 0.006563819013535976   Iteration 2 of 100, loss = 0.006054755765944719   Iteration 3 of 100, loss = 0.00750767532736063   Iteration 4 of 100, loss = 0.007272215560078621   Iteration 5 of 100, loss = 0.007165668532252312   Iteration 6 of 100, loss = 0.008269060092667738   Iteration 7 of 100, loss = 0.008027000552309411   Iteration 8 of 100, loss = 0.008092844567727298   Iteration 9 of 100, loss = 0.008073064964264631   Iteration 10 of 100, loss = 0.008372381282970309   Iteration 11 of 100, loss = 0.008652197324078192   Iteration 12 of 100, loss = 0.008540608066444596   Iteration 13 of 100, loss = 0.008763986281477489   Iteration 14 of 100, loss = 0.008781993295997381   Iteration 15 of 100, loss = 0.008526919254412254   Iteration 16 of 100, loss = 0.008564114541513845   Iteration 17 of 100, loss = 0.008885442306671073   Iteration 18 of 100, loss = 0.00891774621171256   Iteration 19 of 100, loss = 0.008795308341321192   Iteration 20 of 100, loss = 0.008860746445134283   Iteration 21 of 100, loss = 0.008731958367640064   Iteration 22 of 100, loss = 0.008815852374854412   Iteration 23 of 100, loss = 0.008762756949695557   Iteration 24 of 100, loss = 0.008807128431120267   Iteration 25 of 100, loss = 0.008634744826704264   Iteration 26 of 100, loss = 0.008557475458544034   Iteration 27 of 100, loss = 0.008561479721080375   Iteration 28 of 100, loss = 0.00865623404804085   Iteration 29 of 100, loss = 0.008521662109756264   Iteration 30 of 100, loss = 0.008516224023575584   Iteration 31 of 100, loss = 0.008403415971946332   Iteration 32 of 100, loss = 0.008273984756669961   Iteration 33 of 100, loss = 0.008360995812285128   Iteration 34 of 100, loss = 0.008337603964130668   Iteration 35 of 100, loss = 0.00832720925765378   Iteration 36 of 100, loss = 0.008263188776456647   Iteration 37 of 100, loss = 0.008267541944577888   Iteration 38 of 100, loss = 0.008282087057044632   Iteration 39 of 100, loss = 0.008277795277535915   Iteration 40 of 100, loss = 0.008286972483620047   Iteration 41 of 100, loss = 0.008272940610967032   Iteration 42 of 100, loss = 0.008375479241034814   Iteration 43 of 100, loss = 0.008297017515572004   Iteration 44 of 100, loss = 0.008226923549293795   Iteration 45 of 100, loss = 0.008293757473842965   Iteration 46 of 100, loss = 0.008215881327329122   Iteration 47 of 100, loss = 0.008123930826030195   Iteration 48 of 100, loss = 0.008082454805844463   Iteration 49 of 100, loss = 0.008029586364686186   Iteration 50 of 100, loss = 0.00809378535952419   Iteration 51 of 100, loss = 0.008152537554612054   Iteration 52 of 100, loss = 0.008102925865946768   Iteration 53 of 100, loss = 0.008032176542570288   Iteration 54 of 100, loss = 0.00804809724515373   Iteration 55 of 100, loss = 0.008006146418946711   Iteration 56 of 100, loss = 0.0079730703520389   Iteration 57 of 100, loss = 0.007972622237151913   Iteration 58 of 100, loss = 0.008023646720363918   Iteration 59 of 100, loss = 0.00800295818549723   Iteration 60 of 100, loss = 0.007972634921316057   Iteration 61 of 100, loss = 0.00790342483974871   Iteration 62 of 100, loss = 0.00799478957008931   Iteration 63 of 100, loss = 0.007929676759337622   Iteration 64 of 100, loss = 0.007952986983582377   Iteration 65 of 100, loss = 0.008013023321445172   Iteration 66 of 100, loss = 0.007955960513120799   Iteration 67 of 100, loss = 0.007925043786083585   Iteration 68 of 100, loss = 0.007848202648079571   Iteration 69 of 100, loss = 0.007890537327182466   Iteration 70 of 100, loss = 0.007908999653799193   Iteration 71 of 100, loss = 0.007863840927750292   Iteration 72 of 100, loss = 0.007837360860624662   Iteration 73 of 100, loss = 0.007808253468869076   Iteration 74 of 100, loss = 0.007781420840655227   Iteration 75 of 100, loss = 0.007809532278527816   Iteration 76 of 100, loss = 0.007782959195442106   Iteration 77 of 100, loss = 0.007852104940004163   Iteration 78 of 100, loss = 0.007853894207913142   Iteration 79 of 100, loss = 0.007901239032043686   Iteration 80 of 100, loss = 0.007887701829895377   Iteration 81 of 100, loss = 0.007869009267722752   Iteration 82 of 100, loss = 0.007858985529576496   Iteration 83 of 100, loss = 0.007851747902536607   Iteration 84 of 100, loss = 0.007879820203275554   Iteration 85 of 100, loss = 0.007835507217575522   Iteration 86 of 100, loss = 0.007849103749491448   Iteration 87 of 100, loss = 0.007848594123604655   Iteration 88 of 100, loss = 0.00783568373563784   Iteration 89 of 100, loss = 0.007785664601879341   Iteration 90 of 100, loss = 0.0077676997183718614   Iteration 91 of 100, loss = 0.007768773430303394   Iteration 92 of 100, loss = 0.007736729141628451   Iteration 93 of 100, loss = 0.007738299044449964   Iteration 94 of 100, loss = 0.007815074817118968   Iteration 95 of 100, loss = 0.007798980786710193   Iteration 96 of 100, loss = 0.007802211264788639   Iteration 97 of 100, loss = 0.007806759099620059   Iteration 98 of 100, loss = 0.007833755948124644   Iteration 99 of 100, loss = 0.007820953974838962   Iteration 100 of 100, loss = 0.007836551314685494
   End of epoch 21; saving model... 

Epoch 22 of 2000
   Iteration 1 of 100, loss = 0.004627825226634741   Iteration 2 of 100, loss = 0.004948849556967616   Iteration 3 of 100, loss = 0.00477077920610706   Iteration 4 of 100, loss = 0.005605563637800515   Iteration 5 of 100, loss = 0.007113409880548716   Iteration 6 of 100, loss = 0.007214358930165569   Iteration 7 of 100, loss = 0.007079623306968382   Iteration 8 of 100, loss = 0.006893289741128683   Iteration 9 of 100, loss = 0.006997799293862449   Iteration 10 of 100, loss = 0.006636537797749043   Iteration 11 of 100, loss = 0.006970281712710857   Iteration 12 of 100, loss = 0.006763859962423642   Iteration 13 of 100, loss = 0.00691478169308259   Iteration 14 of 100, loss = 0.006729196956647294   Iteration 15 of 100, loss = 0.00660797959814469   Iteration 16 of 100, loss = 0.006456257397076115   Iteration 17 of 100, loss = 0.006393230739323532   Iteration 18 of 100, loss = 0.006342855773659216   Iteration 19 of 100, loss = 0.006519477054672806   Iteration 20 of 100, loss = 0.0064125294797122475   Iteration 21 of 100, loss = 0.006471032941980022   Iteration 22 of 100, loss = 0.006629138634624806   Iteration 23 of 100, loss = 0.00659054319333771   Iteration 24 of 100, loss = 0.006584207857182871   Iteration 25 of 100, loss = 0.006572801228612661   Iteration 26 of 100, loss = 0.006793515094054433   Iteration 27 of 100, loss = 0.006781280540895683   Iteration 28 of 100, loss = 0.006697749136947095   Iteration 29 of 100, loss = 0.006850863758731505   Iteration 30 of 100, loss = 0.006979598058387637   Iteration 31 of 100, loss = 0.006930787401694444   Iteration 32 of 100, loss = 0.007111622442607768   Iteration 33 of 100, loss = 0.007274864453145049   Iteration 34 of 100, loss = 0.007242025533581481   Iteration 35 of 100, loss = 0.007139753044715949   Iteration 36 of 100, loss = 0.0071669025087936055   Iteration 37 of 100, loss = 0.007183828139425935   Iteration 38 of 100, loss = 0.007338813432541333   Iteration 39 of 100, loss = 0.007318503868121367   Iteration 40 of 100, loss = 0.007512370962649584   Iteration 41 of 100, loss = 0.007492609969453841   Iteration 42 of 100, loss = 0.007489708706825262   Iteration 43 of 100, loss = 0.007523078980400812   Iteration 44 of 100, loss = 0.0075899648628282275   Iteration 45 of 100, loss = 0.0075783585819105305   Iteration 46 of 100, loss = 0.007554434918110137   Iteration 47 of 100, loss = 0.007555777137663136   Iteration 48 of 100, loss = 0.007532772957347333   Iteration 49 of 100, loss = 0.007473025328422688   Iteration 50 of 100, loss = 0.007535447748377919   Iteration 51 of 100, loss = 0.007535603162193415   Iteration 52 of 100, loss = 0.007608221852793717   Iteration 53 of 100, loss = 0.007613078576846505   Iteration 54 of 100, loss = 0.007598666379366208   Iteration 55 of 100, loss = 0.007734152073548599   Iteration 56 of 100, loss = 0.007759991891881717   Iteration 57 of 100, loss = 0.007782672376682361   Iteration 58 of 100, loss = 0.007749876481127636   Iteration 59 of 100, loss = 0.007772067206580255   Iteration 60 of 100, loss = 0.007815541505503157   Iteration 61 of 100, loss = 0.007826432959772036   Iteration 62 of 100, loss = 0.007752000541997052   Iteration 63 of 100, loss = 0.00769501311763648   Iteration 64 of 100, loss = 0.007777784128847998   Iteration 65 of 100, loss = 0.007758593100767869   Iteration 66 of 100, loss = 0.007700734912897601   Iteration 67 of 100, loss = 0.00764595618499304   Iteration 68 of 100, loss = 0.007640767527525039   Iteration 69 of 100, loss = 0.007626439026300458   Iteration 70 of 100, loss = 0.0076015163545629805   Iteration 71 of 100, loss = 0.0076130116292813296   Iteration 72 of 100, loss = 0.007600117701157514   Iteration 73 of 100, loss = 0.007612949001207335   Iteration 74 of 100, loss = 0.0076216131989919654   Iteration 75 of 100, loss = 0.007645690782616536   Iteration 76 of 100, loss = 0.0076174559868185925   Iteration 77 of 100, loss = 0.0076230235409910805   Iteration 78 of 100, loss = 0.007607666668123924   Iteration 79 of 100, loss = 0.00760568821614113   Iteration 80 of 100, loss = 0.007546002155868337   Iteration 81 of 100, loss = 0.007561986248388335   Iteration 82 of 100, loss = 0.007604913939381155   Iteration 83 of 100, loss = 0.007586512434105557   Iteration 84 of 100, loss = 0.00759311250987507   Iteration 85 of 100, loss = 0.007548838032080847   Iteration 86 of 100, loss = 0.0075477871794773395   Iteration 87 of 100, loss = 0.0075500190482828125   Iteration 88 of 100, loss = 0.007563268019690771   Iteration 89 of 100, loss = 0.007583708382012804   Iteration 90 of 100, loss = 0.007601073503287302   Iteration 91 of 100, loss = 0.007576905165358886   Iteration 92 of 100, loss = 0.0075612688163781295   Iteration 93 of 100, loss = 0.007577397094498719   Iteration 94 of 100, loss = 0.007553186852167895   Iteration 95 of 100, loss = 0.0076068734358015816   Iteration 96 of 100, loss = 0.007575919225928374   Iteration 97 of 100, loss = 0.007614337431132486   Iteration 98 of 100, loss = 0.007610614701383272   Iteration 99 of 100, loss = 0.0076070003108017975   Iteration 100 of 100, loss = 0.0075631943182088435
   End of epoch 22; saving model... 

Epoch 23 of 2000
   Iteration 1 of 100, loss = 0.014103228226304054   Iteration 2 of 100, loss = 0.011073104105889797   Iteration 3 of 100, loss = 0.010055415642758211   Iteration 4 of 100, loss = 0.011079402174800634   Iteration 5 of 100, loss = 0.009870944358408452   Iteration 6 of 100, loss = 0.009317457598323623   Iteration 7 of 100, loss = 0.008841120039245911   Iteration 8 of 100, loss = 0.008498536015395075   Iteration 9 of 100, loss = 0.008252856321632862   Iteration 10 of 100, loss = 0.008319533336907626   Iteration 11 of 100, loss = 0.008178999393501064   Iteration 12 of 100, loss = 0.008052817972687384   Iteration 13 of 100, loss = 0.007860556853791842   Iteration 14 of 100, loss = 0.007848870341799088   Iteration 15 of 100, loss = 0.007904969217876593   Iteration 16 of 100, loss = 0.007683675270527601   Iteration 17 of 100, loss = 0.007686281138483216   Iteration 18 of 100, loss = 0.007380407445857095   Iteration 19 of 100, loss = 0.007451492055368267   Iteration 20 of 100, loss = 0.007255861896555871   Iteration 21 of 100, loss = 0.007215196166985801   Iteration 22 of 100, loss = 0.00737839326558804   Iteration 23 of 100, loss = 0.007470106857869288   Iteration 24 of 100, loss = 0.007443769747624174   Iteration 25 of 100, loss = 0.007347186310216785   Iteration 26 of 100, loss = 0.007376327815179069   Iteration 27 of 100, loss = 0.007479136111214757   Iteration 28 of 100, loss = 0.007573382222160164   Iteration 29 of 100, loss = 0.007604367091673715   Iteration 30 of 100, loss = 0.007658102821248273   Iteration 31 of 100, loss = 0.007795943810995068   Iteration 32 of 100, loss = 0.007698492285271641   Iteration 33 of 100, loss = 0.007571757058471892   Iteration 34 of 100, loss = 0.007520648602889303   Iteration 35 of 100, loss = 0.0074870933712060965   Iteration 36 of 100, loss = 0.0075381910234379275   Iteration 37 of 100, loss = 0.007561566389946116   Iteration 38 of 100, loss = 0.007489862196196459   Iteration 39 of 100, loss = 0.007505136476352046   Iteration 40 of 100, loss = 0.007489485194673762   Iteration 41 of 100, loss = 0.007602744116788593   Iteration 42 of 100, loss = 0.007599863306885319   Iteration 43 of 100, loss = 0.007651264947124346   Iteration 44 of 100, loss = 0.007659927703736519   Iteration 45 of 100, loss = 0.00757622972337736   Iteration 46 of 100, loss = 0.0075775193981826305   Iteration 47 of 100, loss = 0.007649979435224483   Iteration 48 of 100, loss = 0.007722596366268893   Iteration 49 of 100, loss = 0.007650160990959528   Iteration 50 of 100, loss = 0.007635521795600652   Iteration 51 of 100, loss = 0.007638434605563388   Iteration 52 of 100, loss = 0.007583842147141695   Iteration 53 of 100, loss = 0.007631796201304445   Iteration 54 of 100, loss = 0.007621858708767427   Iteration 55 of 100, loss = 0.007639154173772443   Iteration 56 of 100, loss = 0.007633275701664388   Iteration 57 of 100, loss = 0.007577118627204184   Iteration 58 of 100, loss = 0.007676489619088584   Iteration 59 of 100, loss = 0.007688544595898208   Iteration 60 of 100, loss = 0.0076258594558263814   Iteration 61 of 100, loss = 0.007657744059125419   Iteration 62 of 100, loss = 0.007669890036566123   Iteration 63 of 100, loss = 0.007666339935173118   Iteration 64 of 100, loss = 0.007603333298902726   Iteration 65 of 100, loss = 0.007527825057220001   Iteration 66 of 100, loss = 0.007539052241058512   Iteration 67 of 100, loss = 0.007525331222577326   Iteration 68 of 100, loss = 0.007533880067057908   Iteration 69 of 100, loss = 0.0075390796662996645   Iteration 70 of 100, loss = 0.0075424258198056905   Iteration 71 of 100, loss = 0.007555372763792394   Iteration 72 of 100, loss = 0.0075105523574166   Iteration 73 of 100, loss = 0.0074447214201552   Iteration 74 of 100, loss = 0.007473220561026923   Iteration 75 of 100, loss = 0.007477741219724218   Iteration 76 of 100, loss = 0.007411244015920123   Iteration 77 of 100, loss = 0.007399596162019418   Iteration 78 of 100, loss = 0.007449154512216456   Iteration 79 of 100, loss = 0.007499305693479844   Iteration 80 of 100, loss = 0.007492368054226972   Iteration 81 of 100, loss = 0.007459376636823571   Iteration 82 of 100, loss = 0.007443037982916505   Iteration 83 of 100, loss = 0.007459654391417841   Iteration 84 of 100, loss = 0.007431477870947371   Iteration 85 of 100, loss = 0.00743932466241805   Iteration 86 of 100, loss = 0.00740941017487108   Iteration 87 of 100, loss = 0.007392894281288502   Iteration 88 of 100, loss = 0.0073726379698862065   Iteration 89 of 100, loss = 0.007353180132576086   Iteration 90 of 100, loss = 0.007416039552643068   Iteration 91 of 100, loss = 0.007418995756389839   Iteration 92 of 100, loss = 0.007386569351302055   Iteration 93 of 100, loss = 0.0073818365757864325   Iteration 94 of 100, loss = 0.007392822856460005   Iteration 95 of 100, loss = 0.00740272382421321   Iteration 96 of 100, loss = 0.0073723588066059165   Iteration 97 of 100, loss = 0.007426266272830748   Iteration 98 of 100, loss = 0.007405122896485335   Iteration 99 of 100, loss = 0.007386125631235314   Iteration 100 of 100, loss = 0.007410093748476356
   End of epoch 23; saving model... 

Epoch 24 of 2000
   Iteration 1 of 100, loss = 0.008175543509423733   Iteration 2 of 100, loss = 0.007973227417096496   Iteration 3 of 100, loss = 0.007367292419075966   Iteration 4 of 100, loss = 0.007669171318411827   Iteration 5 of 100, loss = 0.008193219266831874   Iteration 6 of 100, loss = 0.008138029836118221   Iteration 7 of 100, loss = 0.007942226715385914   Iteration 8 of 100, loss = 0.007610842643771321   Iteration 9 of 100, loss = 0.007166588860046532   Iteration 10 of 100, loss = 0.007447870052419603   Iteration 11 of 100, loss = 0.00735454517416656   Iteration 12 of 100, loss = 0.007105991069693118   Iteration 13 of 100, loss = 0.006991696311160922   Iteration 14 of 100, loss = 0.006803270246434424   Iteration 15 of 100, loss = 0.0071329528000205755   Iteration 16 of 100, loss = 0.006938280494068749   Iteration 17 of 100, loss = 0.007312877665219062   Iteration 18 of 100, loss = 0.007203824675848914   Iteration 19 of 100, loss = 0.007283166259233104   Iteration 20 of 100, loss = 0.007166689692530781   Iteration 21 of 100, loss = 0.007237798279328715   Iteration 22 of 100, loss = 0.007323396233418448   Iteration 23 of 100, loss = 0.00719089788870643   Iteration 24 of 100, loss = 0.0072201106522697955   Iteration 25 of 100, loss = 0.007126853512600065   Iteration 26 of 100, loss = 0.007032545578952592   Iteration 27 of 100, loss = 0.0070565728108502096   Iteration 28 of 100, loss = 0.007125809713865497   Iteration 29 of 100, loss = 0.0071716995123003065   Iteration 30 of 100, loss = 0.007075382730302711   Iteration 31 of 100, loss = 0.007166437857273606   Iteration 32 of 100, loss = 0.007153758757340256   Iteration 33 of 100, loss = 0.007184400738245158   Iteration 34 of 100, loss = 0.007089419201399912   Iteration 35 of 100, loss = 0.007125085479180728   Iteration 36 of 100, loss = 0.007051243479104919   Iteration 37 of 100, loss = 0.006976424194117253   Iteration 38 of 100, loss = 0.00695242436823288   Iteration 39 of 100, loss = 0.006989943585955562   Iteration 40 of 100, loss = 0.0068884929933119565   Iteration 41 of 100, loss = 0.006869348135163508   Iteration 42 of 100, loss = 0.006952066312632745   Iteration 43 of 100, loss = 0.006921851471456331   Iteration 44 of 100, loss = 0.0069655092613009565   Iteration 45 of 100, loss = 0.00695499442000356   Iteration 46 of 100, loss = 0.006997297978555055   Iteration 47 of 100, loss = 0.006986363885052344   Iteration 48 of 100, loss = 0.007039134773852614   Iteration 49 of 100, loss = 0.007022445836123459   Iteration 50 of 100, loss = 0.006999965938739479   Iteration 51 of 100, loss = 0.006978149493864062   Iteration 52 of 100, loss = 0.007107657546070046   Iteration 53 of 100, loss = 0.007130728705065712   Iteration 54 of 100, loss = 0.007129808116048851   Iteration 55 of 100, loss = 0.007157053362408823   Iteration 56 of 100, loss = 0.007181611348642036   Iteration 57 of 100, loss = 0.007199758912943173   Iteration 58 of 100, loss = 0.007266977821990591   Iteration 59 of 100, loss = 0.007282407926711238   Iteration 60 of 100, loss = 0.007274650537874549   Iteration 61 of 100, loss = 0.007355195473971181   Iteration 62 of 100, loss = 0.007385708485549736   Iteration 63 of 100, loss = 0.007363959810593062   Iteration 64 of 100, loss = 0.0074038777565874625   Iteration 65 of 100, loss = 0.007395386147814301   Iteration 66 of 100, loss = 0.007354677086837139   Iteration 67 of 100, loss = 0.00734122938810111   Iteration 68 of 100, loss = 0.007353058156749124   Iteration 69 of 100, loss = 0.0073488842108813315   Iteration 70 of 100, loss = 0.007399898118871664   Iteration 71 of 100, loss = 0.0073865555508823046   Iteration 72 of 100, loss = 0.0074085583748658085   Iteration 73 of 100, loss = 0.0074150490427823505   Iteration 74 of 100, loss = 0.00736702757421881   Iteration 75 of 100, loss = 0.007325056465342641   Iteration 76 of 100, loss = 0.0073231572965405094   Iteration 77 of 100, loss = 0.007328986737562658   Iteration 78 of 100, loss = 0.0072804146016446445   Iteration 79 of 100, loss = 0.007316028581389898   Iteration 80 of 100, loss = 0.007313411857467145   Iteration 81 of 100, loss = 0.007280371611776911   Iteration 82 of 100, loss = 0.007249323918097993   Iteration 83 of 100, loss = 0.007247816389763212   Iteration 84 of 100, loss = 0.0072569036967165415   Iteration 85 of 100, loss = 0.007214244690668933   Iteration 86 of 100, loss = 0.007215280275315393   Iteration 87 of 100, loss = 0.007191600925663765   Iteration 88 of 100, loss = 0.007181394427210431   Iteration 89 of 100, loss = 0.0071942482635462554   Iteration 90 of 100, loss = 0.007193953647381729   Iteration 91 of 100, loss = 0.007229078325678359   Iteration 92 of 100, loss = 0.007186447657422041   Iteration 93 of 100, loss = 0.00716513381039183   Iteration 94 of 100, loss = 0.00712628440406332   Iteration 95 of 100, loss = 0.007110756613608254   Iteration 96 of 100, loss = 0.007252679844289863   Iteration 97 of 100, loss = 0.007298567550756114   Iteration 98 of 100, loss = 0.007323853365069598   Iteration 99 of 100, loss = 0.007313882214760389   Iteration 100 of 100, loss = 0.007366229284089059
   End of epoch 24; saving model... 

Epoch 25 of 2000
   Iteration 1 of 100, loss = 0.006185293197631836   Iteration 2 of 100, loss = 0.0063473444897681475   Iteration 3 of 100, loss = 0.007222986624886592   Iteration 4 of 100, loss = 0.006701169069856405   Iteration 5 of 100, loss = 0.0069249775260686874   Iteration 6 of 100, loss = 0.007148496496180694   Iteration 7 of 100, loss = 0.007037187261240823   Iteration 8 of 100, loss = 0.006719575903844088   Iteration 9 of 100, loss = 0.006467347654203574   Iteration 10 of 100, loss = 0.006280975649133325   Iteration 11 of 100, loss = 0.006016338138248433   Iteration 12 of 100, loss = 0.006022947588159393   Iteration 13 of 100, loss = 0.0065465133028248185   Iteration 14 of 100, loss = 0.006779352119857711   Iteration 15 of 100, loss = 0.006642991692448656   Iteration 16 of 100, loss = 0.006710828994982876   Iteration 17 of 100, loss = 0.006678078309906756   Iteration 18 of 100, loss = 0.0068294614320620894   Iteration 19 of 100, loss = 0.006862002829285829   Iteration 20 of 100, loss = 0.00685466491850093   Iteration 21 of 100, loss = 0.006874076678373274   Iteration 22 of 100, loss = 0.0067697480342096905   Iteration 23 of 100, loss = 0.007027553080621621   Iteration 24 of 100, loss = 0.007115216586195554   Iteration 25 of 100, loss = 0.007122672973200679   Iteration 26 of 100, loss = 0.007114890971794152   Iteration 27 of 100, loss = 0.007024415811799743   Iteration 28 of 100, loss = 0.007133367413189262   Iteration 29 of 100, loss = 0.0072266081235660565   Iteration 30 of 100, loss = 0.00718346678186208   Iteration 31 of 100, loss = 0.007187531292138081   Iteration 32 of 100, loss = 0.007325708334974479   Iteration 33 of 100, loss = 0.0074210356793959036   Iteration 34 of 100, loss = 0.007548124495181529   Iteration 35 of 100, loss = 0.007619397308943527   Iteration 36 of 100, loss = 0.007539383982980831   Iteration 37 of 100, loss = 0.0076154580125836905   Iteration 38 of 100, loss = 0.00763353165606723   Iteration 39 of 100, loss = 0.007622350299826417   Iteration 40 of 100, loss = 0.007571275479858741   Iteration 41 of 100, loss = 0.007585751205092159   Iteration 42 of 100, loss = 0.007694637973881548   Iteration 43 of 100, loss = 0.007605954885569422   Iteration 44 of 100, loss = 0.0076711605705151505   Iteration 45 of 100, loss = 0.00769433051140772   Iteration 46 of 100, loss = 0.00771936613297009   Iteration 47 of 100, loss = 0.007736844714096886   Iteration 48 of 100, loss = 0.007704215133950735   Iteration 49 of 100, loss = 0.007649858501188609   Iteration 50 of 100, loss = 0.00771145399659872   Iteration 51 of 100, loss = 0.007736736762465215   Iteration 52 of 100, loss = 0.007820915538244523   Iteration 53 of 100, loss = 0.007746179579352995   Iteration 54 of 100, loss = 0.007726027785489957   Iteration 55 of 100, loss = 0.007672288556667892   Iteration 56 of 100, loss = 0.007615970622282475   Iteration 57 of 100, loss = 0.007609977395061338   Iteration 58 of 100, loss = 0.007547842202194292   Iteration 59 of 100, loss = 0.007545117036265842   Iteration 60 of 100, loss = 0.007511282238798837   Iteration 61 of 100, loss = 0.007509310653463739   Iteration 62 of 100, loss = 0.007474946541591517   Iteration 63 of 100, loss = 0.00744796780100654   Iteration 64 of 100, loss = 0.007422072550980374   Iteration 65 of 100, loss = 0.0074131426114875535   Iteration 66 of 100, loss = 0.007370538339301041   Iteration 67 of 100, loss = 0.007300253060938262   Iteration 68 of 100, loss = 0.007330310304977876   Iteration 69 of 100, loss = 0.0073435424044188385   Iteration 70 of 100, loss = 0.007414864861805524   Iteration 71 of 100, loss = 0.007440128501399722   Iteration 72 of 100, loss = 0.007421605580020696   Iteration 73 of 100, loss = 0.007469072382999201   Iteration 74 of 100, loss = 0.0074028556228841885   Iteration 75 of 100, loss = 0.007432336816564202   Iteration 76 of 100, loss = 0.00741633172698417   Iteration 77 of 100, loss = 0.007397938438074349   Iteration 78 of 100, loss = 0.0074492745871584005   Iteration 79 of 100, loss = 0.0074930527524527495   Iteration 80 of 100, loss = 0.007458175273495726   Iteration 81 of 100, loss = 0.007443310598049451   Iteration 82 of 100, loss = 0.007395449827039023   Iteration 83 of 100, loss = 0.007394391280340861   Iteration 84 of 100, loss = 0.00738627625451911   Iteration 85 of 100, loss = 0.007371372844585601   Iteration 86 of 100, loss = 0.0073661845513121335   Iteration 87 of 100, loss = 0.007399330659630312   Iteration 88 of 100, loss = 0.0073968750498765575   Iteration 89 of 100, loss = 0.007411070822037003   Iteration 90 of 100, loss = 0.007382193207740783   Iteration 91 of 100, loss = 0.007438994851986786   Iteration 92 of 100, loss = 0.007406558056928865   Iteration 93 of 100, loss = 0.007377951360878444   Iteration 94 of 100, loss = 0.007393313626303   Iteration 95 of 100, loss = 0.00737629935243412   Iteration 96 of 100, loss = 0.007364383864720973   Iteration 97 of 100, loss = 0.00739100763151787   Iteration 98 of 100, loss = 0.0073695861762959735   Iteration 99 of 100, loss = 0.007368506049981924   Iteration 100 of 100, loss = 0.0073521186131983995
   End of epoch 25; saving model... 

Epoch 26 of 2000
   Iteration 1 of 100, loss = 0.007569674868136644   Iteration 2 of 100, loss = 0.010070523479953408   Iteration 3 of 100, loss = 0.008154889879127344   Iteration 4 of 100, loss = 0.007336664712056518   Iteration 5 of 100, loss = 0.007167340535670519   Iteration 6 of 100, loss = 0.0066706900640080375   Iteration 7 of 100, loss = 0.0068367346456008294   Iteration 8 of 100, loss = 0.006449937121942639   Iteration 9 of 100, loss = 0.006192859934849871   Iteration 10 of 100, loss = 0.006406662939116359   Iteration 11 of 100, loss = 0.006229417567903345   Iteration 12 of 100, loss = 0.0062083467685927944   Iteration 13 of 100, loss = 0.006453228827852469   Iteration 14 of 100, loss = 0.006825936226440328   Iteration 15 of 100, loss = 0.006829397566616535   Iteration 16 of 100, loss = 0.00666614796500653   Iteration 17 of 100, loss = 0.00704462146934341   Iteration 18 of 100, loss = 0.006882162635318107   Iteration 19 of 100, loss = 0.006908525982381482   Iteration 20 of 100, loss = 0.006790283625014127   Iteration 21 of 100, loss = 0.006757080754531282   Iteration 22 of 100, loss = 0.0066079773876646705   Iteration 23 of 100, loss = 0.0064650865615871935   Iteration 24 of 100, loss = 0.006624353865239148   Iteration 25 of 100, loss = 0.006479312656447292   Iteration 26 of 100, loss = 0.00658089870837732   Iteration 27 of 100, loss = 0.006839651502323923   Iteration 28 of 100, loss = 0.006745365556396011   Iteration 29 of 100, loss = 0.006632456620191705   Iteration 30 of 100, loss = 0.006736740563064813   Iteration 31 of 100, loss = 0.006749416536260997   Iteration 32 of 100, loss = 0.006773694418370724   Iteration 33 of 100, loss = 0.006793468343940648   Iteration 34 of 100, loss = 0.0068897649864940085   Iteration 35 of 100, loss = 0.006975836173764297   Iteration 36 of 100, loss = 0.006959871440711949   Iteration 37 of 100, loss = 0.00699456111603492   Iteration 38 of 100, loss = 0.006888346256394135   Iteration 39 of 100, loss = 0.006835835806738872   Iteration 40 of 100, loss = 0.006769276619888842   Iteration 41 of 100, loss = 0.006728943187470843   Iteration 42 of 100, loss = 0.006822382077752124   Iteration 43 of 100, loss = 0.006834059433881627   Iteration 44 of 100, loss = 0.00680239932526919   Iteration 45 of 100, loss = 0.006808007922437456   Iteration 46 of 100, loss = 0.006785257172811291   Iteration 47 of 100, loss = 0.006767116487026215   Iteration 48 of 100, loss = 0.006706476832429568   Iteration 49 of 100, loss = 0.006671061786841981   Iteration 50 of 100, loss = 0.00663502567447722   Iteration 51 of 100, loss = 0.006605378899942426   Iteration 52 of 100, loss = 0.006673701429882875   Iteration 53 of 100, loss = 0.006683669430818761   Iteration 54 of 100, loss = 0.00664630847879582   Iteration 55 of 100, loss = 0.006614224502647465   Iteration 56 of 100, loss = 0.006649540928525052   Iteration 57 of 100, loss = 0.006671044754942781   Iteration 58 of 100, loss = 0.00663212570361793   Iteration 59 of 100, loss = 0.006705705952530695   Iteration 60 of 100, loss = 0.006739289336837828   Iteration 61 of 100, loss = 0.0066982650839280886   Iteration 62 of 100, loss = 0.006661238907385738   Iteration 63 of 100, loss = 0.006702451781916713   Iteration 64 of 100, loss = 0.006753408881195355   Iteration 65 of 100, loss = 0.006754559063567565   Iteration 66 of 100, loss = 0.006797089509553079   Iteration 67 of 100, loss = 0.006763047205089633   Iteration 68 of 100, loss = 0.006749288288547713   Iteration 69 of 100, loss = 0.006718739988687245   Iteration 70 of 100, loss = 0.006699053550671254   Iteration 71 of 100, loss = 0.006683820681515294   Iteration 72 of 100, loss = 0.0066686386643495   Iteration 73 of 100, loss = 0.006644804802506346   Iteration 74 of 100, loss = 0.0066374032506467525   Iteration 75 of 100, loss = 0.006582440823937456   Iteration 76 of 100, loss = 0.006650294989077865   Iteration 77 of 100, loss = 0.006659509484087686   Iteration 78 of 100, loss = 0.006655076306719237   Iteration 79 of 100, loss = 0.006677351659163833   Iteration 80 of 100, loss = 0.0066863257117802275   Iteration 81 of 100, loss = 0.0066617142529813225   Iteration 82 of 100, loss = 0.006636717109713794   Iteration 83 of 100, loss = 0.00664544579326119   Iteration 84 of 100, loss = 0.006662276742558572   Iteration 85 of 100, loss = 0.006687873199253398   Iteration 86 of 100, loss = 0.006686558034595882   Iteration 87 of 100, loss = 0.006659753125524898   Iteration 88 of 100, loss = 0.006740396437552673   Iteration 89 of 100, loss = 0.006759897834527191   Iteration 90 of 100, loss = 0.006770323281590309   Iteration 91 of 100, loss = 0.0067904151203417844   Iteration 92 of 100, loss = 0.006803005227677362   Iteration 93 of 100, loss = 0.0067811463283555164   Iteration 94 of 100, loss = 0.00677458670218178   Iteration 95 of 100, loss = 0.006762602364056205   Iteration 96 of 100, loss = 0.006782297246293941   Iteration 97 of 100, loss = 0.006781952640464164   Iteration 98 of 100, loss = 0.0067779161915069025   Iteration 99 of 100, loss = 0.006792494681466258   Iteration 100 of 100, loss = 0.006852807386312634
   End of epoch 26; saving model... 

Epoch 27 of 2000
   Iteration 1 of 100, loss = 0.009412459097802639   Iteration 2 of 100, loss = 0.007668488891795278   Iteration 3 of 100, loss = 0.0080076246522367   Iteration 4 of 100, loss = 0.006685186119284481   Iteration 5 of 100, loss = 0.006897729588672519   Iteration 6 of 100, loss = 0.006749166913020114   Iteration 7 of 100, loss = 0.0069074316415935755   Iteration 8 of 100, loss = 0.006953563686693087   Iteration 9 of 100, loss = 0.007770490030654603   Iteration 10 of 100, loss = 0.0076288426062092185   Iteration 11 of 100, loss = 0.0071723935278979216   Iteration 12 of 100, loss = 0.007080827684452136   Iteration 13 of 100, loss = 0.007477110538345117   Iteration 14 of 100, loss = 0.007828425815595048   Iteration 15 of 100, loss = 0.008232789300382137   Iteration 16 of 100, loss = 0.008139300683978945   Iteration 17 of 100, loss = 0.008046806488624391   Iteration 18 of 100, loss = 0.007942679286417034   Iteration 19 of 100, loss = 0.008018754814800463   Iteration 20 of 100, loss = 0.007928768428973854   Iteration 21 of 100, loss = 0.00788312449696518   Iteration 22 of 100, loss = 0.007745983523570679   Iteration 23 of 100, loss = 0.007941584568470716   Iteration 24 of 100, loss = 0.007926394464448094   Iteration 25 of 100, loss = 0.007798423338681459   Iteration 26 of 100, loss = 0.00789758382150187   Iteration 27 of 100, loss = 0.007756705137176646   Iteration 28 of 100, loss = 0.007753568036215646   Iteration 29 of 100, loss = 0.0076850305696756676   Iteration 30 of 100, loss = 0.007636474367852013   Iteration 31 of 100, loss = 0.007649357505743542   Iteration 32 of 100, loss = 0.007555836564279161   Iteration 33 of 100, loss = 0.007494520240773757   Iteration 34 of 100, loss = 0.007576340960119577   Iteration 35 of 100, loss = 0.007591489981859922   Iteration 36 of 100, loss = 0.007598367429131435   Iteration 37 of 100, loss = 0.007535360073922454   Iteration 38 of 100, loss = 0.007479198289250857   Iteration 39 of 100, loss = 0.007483748898196679   Iteration 40 of 100, loss = 0.007521759055089205   Iteration 41 of 100, loss = 0.007459767583030753   Iteration 42 of 100, loss = 0.007347681116135348   Iteration 43 of 100, loss = 0.007272547078427187   Iteration 44 of 100, loss = 0.007322571441446516   Iteration 45 of 100, loss = 0.007326175086200237   Iteration 46 of 100, loss = 0.007246423289989648   Iteration 47 of 100, loss = 0.007247427191109734   Iteration 48 of 100, loss = 0.0072520166577305645   Iteration 49 of 100, loss = 0.007272975604829131   Iteration 50 of 100, loss = 0.007188890222460031   Iteration 51 of 100, loss = 0.007134651025647626   Iteration 52 of 100, loss = 0.007095605564805178   Iteration 53 of 100, loss = 0.0071682992197994915   Iteration 54 of 100, loss = 0.00712701968020863   Iteration 55 of 100, loss = 0.007125215985896913   Iteration 56 of 100, loss = 0.007132046581578574   Iteration 57 of 100, loss = 0.00713991473445244   Iteration 58 of 100, loss = 0.007152341579183422   Iteration 59 of 100, loss = 0.007138524078211542   Iteration 60 of 100, loss = 0.007084311133561035   Iteration 61 of 100, loss = 0.00702003851059641   Iteration 62 of 100, loss = 0.006943014157455294   Iteration 63 of 100, loss = 0.007043305821421128   Iteration 64 of 100, loss = 0.007078868213284295   Iteration 65 of 100, loss = 0.00706829006712024   Iteration 66 of 100, loss = 0.0070762003729627895   Iteration 67 of 100, loss = 0.007053546329487616   Iteration 68 of 100, loss = 0.007049958310637842   Iteration 69 of 100, loss = 0.0070832628095387545   Iteration 70 of 100, loss = 0.00706289187738938   Iteration 71 of 100, loss = 0.007030979415375582   Iteration 72 of 100, loss = 0.007016867069372286   Iteration 73 of 100, loss = 0.006999711352974585   Iteration 74 of 100, loss = 0.0070623290548856195   Iteration 75 of 100, loss = 0.00706462737172842   Iteration 76 of 100, loss = 0.0070047141052782536   Iteration 77 of 100, loss = 0.006978346736400159   Iteration 78 of 100, loss = 0.007001801393926144   Iteration 79 of 100, loss = 0.0069433552437002145   Iteration 80 of 100, loss = 0.006912622530944645   Iteration 81 of 100, loss = 0.006909343551982332   Iteration 82 of 100, loss = 0.006909017030876584   Iteration 83 of 100, loss = 0.0068963741468467624   Iteration 84 of 100, loss = 0.006883157827403574   Iteration 85 of 100, loss = 0.006864533518605372   Iteration 86 of 100, loss = 0.006901195391925962   Iteration 87 of 100, loss = 0.006890961140308572   Iteration 88 of 100, loss = 0.0068452397192066364   Iteration 89 of 100, loss = 0.006914408458920007   Iteration 90 of 100, loss = 0.006872021880311271   Iteration 91 of 100, loss = 0.0068993080115703105   Iteration 92 of 100, loss = 0.006849574661590968   Iteration 93 of 100, loss = 0.006851749777573571   Iteration 94 of 100, loss = 0.006907717634408557   Iteration 95 of 100, loss = 0.006862267562629361   Iteration 96 of 100, loss = 0.006863886180023353   Iteration 97 of 100, loss = 0.006833468400633212   Iteration 98 of 100, loss = 0.006800972319645237   Iteration 99 of 100, loss = 0.006837599689724168   Iteration 100 of 100, loss = 0.006851265118457377
   End of epoch 27; saving model... 

Epoch 28 of 2000
   Iteration 1 of 100, loss = 0.008715656585991383   Iteration 2 of 100, loss = 0.006703830324113369   Iteration 3 of 100, loss = 0.006342585043360789   Iteration 4 of 100, loss = 0.006747159059159458   Iteration 5 of 100, loss = 0.005780586833134293   Iteration 6 of 100, loss = 0.006500544065299134   Iteration 7 of 100, loss = 0.006645520517070379   Iteration 8 of 100, loss = 0.006530940503580496   Iteration 9 of 100, loss = 0.006896583544504311   Iteration 10 of 100, loss = 0.006540351011790335   Iteration 11 of 100, loss = 0.006331685824658383   Iteration 12 of 100, loss = 0.0065613048112330334   Iteration 13 of 100, loss = 0.006719687434199911   Iteration 14 of 100, loss = 0.006741197364005659   Iteration 15 of 100, loss = 0.006829892269646128   Iteration 16 of 100, loss = 0.007019567987299524   Iteration 17 of 100, loss = 0.00674562605426592   Iteration 18 of 100, loss = 0.006544512929394841   Iteration 19 of 100, loss = 0.006491266632158505   Iteration 20 of 100, loss = 0.00637681819498539   Iteration 21 of 100, loss = 0.006465516807067962   Iteration 22 of 100, loss = 0.006642775906419212   Iteration 23 of 100, loss = 0.006853923565991547   Iteration 24 of 100, loss = 0.006753972847945988   Iteration 25 of 100, loss = 0.006647398136556149   Iteration 26 of 100, loss = 0.006745828781276941   Iteration 27 of 100, loss = 0.006638228203411456   Iteration 28 of 100, loss = 0.006572079179542405   Iteration 29 of 100, loss = 0.0065670743552518306   Iteration 30 of 100, loss = 0.006658643716946244   Iteration 31 of 100, loss = 0.006647888195490645   Iteration 32 of 100, loss = 0.006549984304001555   Iteration 33 of 100, loss = 0.006546179778083708   Iteration 34 of 100, loss = 0.0065466125276597105   Iteration 35 of 100, loss = 0.006540946941822767   Iteration 36 of 100, loss = 0.006700407260925406   Iteration 37 of 100, loss = 0.006600684637354838   Iteration 38 of 100, loss = 0.0066504690943187785   Iteration 39 of 100, loss = 0.006604315832448311   Iteration 40 of 100, loss = 0.0065560982679016885   Iteration 41 of 100, loss = 0.006467323682111938   Iteration 42 of 100, loss = 0.006452417699620128   Iteration 43 of 100, loss = 0.006435633528717729   Iteration 44 of 100, loss = 0.006495218300683932   Iteration 45 of 100, loss = 0.006574092412160503   Iteration 46 of 100, loss = 0.006559327315620106   Iteration 47 of 100, loss = 0.006563547136697998   Iteration 48 of 100, loss = 0.006600234570214525   Iteration 49 of 100, loss = 0.006626499636212782   Iteration 50 of 100, loss = 0.0066591630782932044   Iteration 51 of 100, loss = 0.006698176547811896   Iteration 52 of 100, loss = 0.006657772079611627   Iteration 53 of 100, loss = 0.006665148245135568   Iteration 54 of 100, loss = 0.006629241466591203   Iteration 55 of 100, loss = 0.006615155147896572   Iteration 56 of 100, loss = 0.006595646197508488   Iteration 57 of 100, loss = 0.006594451201524128   Iteration 58 of 100, loss = 0.006563063959815893   Iteration 59 of 100, loss = 0.006645096710614733   Iteration 60 of 100, loss = 0.00660960612197717   Iteration 61 of 100, loss = 0.006685196757927293   Iteration 62 of 100, loss = 0.006735490770229409   Iteration 63 of 100, loss = 0.006743775303697302   Iteration 64 of 100, loss = 0.006809039805375505   Iteration 65 of 100, loss = 0.006790017100194326   Iteration 66 of 100, loss = 0.006774956593289971   Iteration 67 of 100, loss = 0.006772247226491793   Iteration 68 of 100, loss = 0.006774905254133046   Iteration 69 of 100, loss = 0.006793610312962445   Iteration 70 of 100, loss = 0.006787063514015504   Iteration 71 of 100, loss = 0.006835078807468985   Iteration 72 of 100, loss = 0.006769470259314403   Iteration 73 of 100, loss = 0.006783497816410988   Iteration 74 of 100, loss = 0.006751485411203592   Iteration 75 of 100, loss = 0.006717223217710852   Iteration 76 of 100, loss = 0.006686637879618884   Iteration 77 of 100, loss = 0.006681792374530976   Iteration 78 of 100, loss = 0.006629458852470494   Iteration 79 of 100, loss = 0.006576807936653495   Iteration 80 of 100, loss = 0.006550153388525359   Iteration 81 of 100, loss = 0.006530353900068152   Iteration 82 of 100, loss = 0.006522196580701303   Iteration 83 of 100, loss = 0.006528920468773289   Iteration 84 of 100, loss = 0.006545601088354098   Iteration 85 of 100, loss = 0.006559072684167939   Iteration 86 of 100, loss = 0.006560036173458536   Iteration 87 of 100, loss = 0.00662328771465383   Iteration 88 of 100, loss = 0.006614886015251448   Iteration 89 of 100, loss = 0.006605541210600667   Iteration 90 of 100, loss = 0.006555137219321397   Iteration 91 of 100, loss = 0.006535460553285512   Iteration 92 of 100, loss = 0.006502155376517255   Iteration 93 of 100, loss = 0.006526814483266364   Iteration 94 of 100, loss = 0.006537165889080534   Iteration 95 of 100, loss = 0.006550328016869332   Iteration 96 of 100, loss = 0.006524035702265489   Iteration 97 of 100, loss = 0.0065073519417075155   Iteration 98 of 100, loss = 0.006534796469483753   Iteration 99 of 100, loss = 0.006501603591716801   Iteration 100 of 100, loss = 0.006549970016349107
   End of epoch 28; saving model... 

Epoch 29 of 2000
   Iteration 1 of 100, loss = 0.00444365106523037   Iteration 2 of 100, loss = 0.008627929724752903   Iteration 3 of 100, loss = 0.007871882679561773   Iteration 4 of 100, loss = 0.007918674033135176   Iteration 5 of 100, loss = 0.008679617382586002   Iteration 6 of 100, loss = 0.008166998081530133   Iteration 7 of 100, loss = 0.00787160765113575   Iteration 8 of 100, loss = 0.007894330599810928   Iteration 9 of 100, loss = 0.008015099861141708   Iteration 10 of 100, loss = 0.008149528643116355   Iteration 11 of 100, loss = 0.007694956952367316   Iteration 12 of 100, loss = 0.007296220515854657   Iteration 13 of 100, loss = 0.007146182971505018   Iteration 14 of 100, loss = 0.007194748214845147   Iteration 15 of 100, loss = 0.007032893070330223   Iteration 16 of 100, loss = 0.006859040295239538   Iteration 17 of 100, loss = 0.006865627570625614   Iteration 18 of 100, loss = 0.006854565503696601   Iteration 19 of 100, loss = 0.006883806916639993   Iteration 20 of 100, loss = 0.006931397062726319   Iteration 21 of 100, loss = 0.006816092146826642   Iteration 22 of 100, loss = 0.006754872875965454   Iteration 23 of 100, loss = 0.006745133994390135   Iteration 24 of 100, loss = 0.006822997044461469   Iteration 25 of 100, loss = 0.006866474784910679   Iteration 26 of 100, loss = 0.006901259426600658   Iteration 27 of 100, loss = 0.006998312797535349   Iteration 28 of 100, loss = 0.007013737839380545   Iteration 29 of 100, loss = 0.006988589250450504   Iteration 30 of 100, loss = 0.007114340721940001   Iteration 31 of 100, loss = 0.006997610862937665   Iteration 32 of 100, loss = 0.006901461936649866   Iteration 33 of 100, loss = 0.006853463763201778   Iteration 34 of 100, loss = 0.006769505151383141   Iteration 35 of 100, loss = 0.006739223788359335   Iteration 36 of 100, loss = 0.0066667716794957714   Iteration 37 of 100, loss = 0.006701665930449963   Iteration 38 of 100, loss = 0.006701380835453931   Iteration 39 of 100, loss = 0.006641610847929349   Iteration 40 of 100, loss = 0.006596034555695951   Iteration 41 of 100, loss = 0.006707548163831234   Iteration 42 of 100, loss = 0.006622198010085239   Iteration 43 of 100, loss = 0.006670864986602304   Iteration 44 of 100, loss = 0.0067740726147101004   Iteration 45 of 100, loss = 0.006748444002328648   Iteration 46 of 100, loss = 0.006819066262561018   Iteration 47 of 100, loss = 0.006844846328641189   Iteration 48 of 100, loss = 0.0067808265157509595   Iteration 49 of 100, loss = 0.006768896234963013   Iteration 50 of 100, loss = 0.006713723177090287   Iteration 51 of 100, loss = 0.006699105313814738   Iteration 52 of 100, loss = 0.006693057080086034   Iteration 53 of 100, loss = 0.006705733481794596   Iteration 54 of 100, loss = 0.006699080277165329   Iteration 55 of 100, loss = 0.006693952852352099   Iteration 56 of 100, loss = 0.006657067295496485   Iteration 57 of 100, loss = 0.006623946236479178   Iteration 58 of 100, loss = 0.006611416814848781   Iteration 59 of 100, loss = 0.00671001695001782   Iteration 60 of 100, loss = 0.006738426062899331   Iteration 61 of 100, loss = 0.006777043370377334   Iteration 62 of 100, loss = 0.0067383248674412885   Iteration 63 of 100, loss = 0.006764370585895247   Iteration 64 of 100, loss = 0.006794097811507527   Iteration 65 of 100, loss = 0.006767011498315976   Iteration 66 of 100, loss = 0.006811499122925328   Iteration 67 of 100, loss = 0.006760462819695917   Iteration 68 of 100, loss = 0.006711848254781216   Iteration 69 of 100, loss = 0.006715368091439207   Iteration 70 of 100, loss = 0.006698358714181398   Iteration 71 of 100, loss = 0.006759622583533047   Iteration 72 of 100, loss = 0.00676951552547204   Iteration 73 of 100, loss = 0.0067732158174406585   Iteration 74 of 100, loss = 0.006747411170697494   Iteration 75 of 100, loss = 0.006761142564937472   Iteration 76 of 100, loss = 0.006735801632442561   Iteration 77 of 100, loss = 0.006805480454818575   Iteration 78 of 100, loss = 0.006842980767265918   Iteration 79 of 100, loss = 0.0067927928529444   Iteration 80 of 100, loss = 0.006766860405332409   Iteration 81 of 100, loss = 0.006774143215245855   Iteration 82 of 100, loss = 0.006827220925493393   Iteration 83 of 100, loss = 0.006816077520173177   Iteration 84 of 100, loss = 0.0068033930618271584   Iteration 85 of 100, loss = 0.006873587921590489   Iteration 86 of 100, loss = 0.006933248696610505   Iteration 87 of 100, loss = 0.006953383161654246   Iteration 88 of 100, loss = 0.006944684573682025   Iteration 89 of 100, loss = 0.006928215444276339   Iteration 90 of 100, loss = 0.006943988730199635   Iteration 91 of 100, loss = 0.006976309255440976   Iteration 92 of 100, loss = 0.006964545831104498   Iteration 93 of 100, loss = 0.006932396078682555   Iteration 94 of 100, loss = 0.0069427212695293925   Iteration 95 of 100, loss = 0.006952053864829635   Iteration 96 of 100, loss = 0.006964778437880644   Iteration 97 of 100, loss = 0.006958873119186034   Iteration 98 of 100, loss = 0.006975785090245915   Iteration 99 of 100, loss = 0.006963341057093607   Iteration 100 of 100, loss = 0.00696116421604529
   End of epoch 29; saving model... 

Epoch 30 of 2000
   Iteration 1 of 100, loss = 0.006535520311444998   Iteration 2 of 100, loss = 0.005930115235969424   Iteration 3 of 100, loss = 0.006287454627454281   Iteration 4 of 100, loss = 0.0068045067600905895   Iteration 5 of 100, loss = 0.006612857524305582   Iteration 6 of 100, loss = 0.006540617672726512   Iteration 7 of 100, loss = 0.00664343498647213   Iteration 8 of 100, loss = 0.006432266149204224   Iteration 9 of 100, loss = 0.006391460955556896   Iteration 10 of 100, loss = 0.006307501811534166   Iteration 11 of 100, loss = 0.00628264658999714   Iteration 12 of 100, loss = 0.006016714090947062   Iteration 13 of 100, loss = 0.006071425884818802   Iteration 14 of 100, loss = 0.005927793265852545   Iteration 15 of 100, loss = 0.005851160719369849   Iteration 16 of 100, loss = 0.005864124643267132   Iteration 17 of 100, loss = 0.005706010180908968   Iteration 18 of 100, loss = 0.005766155159411331   Iteration 19 of 100, loss = 0.005867672704258247   Iteration 20 of 100, loss = 0.0058610108797438444   Iteration 21 of 100, loss = 0.005878181340882466   Iteration 22 of 100, loss = 0.005887971503067423   Iteration 23 of 100, loss = 0.005778377339162905   Iteration 24 of 100, loss = 0.005868761092036341   Iteration 25 of 100, loss = 0.005859530149027705   Iteration 26 of 100, loss = 0.005931763614241321   Iteration 27 of 100, loss = 0.00588586673795901   Iteration 28 of 100, loss = 0.005829733971040696   Iteration 29 of 100, loss = 0.00574280588951861   Iteration 30 of 100, loss = 0.005798986173855761   Iteration 31 of 100, loss = 0.005751085219784609   Iteration 32 of 100, loss = 0.00568884881795384   Iteration 33 of 100, loss = 0.005627331225145043   Iteration 34 of 100, loss = 0.0056537906639277935   Iteration 35 of 100, loss = 0.005597433753843819   Iteration 36 of 100, loss = 0.00562376336246315   Iteration 37 of 100, loss = 0.005572779374700543   Iteration 38 of 100, loss = 0.005682736678097986   Iteration 39 of 100, loss = 0.005675850298781044   Iteration 40 of 100, loss = 0.005723347916500643   Iteration 41 of 100, loss = 0.005710939041952171   Iteration 42 of 100, loss = 0.005813733635780712   Iteration 43 of 100, loss = 0.005807918209452615   Iteration 44 of 100, loss = 0.005833692938639698   Iteration 45 of 100, loss = 0.00579418094518284   Iteration 46 of 100, loss = 0.005822362292193524   Iteration 47 of 100, loss = 0.0058624480325887175   Iteration 48 of 100, loss = 0.005836540023058963   Iteration 49 of 100, loss = 0.005874563868594717   Iteration 50 of 100, loss = 0.005877531957812607   Iteration 51 of 100, loss = 0.005872455092293082   Iteration 52 of 100, loss = 0.005977457689228826   Iteration 53 of 100, loss = 0.0059783618220672855   Iteration 54 of 100, loss = 0.006042714554092122   Iteration 55 of 100, loss = 0.00606493899514052   Iteration 56 of 100, loss = 0.006123068048119811   Iteration 57 of 100, loss = 0.006125141699030472   Iteration 58 of 100, loss = 0.0061242351396780075   Iteration 59 of 100, loss = 0.006179722148325231   Iteration 60 of 100, loss = 0.00621388873939092   Iteration 61 of 100, loss = 0.006244298311133609   Iteration 62 of 100, loss = 0.006262690809014584   Iteration 63 of 100, loss = 0.006337930762489874   Iteration 64 of 100, loss = 0.00638574912227341   Iteration 65 of 100, loss = 0.006327091537129421   Iteration 66 of 100, loss = 0.006343423381842898   Iteration 67 of 100, loss = 0.006356517603593086   Iteration 68 of 100, loss = 0.006368166513686233   Iteration 69 of 100, loss = 0.006360216086487408   Iteration 70 of 100, loss = 0.006381513065259372   Iteration 71 of 100, loss = 0.006357892482003695   Iteration 72 of 100, loss = 0.006330357282422483   Iteration 73 of 100, loss = 0.006352754769055811   Iteration 74 of 100, loss = 0.0063517738662257385   Iteration 75 of 100, loss = 0.0063446237271030746   Iteration 76 of 100, loss = 0.006369570208909481   Iteration 77 of 100, loss = 0.006410629113579726   Iteration 78 of 100, loss = 0.006428499909070058   Iteration 79 of 100, loss = 0.006480104938338074   Iteration 80 of 100, loss = 0.006446644262177869   Iteration 81 of 100, loss = 0.0065107929957225735   Iteration 82 of 100, loss = 0.006505825397808377   Iteration 83 of 100, loss = 0.006519089234117643   Iteration 84 of 100, loss = 0.006534237287095969   Iteration 85 of 100, loss = 0.006494858441874385   Iteration 86 of 100, loss = 0.006512340848594037   Iteration 87 of 100, loss = 0.006490262693607773   Iteration 88 of 100, loss = 0.00653211479022337   Iteration 89 of 100, loss = 0.006535454038425945   Iteration 90 of 100, loss = 0.00655290763049076   Iteration 91 of 100, loss = 0.006514689752033779   Iteration 92 of 100, loss = 0.006537443897484437   Iteration 93 of 100, loss = 0.006517007861847198   Iteration 94 of 100, loss = 0.006522799648859716   Iteration 95 of 100, loss = 0.006533957066896715   Iteration 96 of 100, loss = 0.0065227967376510305   Iteration 97 of 100, loss = 0.006592771124824421   Iteration 98 of 100, loss = 0.006624398581987741   Iteration 99 of 100, loss = 0.006614902503600325   Iteration 100 of 100, loss = 0.006616415372118354
   End of epoch 30; saving model... 

Epoch 31 of 2000
   Iteration 1 of 100, loss = 0.0045552863739430904   Iteration 2 of 100, loss = 0.006123616360127926   Iteration 3 of 100, loss = 0.0064592234169443445   Iteration 4 of 100, loss = 0.005838802549988031   Iteration 5 of 100, loss = 0.0057536671869456765   Iteration 6 of 100, loss = 0.006319048271204035   Iteration 7 of 100, loss = 0.006744901849223035   Iteration 8 of 100, loss = 0.006825958203990012   Iteration 9 of 100, loss = 0.007103582999358575   Iteration 10 of 100, loss = 0.006888402067124844   Iteration 11 of 100, loss = 0.006940833335234361   Iteration 12 of 100, loss = 0.007187617205393811   Iteration 13 of 100, loss = 0.006883873102756647   Iteration 14 of 100, loss = 0.006747793971693942   Iteration 15 of 100, loss = 0.006851549601803223   Iteration 16 of 100, loss = 0.006933493918040767   Iteration 17 of 100, loss = 0.006955915651119807   Iteration 18 of 100, loss = 0.006849331186256475   Iteration 19 of 100, loss = 0.0068128906974667   Iteration 20 of 100, loss = 0.006906163273379206   Iteration 21 of 100, loss = 0.006832861053269534   Iteration 22 of 100, loss = 0.006710442672060294   Iteration 23 of 100, loss = 0.006623226967032837   Iteration 24 of 100, loss = 0.006661274470388889   Iteration 25 of 100, loss = 0.006486766701564193   Iteration 26 of 100, loss = 0.006672261273846603   Iteration 27 of 100, loss = 0.006777200183865649   Iteration 28 of 100, loss = 0.006907879466390503   Iteration 29 of 100, loss = 0.006988039103754121   Iteration 30 of 100, loss = 0.006908914175194999   Iteration 31 of 100, loss = 0.00703485052461826   Iteration 32 of 100, loss = 0.006966140375880059   Iteration 33 of 100, loss = 0.0069201765088082266   Iteration 34 of 100, loss = 0.00685341448714847   Iteration 35 of 100, loss = 0.006824003153347543   Iteration 36 of 100, loss = 0.00686779177825277   Iteration 37 of 100, loss = 0.0068559279677936355   Iteration 38 of 100, loss = 0.006835627302184309   Iteration 39 of 100, loss = 0.006913200050640183   Iteration 40 of 100, loss = 0.006861461995868012   Iteration 41 of 100, loss = 0.006794197853972636   Iteration 42 of 100, loss = 0.006870958604849875   Iteration 43 of 100, loss = 0.006848300552688712   Iteration 44 of 100, loss = 0.0067784617792560975   Iteration 45 of 100, loss = 0.006826417008414865   Iteration 46 of 100, loss = 0.006931723748414736   Iteration 47 of 100, loss = 0.006952674390668882   Iteration 48 of 100, loss = 0.007001160124976498   Iteration 49 of 100, loss = 0.006974881358102572   Iteration 50 of 100, loss = 0.00693763839546591   Iteration 51 of 100, loss = 0.006893497741068988   Iteration 52 of 100, loss = 0.006883760730628497   Iteration 53 of 100, loss = 0.0069140611031918596   Iteration 54 of 100, loss = 0.0069171563265155315   Iteration 55 of 100, loss = 0.006903794022615661   Iteration 56 of 100, loss = 0.00691993666363747   Iteration 57 of 100, loss = 0.006952982824785929   Iteration 58 of 100, loss = 0.007018411375485875   Iteration 59 of 100, loss = 0.007111278982138482   Iteration 60 of 100, loss = 0.007039232218327622   Iteration 61 of 100, loss = 0.006987657340732021   Iteration 62 of 100, loss = 0.0069956752779563106   Iteration 63 of 100, loss = 0.006999396308813067   Iteration 64 of 100, loss = 0.006983476927416632   Iteration 65 of 100, loss = 0.006984039370973523   Iteration 66 of 100, loss = 0.006994894046025972   Iteration 67 of 100, loss = 0.007002381347258811   Iteration 68 of 100, loss = 0.007040216371773139   Iteration 69 of 100, loss = 0.007038099910604997   Iteration 70 of 100, loss = 0.0070793587348556945   Iteration 71 of 100, loss = 0.007146499673901519   Iteration 72 of 100, loss = 0.007116556707640282   Iteration 73 of 100, loss = 0.00708956244299571   Iteration 74 of 100, loss = 0.007064967903912671   Iteration 75 of 100, loss = 0.007118307187532385   Iteration 76 of 100, loss = 0.007070608642319904   Iteration 77 of 100, loss = 0.007077282406510664   Iteration 78 of 100, loss = 0.0070297449248102615   Iteration 79 of 100, loss = 0.007003887176301472   Iteration 80 of 100, loss = 0.006995904128416441   Iteration 81 of 100, loss = 0.00695682406126533   Iteration 82 of 100, loss = 0.006910168012127098   Iteration 83 of 100, loss = 0.00692959192927074   Iteration 84 of 100, loss = 0.006892479659568164   Iteration 85 of 100, loss = 0.006865261821076274   Iteration 86 of 100, loss = 0.006849032331279717   Iteration 87 of 100, loss = 0.006823565369343449   Iteration 88 of 100, loss = 0.006794245953311805   Iteration 89 of 100, loss = 0.006784920583301214   Iteration 90 of 100, loss = 0.006767068009099199   Iteration 91 of 100, loss = 0.0067379309023106165   Iteration 92 of 100, loss = 0.0067368016056918905   Iteration 93 of 100, loss = 0.006726906652392078   Iteration 94 of 100, loss = 0.006711039526209711   Iteration 95 of 100, loss = 0.006739840462901874   Iteration 96 of 100, loss = 0.0067344585234726155   Iteration 97 of 100, loss = 0.006735118266828742   Iteration 98 of 100, loss = 0.006711559339274405   Iteration 99 of 100, loss = 0.006716643819924106   Iteration 100 of 100, loss = 0.006715382707770914
   End of epoch 31; saving model... 

Epoch 32 of 2000
   Iteration 1 of 100, loss = 0.009404501877725124   Iteration 2 of 100, loss = 0.008249482838436961   Iteration 3 of 100, loss = 0.008154295850545168   Iteration 4 of 100, loss = 0.007155128754675388   Iteration 5 of 100, loss = 0.006828701589256525   Iteration 6 of 100, loss = 0.007019653993969162   Iteration 7 of 100, loss = 0.006934724348996367   Iteration 8 of 100, loss = 0.0077065794030204415   Iteration 9 of 100, loss = 0.007655062402288119   Iteration 10 of 100, loss = 0.007584548555314541   Iteration 11 of 100, loss = 0.007304465313526717   Iteration 12 of 100, loss = 0.007340287556871772   Iteration 13 of 100, loss = 0.007443783016732106   Iteration 14 of 100, loss = 0.007422767612817032   Iteration 15 of 100, loss = 0.007547971078505119   Iteration 16 of 100, loss = 0.007385496806818992   Iteration 17 of 100, loss = 0.007254454937270459   Iteration 18 of 100, loss = 0.007145741411174337   Iteration 19 of 100, loss = 0.007004539604837957   Iteration 20 of 100, loss = 0.007034567603841424   Iteration 21 of 100, loss = 0.00696875469847804   Iteration 22 of 100, loss = 0.0069259504194964065   Iteration 23 of 100, loss = 0.006813615884469903   Iteration 24 of 100, loss = 0.006754105891256283   Iteration 25 of 100, loss = 0.0067240394651889804   Iteration 26 of 100, loss = 0.00661515358548898   Iteration 27 of 100, loss = 0.006557792235441782   Iteration 28 of 100, loss = 0.0066728103806131655   Iteration 29 of 100, loss = 0.006712231319397688   Iteration 30 of 100, loss = 0.00658748788603892   Iteration 31 of 100, loss = 0.006644858490495432   Iteration 32 of 100, loss = 0.006587807183677796   Iteration 33 of 100, loss = 0.006572334723772876   Iteration 34 of 100, loss = 0.006546794320456684   Iteration 35 of 100, loss = 0.006655115042147892   Iteration 36 of 100, loss = 0.006684693410837402   Iteration 37 of 100, loss = 0.006633160314900246   Iteration 38 of 100, loss = 0.00664099718223473   Iteration 39 of 100, loss = 0.006672207510862977   Iteration 40 of 100, loss = 0.0066345093480777   Iteration 41 of 100, loss = 0.00665489735831393   Iteration 42 of 100, loss = 0.006687742630241527   Iteration 43 of 100, loss = 0.006781932221032506   Iteration 44 of 100, loss = 0.006832108319610019   Iteration 45 of 100, loss = 0.00676779574714601   Iteration 46 of 100, loss = 0.0067507868035413   Iteration 47 of 100, loss = 0.00671560097822642   Iteration 48 of 100, loss = 0.006654704004176892   Iteration 49 of 100, loss = 0.006672497605904937   Iteration 50 of 100, loss = 0.00659244364593178   Iteration 51 of 100, loss = 0.006575058839813459   Iteration 52 of 100, loss = 0.0066089650589184696   Iteration 53 of 100, loss = 0.006563742280463284   Iteration 54 of 100, loss = 0.006575098584613038   Iteration 55 of 100, loss = 0.0065547609659419815   Iteration 56 of 100, loss = 0.0065260444410211805   Iteration 57 of 100, loss = 0.0064831664663200315   Iteration 58 of 100, loss = 0.00647821720962509   Iteration 59 of 100, loss = 0.006532694469600663   Iteration 60 of 100, loss = 0.006588257620266328   Iteration 61 of 100, loss = 0.006682348823113764   Iteration 62 of 100, loss = 0.006688536501549665   Iteration 63 of 100, loss = 0.006707780916864674   Iteration 64 of 100, loss = 0.006690233432891546   Iteration 65 of 100, loss = 0.006644404120743274   Iteration 66 of 100, loss = 0.006620132251445091   Iteration 67 of 100, loss = 0.00666488971171984   Iteration 68 of 100, loss = 0.0067333468400380195   Iteration 69 of 100, loss = 0.006718273693020793   Iteration 70 of 100, loss = 0.006697218951636127   Iteration 71 of 100, loss = 0.006697138312312079   Iteration 72 of 100, loss = 0.006755068561890059   Iteration 73 of 100, loss = 0.0067651412092557504   Iteration 74 of 100, loss = 0.006706195807940251   Iteration 75 of 100, loss = 0.006741857565939427   Iteration 76 of 100, loss = 0.00681387661270013   Iteration 77 of 100, loss = 0.006824289581605366   Iteration 78 of 100, loss = 0.006810091889630525   Iteration 79 of 100, loss = 0.006904878547485871   Iteration 80 of 100, loss = 0.006911898270482197   Iteration 81 of 100, loss = 0.006914106663316488   Iteration 82 of 100, loss = 0.006918898721157414   Iteration 83 of 100, loss = 0.006900500242474927   Iteration 84 of 100, loss = 0.0068607990563447985   Iteration 85 of 100, loss = 0.0068209052880239835   Iteration 86 of 100, loss = 0.0068513751490214886   Iteration 87 of 100, loss = 0.00689021397606823   Iteration 88 of 100, loss = 0.006864005109739744   Iteration 89 of 100, loss = 0.006858955746977015   Iteration 90 of 100, loss = 0.006849895730718142   Iteration 91 of 100, loss = 0.00685364257411233   Iteration 92 of 100, loss = 0.006861199698228713   Iteration 93 of 100, loss = 0.006853618776746174   Iteration 94 of 100, loss = 0.006822526992417555   Iteration 95 of 100, loss = 0.006849496451353556   Iteration 96 of 100, loss = 0.0068939400783468345   Iteration 97 of 100, loss = 0.006869267626694336   Iteration 98 of 100, loss = 0.0068845392741757085   Iteration 99 of 100, loss = 0.006887049886934234   Iteration 100 of 100, loss = 0.0068683119234628975
   End of epoch 32; saving model... 

Epoch 33 of 2000
   Iteration 1 of 100, loss = 0.008069095201790333   Iteration 2 of 100, loss = 0.0066524536814540625   Iteration 3 of 100, loss = 0.006737446878105402   Iteration 4 of 100, loss = 0.0064935797126963735   Iteration 5 of 100, loss = 0.0066658521071076395   Iteration 6 of 100, loss = 0.006335387704893947   Iteration 7 of 100, loss = 0.006593252598707165   Iteration 8 of 100, loss = 0.006493306835182011   Iteration 9 of 100, loss = 0.0062782324643598664   Iteration 10 of 100, loss = 0.006417921977117658   Iteration 11 of 100, loss = 0.006827040109783411   Iteration 12 of 100, loss = 0.006706691541088124   Iteration 13 of 100, loss = 0.006754150005200734   Iteration 14 of 100, loss = 0.007008110139785069   Iteration 15 of 100, loss = 0.007175771923114856   Iteration 16 of 100, loss = 0.007038341631414369   Iteration 17 of 100, loss = 0.007146008230526657   Iteration 18 of 100, loss = 0.007187745042352213   Iteration 19 of 100, loss = 0.007133210445509145   Iteration 20 of 100, loss = 0.007149845012463629   Iteration 21 of 100, loss = 0.0070232840121856755   Iteration 22 of 100, loss = 0.007049902744421905   Iteration 23 of 100, loss = 0.007056093693751356   Iteration 24 of 100, loss = 0.006989661526555817   Iteration 25 of 100, loss = 0.006917422823607922   Iteration 26 of 100, loss = 0.006945651991722675   Iteration 27 of 100, loss = 0.006948440525404833   Iteration 28 of 100, loss = 0.006906363381338971   Iteration 29 of 100, loss = 0.00681918273390881   Iteration 30 of 100, loss = 0.00682671774799625   Iteration 31 of 100, loss = 0.0069416847921186875   Iteration 32 of 100, loss = 0.006996676209382713   Iteration 33 of 100, loss = 0.006952807998679804   Iteration 34 of 100, loss = 0.00687591585001963   Iteration 35 of 100, loss = 0.006799821156476225   Iteration 36 of 100, loss = 0.006758405671765407   Iteration 37 of 100, loss = 0.006721000061244578   Iteration 38 of 100, loss = 0.006721870630587402   Iteration 39 of 100, loss = 0.006707594813540196   Iteration 40 of 100, loss = 0.006686205801088363   Iteration 41 of 100, loss = 0.006783460618973505   Iteration 42 of 100, loss = 0.006716188065530289   Iteration 43 of 100, loss = 0.006787472664443559   Iteration 44 of 100, loss = 0.006718569689176299   Iteration 45 of 100, loss = 0.006760303821000788   Iteration 46 of 100, loss = 0.006879815730549719   Iteration 47 of 100, loss = 0.006938100950990586   Iteration 48 of 100, loss = 0.006891442588918532   Iteration 49 of 100, loss = 0.006824510219525926   Iteration 50 of 100, loss = 0.006820279024541378   Iteration 51 of 100, loss = 0.006801311520165673   Iteration 52 of 100, loss = 0.006819612364499615   Iteration 53 of 100, loss = 0.006832738196090708   Iteration 54 of 100, loss = 0.006773114557964382   Iteration 55 of 100, loss = 0.006798014882951975   Iteration 56 of 100, loss = 0.006910907578588065   Iteration 57 of 100, loss = 0.006874725729096354   Iteration 58 of 100, loss = 0.006903547440366498   Iteration 59 of 100, loss = 0.006889366899948504   Iteration 60 of 100, loss = 0.0068523613192761935   Iteration 61 of 100, loss = 0.006851637087090582   Iteration 62 of 100, loss = 0.006842417154280889   Iteration 63 of 100, loss = 0.006855587304998485   Iteration 64 of 100, loss = 0.006853836428490467   Iteration 65 of 100, loss = 0.006842221763844673   Iteration 66 of 100, loss = 0.006924052807417783   Iteration 67 of 100, loss = 0.006974185247029831   Iteration 68 of 100, loss = 0.006926024490145638   Iteration 69 of 100, loss = 0.006957242690512668   Iteration 70 of 100, loss = 0.006904241472615727   Iteration 71 of 100, loss = 0.006886897231517753   Iteration 72 of 100, loss = 0.0069269156762554   Iteration 73 of 100, loss = 0.006947259587707789   Iteration 74 of 100, loss = 0.006893072947482201   Iteration 75 of 100, loss = 0.006920722862705588   Iteration 76 of 100, loss = 0.006962347104777827   Iteration 77 of 100, loss = 0.0069361008891182675   Iteration 78 of 100, loss = 0.00688970239701657   Iteration 79 of 100, loss = 0.006894816329136868   Iteration 80 of 100, loss = 0.006851270326296799   Iteration 81 of 100, loss = 0.006897535390668997   Iteration 82 of 100, loss = 0.006878763235673853   Iteration 83 of 100, loss = 0.0069146035154944805   Iteration 84 of 100, loss = 0.006943320215214044   Iteration 85 of 100, loss = 0.006899589776773663   Iteration 86 of 100, loss = 0.006856572559796447   Iteration 87 of 100, loss = 0.00684466231186157   Iteration 88 of 100, loss = 0.006840609649026936   Iteration 89 of 100, loss = 0.0068709752051515525   Iteration 90 of 100, loss = 0.006843857850051588   Iteration 91 of 100, loss = 0.006803887862978237   Iteration 92 of 100, loss = 0.006780128457846687   Iteration 93 of 100, loss = 0.006744491795117977   Iteration 94 of 100, loss = 0.006839827176163647   Iteration 95 of 100, loss = 0.0068360570499575455   Iteration 96 of 100, loss = 0.00681673142874691   Iteration 97 of 100, loss = 0.0068023854208937315   Iteration 98 of 100, loss = 0.0067644454728888   Iteration 99 of 100, loss = 0.006762634544172371   Iteration 100 of 100, loss = 0.006836661216802895
   End of epoch 33; saving model... 

Epoch 34 of 2000
   Iteration 1 of 100, loss = 0.004819191992282867   Iteration 2 of 100, loss = 0.006468622013926506   Iteration 3 of 100, loss = 0.007084856430689494   Iteration 4 of 100, loss = 0.006352554890327156   Iteration 5 of 100, loss = 0.0061515867710113525   Iteration 6 of 100, loss = 0.006002676673233509   Iteration 7 of 100, loss = 0.005949254347277539   Iteration 8 of 100, loss = 0.006216385692823678   Iteration 9 of 100, loss = 0.006594828485200803   Iteration 10 of 100, loss = 0.0067968280520290135   Iteration 11 of 100, loss = 0.00661558433520523   Iteration 12 of 100, loss = 0.006765848685366412   Iteration 13 of 100, loss = 0.006533395481080963   Iteration 14 of 100, loss = 0.006666478085597711   Iteration 15 of 100, loss = 0.00688149337656796   Iteration 16 of 100, loss = 0.006769689280190505   Iteration 17 of 100, loss = 0.006838988964719807   Iteration 18 of 100, loss = 0.007113208024141689   Iteration 19 of 100, loss = 0.007114245789125562   Iteration 20 of 100, loss = 0.007029881805647164   Iteration 21 of 100, loss = 0.006964556839583176   Iteration 22 of 100, loss = 0.007135218485597183   Iteration 23 of 100, loss = 0.007133504770615179   Iteration 24 of 100, loss = 0.007189207739429548   Iteration 25 of 100, loss = 0.007025044150650501   Iteration 26 of 100, loss = 0.007007166528357909   Iteration 27 of 100, loss = 0.007127211222218143   Iteration 28 of 100, loss = 0.007040757486330611   Iteration 29 of 100, loss = 0.006995004441203742   Iteration 30 of 100, loss = 0.007148734759539366   Iteration 31 of 100, loss = 0.007105678935805636   Iteration 32 of 100, loss = 0.0071355804248014465   Iteration 33 of 100, loss = 0.007106828150536978   Iteration 34 of 100, loss = 0.00708966185886632   Iteration 35 of 100, loss = 0.007005004012691123   Iteration 36 of 100, loss = 0.006966730437448455   Iteration 37 of 100, loss = 0.007010818370995489   Iteration 38 of 100, loss = 0.007097760791351136   Iteration 39 of 100, loss = 0.007043719649888002   Iteration 40 of 100, loss = 0.0070024110958911475   Iteration 41 of 100, loss = 0.006969299269612969   Iteration 42 of 100, loss = 0.0069830821206172304   Iteration 43 of 100, loss = 0.006906618883963241   Iteration 44 of 100, loss = 0.006857202600010417   Iteration 45 of 100, loss = 0.006813270640042093   Iteration 46 of 100, loss = 0.006780583047024582   Iteration 47 of 100, loss = 0.006843482500853691   Iteration 48 of 100, loss = 0.006783839072644089   Iteration 49 of 100, loss = 0.006746408501069764   Iteration 50 of 100, loss = 0.006767107034102082   Iteration 51 of 100, loss = 0.006841368178891785   Iteration 52 of 100, loss = 0.00681264793428664   Iteration 53 of 100, loss = 0.006788322482398659   Iteration 54 of 100, loss = 0.0067541146288729375   Iteration 55 of 100, loss = 0.006759176403284073   Iteration 56 of 100, loss = 0.006698231225267851   Iteration 57 of 100, loss = 0.006646397164124146   Iteration 58 of 100, loss = 0.00662724603095959   Iteration 59 of 100, loss = 0.006620505651048684   Iteration 60 of 100, loss = 0.0066198075966288645   Iteration 61 of 100, loss = 0.0067350867005889535   Iteration 62 of 100, loss = 0.0067838452035380945   Iteration 63 of 100, loss = 0.006791867005328338   Iteration 64 of 100, loss = 0.006840747693786398   Iteration 65 of 100, loss = 0.006847754643800167   Iteration 66 of 100, loss = 0.0068146035315073804   Iteration 67 of 100, loss = 0.006829380189805333   Iteration 68 of 100, loss = 0.006854576599674628   Iteration 69 of 100, loss = 0.0069048700084828815   Iteration 70 of 100, loss = 0.006866266831223454   Iteration 71 of 100, loss = 0.0068602201423909465   Iteration 72 of 100, loss = 0.00685630146957313   Iteration 73 of 100, loss = 0.006826344367167721   Iteration 74 of 100, loss = 0.006835276512680827   Iteration 75 of 100, loss = 0.006804347379753987   Iteration 76 of 100, loss = 0.006863121868503329   Iteration 77 of 100, loss = 0.0069174801797739095   Iteration 78 of 100, loss = 0.0069695139984385325   Iteration 79 of 100, loss = 0.006970458976405708   Iteration 80 of 100, loss = 0.006933009147178382   Iteration 81 of 100, loss = 0.006970183429434711   Iteration 82 of 100, loss = 0.006933653017324282   Iteration 83 of 100, loss = 0.0069134056972092895   Iteration 84 of 100, loss = 0.006871136789587105   Iteration 85 of 100, loss = 0.006864886399468078   Iteration 86 of 100, loss = 0.006839173919044782   Iteration 87 of 100, loss = 0.006873815756655116   Iteration 88 of 100, loss = 0.006888002757808532   Iteration 89 of 100, loss = 0.0068581388567396425   Iteration 90 of 100, loss = 0.006826256533774237   Iteration 91 of 100, loss = 0.006902089810694803   Iteration 92 of 100, loss = 0.006919198707454716   Iteration 93 of 100, loss = 0.006948380358016459   Iteration 94 of 100, loss = 0.006916105437607682   Iteration 95 of 100, loss = 0.006888903503453261   Iteration 96 of 100, loss = 0.006867601980047766   Iteration 97 of 100, loss = 0.006880977131023081   Iteration 98 of 100, loss = 0.006871745572425425   Iteration 99 of 100, loss = 0.00686088669809955   Iteration 100 of 100, loss = 0.006839282170403749
   End of epoch 34; saving model... 

Epoch 35 of 2000
   Iteration 1 of 100, loss = 0.009347202256321907   Iteration 2 of 100, loss = 0.006937659345567226   Iteration 3 of 100, loss = 0.00571492500603199   Iteration 4 of 100, loss = 0.008044973481446505   Iteration 5 of 100, loss = 0.0075804200954735276   Iteration 6 of 100, loss = 0.00808582198806107   Iteration 7 of 100, loss = 0.007567520053791148   Iteration 8 of 100, loss = 0.00694281212054193   Iteration 9 of 100, loss = 0.006998690207385355   Iteration 10 of 100, loss = 0.006917008990421891   Iteration 11 of 100, loss = 0.0066725706512277775   Iteration 12 of 100, loss = 0.006655245049235721   Iteration 13 of 100, loss = 0.0065765640555092925   Iteration 14 of 100, loss = 0.006699682579242757   Iteration 15 of 100, loss = 0.006456980605920156   Iteration 16 of 100, loss = 0.0066606003092601895   Iteration 17 of 100, loss = 0.006786511882263071   Iteration 18 of 100, loss = 0.006871932082706028   Iteration 19 of 100, loss = 0.006709357527525802   Iteration 20 of 100, loss = 0.006902109831571579   Iteration 21 of 100, loss = 0.0069259426645225   Iteration 22 of 100, loss = 0.006812739672816612   Iteration 23 of 100, loss = 0.006865093909689914   Iteration 24 of 100, loss = 0.0067848475688758   Iteration 25 of 100, loss = 0.006893668305128813   Iteration 26 of 100, loss = 0.00696180508328745   Iteration 27 of 100, loss = 0.006875552375007559   Iteration 28 of 100, loss = 0.006819568557797798   Iteration 29 of 100, loss = 0.006765218885165864   Iteration 30 of 100, loss = 0.006831492374961575   Iteration 31 of 100, loss = 0.006708260648132813   Iteration 32 of 100, loss = 0.006619481879170053   Iteration 33 of 100, loss = 0.0065568638824377995   Iteration 34 of 100, loss = 0.006725899067104739   Iteration 35 of 100, loss = 0.006771106126585177   Iteration 36 of 100, loss = 0.0067620870993576115   Iteration 37 of 100, loss = 0.006699862411698779   Iteration 38 of 100, loss = 0.006720093385267414   Iteration 39 of 100, loss = 0.006704890372183843   Iteration 40 of 100, loss = 0.0067908349796198305   Iteration 41 of 100, loss = 0.006692397788666734   Iteration 42 of 100, loss = 0.00671475927811116   Iteration 43 of 100, loss = 0.0066980762071474345   Iteration 44 of 100, loss = 0.006816329397472807   Iteration 45 of 100, loss = 0.006802658659095565   Iteration 46 of 100, loss = 0.006914830366756929   Iteration 47 of 100, loss = 0.006872055284242997   Iteration 48 of 100, loss = 0.006827336964003432   Iteration 49 of 100, loss = 0.006802044899145864   Iteration 50 of 100, loss = 0.006876410054974258   Iteration 51 of 100, loss = 0.006934894445151382   Iteration 52 of 100, loss = 0.006901049193961976   Iteration 53 of 100, loss = 0.006884547974035706   Iteration 54 of 100, loss = 0.0069480740025432575   Iteration 55 of 100, loss = 0.006898257301443002   Iteration 56 of 100, loss = 0.006937213770080624   Iteration 57 of 100, loss = 0.0070123582580045125   Iteration 58 of 100, loss = 0.00696891352357664   Iteration 59 of 100, loss = 0.006952325825311117   Iteration 60 of 100, loss = 0.0069270051433704795   Iteration 61 of 100, loss = 0.006995109967185093   Iteration 62 of 100, loss = 0.007015241569118394   Iteration 63 of 100, loss = 0.00706229773202231   Iteration 64 of 100, loss = 0.007015404353296617   Iteration 65 of 100, loss = 0.006971168070315168   Iteration 66 of 100, loss = 0.006943019279843253   Iteration 67 of 100, loss = 0.006971849840996203   Iteration 68 of 100, loss = 0.006976085396565716   Iteration 69 of 100, loss = 0.006969649287318622   Iteration 70 of 100, loss = 0.006948968339046197   Iteration 71 of 100, loss = 0.0069535201461329845   Iteration 72 of 100, loss = 0.006955240933974791   Iteration 73 of 100, loss = 0.0069461725237587955   Iteration 74 of 100, loss = 0.0069339668623649995   Iteration 75 of 100, loss = 0.006880342715109388   Iteration 76 of 100, loss = 0.006842108434188719   Iteration 77 of 100, loss = 0.006798061215645307   Iteration 78 of 100, loss = 0.006762576582005773   Iteration 79 of 100, loss = 0.006783635385004403   Iteration 80 of 100, loss = 0.006739025341812521   Iteration 81 of 100, loss = 0.006747010807840176   Iteration 82 of 100, loss = 0.006759058797686565   Iteration 83 of 100, loss = 0.006755383466426508   Iteration 84 of 100, loss = 0.006765593314499017   Iteration 85 of 100, loss = 0.006768179783488021   Iteration 86 of 100, loss = 0.006772527346647409   Iteration 87 of 100, loss = 0.0068205254869642615   Iteration 88 of 100, loss = 0.006796430754051967   Iteration 89 of 100, loss = 0.00680979270111309   Iteration 90 of 100, loss = 0.006804471804449956   Iteration 91 of 100, loss = 0.006790142746867387   Iteration 92 of 100, loss = 0.006768706649460871   Iteration 93 of 100, loss = 0.006807519473455926   Iteration 94 of 100, loss = 0.00686260968684516   Iteration 95 of 100, loss = 0.006853185638197159   Iteration 96 of 100, loss = 0.0068548544610772906   Iteration 97 of 100, loss = 0.0068173177741928815   Iteration 98 of 100, loss = 0.006810220210261795   Iteration 99 of 100, loss = 0.006802811132123073   Iteration 100 of 100, loss = 0.0068184125190600756
   End of epoch 35; saving model... 

Epoch 36 of 2000
   Iteration 1 of 100, loss = 0.008821836672723293   Iteration 2 of 100, loss = 0.005816673161461949   Iteration 3 of 100, loss = 0.006389736508329709   Iteration 4 of 100, loss = 0.006283992202952504   Iteration 5 of 100, loss = 0.00632375841960311   Iteration 6 of 100, loss = 0.006112891482189298   Iteration 7 of 100, loss = 0.006875872678522553   Iteration 8 of 100, loss = 0.006859628949314356   Iteration 9 of 100, loss = 0.0065929594242738355   Iteration 10 of 100, loss = 0.006263218773528934   Iteration 11 of 100, loss = 0.00606737726114013   Iteration 12 of 100, loss = 0.006078840660241743   Iteration 13 of 100, loss = 0.005948565004823299   Iteration 14 of 100, loss = 0.005749656702391803   Iteration 15 of 100, loss = 0.0058759432130803665   Iteration 16 of 100, loss = 0.005883109857677482   Iteration 17 of 100, loss = 0.005905206685009248   Iteration 18 of 100, loss = 0.005781887396652665   Iteration 19 of 100, loss = 0.00592168561477018   Iteration 20 of 100, loss = 0.006003263348247856   Iteration 21 of 100, loss = 0.005878427442872808   Iteration 22 of 100, loss = 0.005830250003121116   Iteration 23 of 100, loss = 0.00581364623149452   Iteration 24 of 100, loss = 0.005877347469019393   Iteration 25 of 100, loss = 0.005793745992705226   Iteration 26 of 100, loss = 0.005720868044031354   Iteration 27 of 100, loss = 0.005639511427876574   Iteration 28 of 100, loss = 0.005814009969721415   Iteration 29 of 100, loss = 0.005742118637687687   Iteration 30 of 100, loss = 0.005895697860978544   Iteration 31 of 100, loss = 0.00611843602100928   Iteration 32 of 100, loss = 0.00607763525476912   Iteration 33 of 100, loss = 0.006266999883915891   Iteration 34 of 100, loss = 0.006242700462119982   Iteration 35 of 100, loss = 0.006274591619148851   Iteration 36 of 100, loss = 0.006314009757867704   Iteration 37 of 100, loss = 0.006325199967250228   Iteration 38 of 100, loss = 0.006260737139535577   Iteration 39 of 100, loss = 0.006260826109120479   Iteration 40 of 100, loss = 0.006220485060475766   Iteration 41 of 100, loss = 0.006160326358839506   Iteration 42 of 100, loss = 0.006065632926211471   Iteration 43 of 100, loss = 0.006136312604297039   Iteration 44 of 100, loss = 0.00623994968323545   Iteration 45 of 100, loss = 0.006373366030553977   Iteration 46 of 100, loss = 0.006360130576902758   Iteration 47 of 100, loss = 0.006451186515945703   Iteration 48 of 100, loss = 0.006487847237925355   Iteration 49 of 100, loss = 0.00652223187783847   Iteration 50 of 100, loss = 0.006530003007501364   Iteration 51 of 100, loss = 0.006540609651482573   Iteration 52 of 100, loss = 0.006471476168371737   Iteration 53 of 100, loss = 0.006496156706422005   Iteration 54 of 100, loss = 0.006465207975081823   Iteration 55 of 100, loss = 0.006444687497886744   Iteration 56 of 100, loss = 0.006476115817869348   Iteration 57 of 100, loss = 0.00651194709108064   Iteration 58 of 100, loss = 0.006528848244262667   Iteration 59 of 100, loss = 0.006542882258546049   Iteration 60 of 100, loss = 0.006555979799789687   Iteration 61 of 100, loss = 0.00658582061620765   Iteration 62 of 100, loss = 0.006584972391025194   Iteration 63 of 100, loss = 0.006546984803641126   Iteration 64 of 100, loss = 0.006559337241924368   Iteration 65 of 100, loss = 0.006583220812563712   Iteration 66 of 100, loss = 0.006532690625383772   Iteration 67 of 100, loss = 0.006587660061751506   Iteration 68 of 100, loss = 0.006540847291676875   Iteration 69 of 100, loss = 0.006543056627708501   Iteration 70 of 100, loss = 0.006507271222238029   Iteration 71 of 100, loss = 0.006503684879083868   Iteration 72 of 100, loss = 0.00647233177571454   Iteration 73 of 100, loss = 0.0064789583676890155   Iteration 74 of 100, loss = 0.006486800713212909   Iteration 75 of 100, loss = 0.006451712672909101   Iteration 76 of 100, loss = 0.006401480650406723   Iteration 77 of 100, loss = 0.00640238752866817   Iteration 78 of 100, loss = 0.006474649441094162   Iteration 79 of 100, loss = 0.006532716202325648   Iteration 80 of 100, loss = 0.006508302988368087   Iteration 81 of 100, loss = 0.0065052363371913445   Iteration 82 of 100, loss = 0.00650406763150652   Iteration 83 of 100, loss = 0.006489400412460946   Iteration 84 of 100, loss = 0.006532915942703507   Iteration 85 of 100, loss = 0.00652009116978768   Iteration 86 of 100, loss = 0.006497869974673661   Iteration 87 of 100, loss = 0.006498730374799891   Iteration 88 of 100, loss = 0.0064974290514576505   Iteration 89 of 100, loss = 0.006619092623776432   Iteration 90 of 100, loss = 0.006578754545706842   Iteration 91 of 100, loss = 0.006599596471290339   Iteration 92 of 100, loss = 0.006610841728220491   Iteration 93 of 100, loss = 0.006645410837385283   Iteration 94 of 100, loss = 0.006651621802333504   Iteration 95 of 100, loss = 0.006648988884530569   Iteration 96 of 100, loss = 0.0066508416493888944   Iteration 97 of 100, loss = 0.006634282721110533   Iteration 98 of 100, loss = 0.006605423535505424   Iteration 99 of 100, loss = 0.006575845976858729   Iteration 100 of 100, loss = 0.006560509321279824
   End of epoch 36; saving model... 

Epoch 37 of 2000
   Iteration 1 of 100, loss = 0.006176212802529335   Iteration 2 of 100, loss = 0.009149464312940836   Iteration 3 of 100, loss = 0.007880881894379854   Iteration 4 of 100, loss = 0.0076390833128243685   Iteration 5 of 100, loss = 0.007205286342650652   Iteration 6 of 100, loss = 0.0071097202599048615   Iteration 7 of 100, loss = 0.007323676853307656   Iteration 8 of 100, loss = 0.006993257615249604   Iteration 9 of 100, loss = 0.0071324059843189186   Iteration 10 of 100, loss = 0.007484903885051608   Iteration 11 of 100, loss = 0.007379724940454418   Iteration 12 of 100, loss = 0.007290312671102583   Iteration 13 of 100, loss = 0.007140491981632435   Iteration 14 of 100, loss = 0.007374017200033579   Iteration 15 of 100, loss = 0.007079521349320809   Iteration 16 of 100, loss = 0.006920361920492724   Iteration 17 of 100, loss = 0.006971229196471327   Iteration 18 of 100, loss = 0.006995098199695349   Iteration 19 of 100, loss = 0.006822868875276886   Iteration 20 of 100, loss = 0.006780534668359905   Iteration 21 of 100, loss = 0.006754528897415314   Iteration 22 of 100, loss = 0.006586588834497062   Iteration 23 of 100, loss = 0.006483060550754485   Iteration 24 of 100, loss = 0.006769660860300064   Iteration 25 of 100, loss = 0.006726743839681149   Iteration 26 of 100, loss = 0.006713218628787077   Iteration 27 of 100, loss = 0.006759623789952861   Iteration 28 of 100, loss = 0.006769444427586028   Iteration 29 of 100, loss = 0.006663317021367879   Iteration 30 of 100, loss = 0.0065786379544685285   Iteration 31 of 100, loss = 0.006539489968769973   Iteration 32 of 100, loss = 0.006556760068633594   Iteration 33 of 100, loss = 0.006665400807943308   Iteration 34 of 100, loss = 0.006635305800420397   Iteration 35 of 100, loss = 0.006692096777260304   Iteration 36 of 100, loss = 0.0066819999936140245   Iteration 37 of 100, loss = 0.006644283194799681   Iteration 38 of 100, loss = 0.006597807618642324   Iteration 39 of 100, loss = 0.0066143510003502555   Iteration 40 of 100, loss = 0.006557874893769622   Iteration 41 of 100, loss = 0.006550072169885403   Iteration 42 of 100, loss = 0.00667140477647384   Iteration 43 of 100, loss = 0.00665032455351117   Iteration 44 of 100, loss = 0.00664562264203348   Iteration 45 of 100, loss = 0.006719312092496289   Iteration 46 of 100, loss = 0.006753686025900685   Iteration 47 of 100, loss = 0.006807446975181711   Iteration 48 of 100, loss = 0.006863736838568002   Iteration 49 of 100, loss = 0.006893395332201403   Iteration 50 of 100, loss = 0.006802855953574181   Iteration 51 of 100, loss = 0.0067801657680641204   Iteration 52 of 100, loss = 0.006749722067839825   Iteration 53 of 100, loss = 0.00679957666346487   Iteration 54 of 100, loss = 0.006780291148633869   Iteration 55 of 100, loss = 0.006712758850136941   Iteration 56 of 100, loss = 0.006680378553158205   Iteration 57 of 100, loss = 0.006666090604930855   Iteration 58 of 100, loss = 0.006673419763783699   Iteration 59 of 100, loss = 0.006699178805890478   Iteration 60 of 100, loss = 0.00665664691089963   Iteration 61 of 100, loss = 0.00668932249784836   Iteration 62 of 100, loss = 0.006703717690411835   Iteration 63 of 100, loss = 0.006772288546291372   Iteration 64 of 100, loss = 0.006781887324905256   Iteration 65 of 100, loss = 0.006754804771536818   Iteration 66 of 100, loss = 0.006844215627731473   Iteration 67 of 100, loss = 0.006798278345768132   Iteration 68 of 100, loss = 0.006759863031808944   Iteration 69 of 100, loss = 0.006755199168633291   Iteration 70 of 100, loss = 0.006787667031000768   Iteration 71 of 100, loss = 0.0067472940205898085   Iteration 72 of 100, loss = 0.006695580607306005   Iteration 73 of 100, loss = 0.00663613040344662   Iteration 74 of 100, loss = 0.0066101301329311085   Iteration 75 of 100, loss = 0.006645632445191343   Iteration 76 of 100, loss = 0.006599044497737563   Iteration 77 of 100, loss = 0.00658113559308861   Iteration 78 of 100, loss = 0.006595330703884172   Iteration 79 of 100, loss = 0.006614175174220265   Iteration 80 of 100, loss = 0.006606769058271312   Iteration 81 of 100, loss = 0.006621652412124806   Iteration 82 of 100, loss = 0.006625915232977671   Iteration 83 of 100, loss = 0.0066192238114729345   Iteration 84 of 100, loss = 0.006624840956646949   Iteration 85 of 100, loss = 0.006631216930006357   Iteration 86 of 100, loss = 0.006621838154726077   Iteration 87 of 100, loss = 0.0065978605476818206   Iteration 88 of 100, loss = 0.0066694424048447136   Iteration 89 of 100, loss = 0.006640212806569559   Iteration 90 of 100, loss = 0.006629894660889275   Iteration 91 of 100, loss = 0.006694794496889789   Iteration 92 of 100, loss = 0.006680028125866438   Iteration 93 of 100, loss = 0.006700662462922034   Iteration 94 of 100, loss = 0.0067043364855480635   Iteration 95 of 100, loss = 0.006690564219790854   Iteration 96 of 100, loss = 0.006675033876187324   Iteration 97 of 100, loss = 0.006679191390897349   Iteration 98 of 100, loss = 0.006708865008811105   Iteration 99 of 100, loss = 0.006701509230723134   Iteration 100 of 100, loss = 0.006683250621426851
   End of epoch 37; saving model... 

Epoch 38 of 2000
   Iteration 1 of 100, loss = 0.00844014622271061   Iteration 2 of 100, loss = 0.006384647451341152   Iteration 3 of 100, loss = 0.007994107902050018   Iteration 4 of 100, loss = 0.007015895796939731   Iteration 5 of 100, loss = 0.006380114937201142   Iteration 6 of 100, loss = 0.005817789545593162   Iteration 7 of 100, loss = 0.005732493175725851   Iteration 8 of 100, loss = 0.006296329287579283   Iteration 9 of 100, loss = 0.006119260124655234   Iteration 10 of 100, loss = 0.0058122118934988976   Iteration 11 of 100, loss = 0.0056233953642235565   Iteration 12 of 100, loss = 0.0059188276645727456   Iteration 13 of 100, loss = 0.006123074169199054   Iteration 14 of 100, loss = 0.006065462167108697   Iteration 15 of 100, loss = 0.0060015457837531965   Iteration 16 of 100, loss = 0.0058606742531992495   Iteration 17 of 100, loss = 0.006021622842287316   Iteration 18 of 100, loss = 0.005877942635884715   Iteration 19 of 100, loss = 0.005895669412750162   Iteration 20 of 100, loss = 0.005998526781331748   Iteration 21 of 100, loss = 0.006270026954423104   Iteration 22 of 100, loss = 0.006268485057675703   Iteration 23 of 100, loss = 0.0065258549749041385   Iteration 24 of 100, loss = 0.006461814307840541   Iteration 25 of 100, loss = 0.006495062215253711   Iteration 26 of 100, loss = 0.006504296978863959   Iteration 27 of 100, loss = 0.006379894541438531   Iteration 28 of 100, loss = 0.006580711517017335   Iteration 29 of 100, loss = 0.006556905990723392   Iteration 30 of 100, loss = 0.006694562942720949   Iteration 31 of 100, loss = 0.006644170798902069   Iteration 32 of 100, loss = 0.006566735428350512   Iteration 33 of 100, loss = 0.0065374164489295445   Iteration 34 of 100, loss = 0.006655793534317876   Iteration 35 of 100, loss = 0.006829464761540294   Iteration 36 of 100, loss = 0.006850266395809336   Iteration 37 of 100, loss = 0.006748953261538534   Iteration 38 of 100, loss = 0.0066903945193380904   Iteration 39 of 100, loss = 0.006764257368512261   Iteration 40 of 100, loss = 0.0068885824584867805   Iteration 41 of 100, loss = 0.006822903350949651   Iteration 42 of 100, loss = 0.006804680845345415   Iteration 43 of 100, loss = 0.006799656112656691   Iteration 44 of 100, loss = 0.0068477077610706065   Iteration 45 of 100, loss = 0.006842924318172865   Iteration 46 of 100, loss = 0.006922556305020724   Iteration 47 of 100, loss = 0.006972122338025811   Iteration 48 of 100, loss = 0.006958274534554221   Iteration 49 of 100, loss = 0.006925455736452524   Iteration 50 of 100, loss = 0.006876489049755036   Iteration 51 of 100, loss = 0.00690500496192744   Iteration 52 of 100, loss = 0.006856561983183313   Iteration 53 of 100, loss = 0.006796370625039036   Iteration 54 of 100, loss = 0.006826930502602072   Iteration 55 of 100, loss = 0.006851859352636066   Iteration 56 of 100, loss = 0.006794171021153618   Iteration 57 of 100, loss = 0.00674653168065114   Iteration 58 of 100, loss = 0.006736933241662537   Iteration 59 of 100, loss = 0.006739455184473072   Iteration 60 of 100, loss = 0.006668189412448555   Iteration 61 of 100, loss = 0.0067189670144961995   Iteration 62 of 100, loss = 0.006694861751560482   Iteration 63 of 100, loss = 0.006650773013779331   Iteration 64 of 100, loss = 0.006655985871475423   Iteration 65 of 100, loss = 0.006656737450080422   Iteration 66 of 100, loss = 0.006675956400365315   Iteration 67 of 100, loss = 0.006617596866423959   Iteration 68 of 100, loss = 0.006596316843677093   Iteration 69 of 100, loss = 0.0065647970642084665   Iteration 70 of 100, loss = 0.0066240945431802955   Iteration 71 of 100, loss = 0.006716163986375634   Iteration 72 of 100, loss = 0.0067502409737143255   Iteration 73 of 100, loss = 0.006721474874560556   Iteration 74 of 100, loss = 0.0067312947184954945   Iteration 75 of 100, loss = 0.006746460292488337   Iteration 76 of 100, loss = 0.006721832329946521   Iteration 77 of 100, loss = 0.006750074015664203   Iteration 78 of 100, loss = 0.0067638719203667   Iteration 79 of 100, loss = 0.006758340911444606   Iteration 80 of 100, loss = 0.006727165705524385   Iteration 81 of 100, loss = 0.006741725690202948   Iteration 82 of 100, loss = 0.006741216116607553   Iteration 83 of 100, loss = 0.006757419303912355   Iteration 84 of 100, loss = 0.006779774452470953   Iteration 85 of 100, loss = 0.006814864491496016   Iteration 86 of 100, loss = 0.006816798479967686   Iteration 87 of 100, loss = 0.0068107901419373765   Iteration 88 of 100, loss = 0.006837480055930262   Iteration 89 of 100, loss = 0.006835722343556666   Iteration 90 of 100, loss = 0.006814585098375877   Iteration 91 of 100, loss = 0.006826689425896812   Iteration 92 of 100, loss = 0.006794769238457893   Iteration 93 of 100, loss = 0.006754310776589698   Iteration 94 of 100, loss = 0.006753304517491066   Iteration 95 of 100, loss = 0.006726436714004529   Iteration 96 of 100, loss = 0.006702427199343219   Iteration 97 of 100, loss = 0.006663197241051449   Iteration 98 of 100, loss = 0.006623862147312231   Iteration 99 of 100, loss = 0.006609804220403535   Iteration 100 of 100, loss = 0.006582272613886744
   End of epoch 38; saving model... 

Epoch 39 of 2000
   Iteration 1 of 100, loss = 0.005120102781802416   Iteration 2 of 100, loss = 0.008270778926089406   Iteration 3 of 100, loss = 0.006531085120514035   Iteration 4 of 100, loss = 0.006156278133857995   Iteration 5 of 100, loss = 0.006053898623213172   Iteration 6 of 100, loss = 0.006608617142774165   Iteration 7 of 100, loss = 0.0067300397703158   Iteration 8 of 100, loss = 0.0066943752754013985   Iteration 9 of 100, loss = 0.006429025877474083   Iteration 10 of 100, loss = 0.006280725752003491   Iteration 11 of 100, loss = 0.006113783054223115   Iteration 12 of 100, loss = 0.006057513470295817   Iteration 13 of 100, loss = 0.006314973114058375   Iteration 14 of 100, loss = 0.006076065124943852   Iteration 15 of 100, loss = 0.005871266452595591   Iteration 16 of 100, loss = 0.005928161248448305   Iteration 17 of 100, loss = 0.006073235356084564   Iteration 18 of 100, loss = 0.006110655648323397   Iteration 19 of 100, loss = 0.006127073882931941   Iteration 20 of 100, loss = 0.006197485292796045   Iteration 21 of 100, loss = 0.0062650888603890224   Iteration 22 of 100, loss = 0.006248613216236911   Iteration 23 of 100, loss = 0.006386213439881154   Iteration 24 of 100, loss = 0.006293169426498935   Iteration 25 of 100, loss = 0.006239498676732183   Iteration 26 of 100, loss = 0.006293871431038356   Iteration 27 of 100, loss = 0.006215746160941543   Iteration 28 of 100, loss = 0.006182496826763132   Iteration 29 of 100, loss = 0.006334662365181179   Iteration 30 of 100, loss = 0.006385466634916763   Iteration 31 of 100, loss = 0.006447131437579951   Iteration 32 of 100, loss = 0.00645233867544448   Iteration 33 of 100, loss = 0.006509882362672325   Iteration 34 of 100, loss = 0.006432108327691608   Iteration 35 of 100, loss = 0.00639607551773744   Iteration 36 of 100, loss = 0.006473538795641313   Iteration 37 of 100, loss = 0.006475919322739984   Iteration 38 of 100, loss = 0.006506087436144681   Iteration 39 of 100, loss = 0.006440012554566448   Iteration 40 of 100, loss = 0.006501904694596305   Iteration 41 of 100, loss = 0.006553725208859981   Iteration 42 of 100, loss = 0.006532553223050421   Iteration 43 of 100, loss = 0.0065836456961669895   Iteration 44 of 100, loss = 0.006583272992760281   Iteration 45 of 100, loss = 0.006660450441348884   Iteration 46 of 100, loss = 0.006620128613734699   Iteration 47 of 100, loss = 0.006561714610917137   Iteration 48 of 100, loss = 0.006493641669900778   Iteration 49 of 100, loss = 0.006431527240962094   Iteration 50 of 100, loss = 0.006501279673539102   Iteration 51 of 100, loss = 0.0065479546410999465   Iteration 52 of 100, loss = 0.006498632007815803   Iteration 53 of 100, loss = 0.006449521826755888   Iteration 54 of 100, loss = 0.006448346285011481   Iteration 55 of 100, loss = 0.006430803510275754   Iteration 56 of 100, loss = 0.006413250246883503   Iteration 57 of 100, loss = 0.006342719456082896   Iteration 58 of 100, loss = 0.006400120813913387   Iteration 59 of 100, loss = 0.006396654795981564   Iteration 60 of 100, loss = 0.006367061853719254   Iteration 61 of 100, loss = 0.006438349106455924   Iteration 62 of 100, loss = 0.00645981342231314   Iteration 63 of 100, loss = 0.006546701326788891   Iteration 64 of 100, loss = 0.00657767314260127   Iteration 65 of 100, loss = 0.006631140375080017   Iteration 66 of 100, loss = 0.006606479521107041   Iteration 67 of 100, loss = 0.006701628267487038   Iteration 68 of 100, loss = 0.006720425020081594   Iteration 69 of 100, loss = 0.006691003474744333   Iteration 70 of 100, loss = 0.006639654279154326   Iteration 71 of 100, loss = 0.00661954200747882   Iteration 72 of 100, loss = 0.006659351531804229   Iteration 73 of 100, loss = 0.006677829287308332   Iteration 74 of 100, loss = 0.006641699658782297   Iteration 75 of 100, loss = 0.006632558812076847   Iteration 76 of 100, loss = 0.006667327022449554   Iteration 77 of 100, loss = 0.00666922507142382   Iteration 78 of 100, loss = 0.006618422103854708   Iteration 79 of 100, loss = 0.006571551879184155   Iteration 80 of 100, loss = 0.006567931460449472   Iteration 81 of 100, loss = 0.0066103495622950575   Iteration 82 of 100, loss = 0.006559353767576196   Iteration 83 of 100, loss = 0.006557394663455436   Iteration 84 of 100, loss = 0.006542949296999723   Iteration 85 of 100, loss = 0.006604423190412276   Iteration 86 of 100, loss = 0.006596583372176906   Iteration 87 of 100, loss = 0.006570902243577714   Iteration 88 of 100, loss = 0.006523643511834301   Iteration 89 of 100, loss = 0.006531204873947113   Iteration 90 of 100, loss = 0.006551958033297625   Iteration 91 of 100, loss = 0.006534107763750048   Iteration 92 of 100, loss = 0.0065788562161564505   Iteration 93 of 100, loss = 0.006542088884499765   Iteration 94 of 100, loss = 0.006526126551065356   Iteration 95 of 100, loss = 0.006495087270281817   Iteration 96 of 100, loss = 0.006494132530254622   Iteration 97 of 100, loss = 0.006494088391245333   Iteration 98 of 100, loss = 0.0064883178233035976   Iteration 99 of 100, loss = 0.006492538495233866   Iteration 100 of 100, loss = 0.006461924372706563
   End of epoch 39; saving model... 

Epoch 40 of 2000
   Iteration 1 of 100, loss = 0.00908794067800045   Iteration 2 of 100, loss = 0.008877568412572145   Iteration 3 of 100, loss = 0.00785908087467154   Iteration 4 of 100, loss = 0.007644793950021267   Iteration 5 of 100, loss = 0.007784387655556202   Iteration 6 of 100, loss = 0.00755970343016088   Iteration 7 of 100, loss = 0.007347919446017061   Iteration 8 of 100, loss = 0.007993267616257071   Iteration 9 of 100, loss = 0.008152432843214936   Iteration 10 of 100, loss = 0.008724856469780207   Iteration 11 of 100, loss = 0.008786080997775902   Iteration 12 of 100, loss = 0.00862087782782813   Iteration 13 of 100, loss = 0.00835024411431872   Iteration 14 of 100, loss = 0.008285582298412919   Iteration 15 of 100, loss = 0.008262541114042203   Iteration 16 of 100, loss = 0.008161953504895791   Iteration 17 of 100, loss = 0.00811071102233494   Iteration 18 of 100, loss = 0.007817255074365271   Iteration 19 of 100, loss = 0.008004103983311276   Iteration 20 of 100, loss = 0.007979106064885855   Iteration 21 of 100, loss = 0.007752065580072147   Iteration 22 of 100, loss = 0.007648485871455209   Iteration 23 of 100, loss = 0.007578326520793464   Iteration 24 of 100, loss = 0.007587918982608244   Iteration 25 of 100, loss = 0.007533558243885637   Iteration 26 of 100, loss = 0.007569410453120677   Iteration 27 of 100, loss = 0.007630782555443821   Iteration 28 of 100, loss = 0.007585463588059481   Iteration 29 of 100, loss = 0.0074928255896244585   Iteration 30 of 100, loss = 0.007421870366670191   Iteration 31 of 100, loss = 0.007402210834345991   Iteration 32 of 100, loss = 0.0073018660841626115   Iteration 33 of 100, loss = 0.007175965157027046   Iteration 34 of 100, loss = 0.007076899527900797   Iteration 35 of 100, loss = 0.007004042242520622   Iteration 36 of 100, loss = 0.006906846344160537   Iteration 37 of 100, loss = 0.006941397384916608   Iteration 38 of 100, loss = 0.006976651211612318   Iteration 39 of 100, loss = 0.006919356588369761   Iteration 40 of 100, loss = 0.006838240107754245   Iteration 41 of 100, loss = 0.006758224185011009   Iteration 42 of 100, loss = 0.006887080779831324   Iteration 43 of 100, loss = 0.0068616045443990895   Iteration 44 of 100, loss = 0.006758207243613221   Iteration 45 of 100, loss = 0.0067321052153905235   Iteration 46 of 100, loss = 0.006708053001405105   Iteration 47 of 100, loss = 0.006656324887212286   Iteration 48 of 100, loss = 0.006629032985074446   Iteration 49 of 100, loss = 0.006651891566508887   Iteration 50 of 100, loss = 0.006647194027900696   Iteration 51 of 100, loss = 0.006638216859131467   Iteration 52 of 100, loss = 0.006598290235090714   Iteration 53 of 100, loss = 0.006608786896082028   Iteration 54 of 100, loss = 0.00670775271848672   Iteration 55 of 100, loss = 0.0067035215060141954   Iteration 56 of 100, loss = 0.006686032458674163   Iteration 57 of 100, loss = 0.006704846552262704   Iteration 58 of 100, loss = 0.0067434081213613006   Iteration 59 of 100, loss = 0.006811837989331807   Iteration 60 of 100, loss = 0.006835604016669094   Iteration 61 of 100, loss = 0.0067882478756249925   Iteration 62 of 100, loss = 0.006758790538315812   Iteration 63 of 100, loss = 0.006755604645207761   Iteration 64 of 100, loss = 0.006757245086191688   Iteration 65 of 100, loss = 0.006743776633475835   Iteration 66 of 100, loss = 0.006723989570287593   Iteration 67 of 100, loss = 0.006736428685375114   Iteration 68 of 100, loss = 0.006792978945133441   Iteration 69 of 100, loss = 0.006754622308780317   Iteration 70 of 100, loss = 0.006724299217707345   Iteration 71 of 100, loss = 0.006710467551847998   Iteration 72 of 100, loss = 0.006677926847866426   Iteration 73 of 100, loss = 0.0066607287982861476   Iteration 74 of 100, loss = 0.006658686186514191   Iteration 75 of 100, loss = 0.006659389150639375   Iteration 76 of 100, loss = 0.006680059798159881   Iteration 77 of 100, loss = 0.006698360956915013   Iteration 78 of 100, loss = 0.0067026221479934   Iteration 79 of 100, loss = 0.006674167517384019   Iteration 80 of 100, loss = 0.006636009746580384   Iteration 81 of 100, loss = 0.006617717465017865   Iteration 82 of 100, loss = 0.006584177940811326   Iteration 83 of 100, loss = 0.006550570801237082   Iteration 84 of 100, loss = 0.006544549719408332   Iteration 85 of 100, loss = 0.006510844769175439   Iteration 86 of 100, loss = 0.006505488967631272   Iteration 87 of 100, loss = 0.00649838481130528   Iteration 88 of 100, loss = 0.006509873230243102   Iteration 89 of 100, loss = 0.006493422969275814   Iteration 90 of 100, loss = 0.006473469705734816   Iteration 91 of 100, loss = 0.0064593491088189596   Iteration 92 of 100, loss = 0.0064346640416340015   Iteration 93 of 100, loss = 0.006449797002959156   Iteration 94 of 100, loss = 0.006439968004842546   Iteration 95 of 100, loss = 0.006433365756253663   Iteration 96 of 100, loss = 0.006412989185870781   Iteration 97 of 100, loss = 0.006422666796799941   Iteration 98 of 100, loss = 0.006391577876401038   Iteration 99 of 100, loss = 0.006353601759224377   Iteration 100 of 100, loss = 0.006382856231648475
   End of epoch 40; saving model... 

Epoch 41 of 2000
   Iteration 1 of 100, loss = 0.004889311268925667   Iteration 2 of 100, loss = 0.005826625507324934   Iteration 3 of 100, loss = 0.006285959389060736   Iteration 4 of 100, loss = 0.005688836157787591   Iteration 5 of 100, loss = 0.006059498386457562   Iteration 6 of 100, loss = 0.005831045447848737   Iteration 7 of 100, loss = 0.005774515315092036   Iteration 8 of 100, loss = 0.005631508975056931   Iteration 9 of 100, loss = 0.005807527418558796   Iteration 10 of 100, loss = 0.0060478993458673354   Iteration 11 of 100, loss = 0.006035202923654156   Iteration 12 of 100, loss = 0.005787508309974025   Iteration 13 of 100, loss = 0.005760390902511203   Iteration 14 of 100, loss = 0.005631505495070347   Iteration 15 of 100, loss = 0.0057231504935771225   Iteration 16 of 100, loss = 0.005665132470312528   Iteration 17 of 100, loss = 0.005581113797448137   Iteration 18 of 100, loss = 0.005486676792821122   Iteration 19 of 100, loss = 0.005551452049985528   Iteration 20 of 100, loss = 0.005497251485940069   Iteration 21 of 100, loss = 0.005495897372297588   Iteration 22 of 100, loss = 0.005597049084661359   Iteration 23 of 100, loss = 0.005544699151473848   Iteration 24 of 100, loss = 0.005710640291605766   Iteration 25 of 100, loss = 0.005606477912515402   Iteration 26 of 100, loss = 0.005531703901047317   Iteration 27 of 100, loss = 0.005465007240504578   Iteration 28 of 100, loss = 0.005396725551690906   Iteration 29 of 100, loss = 0.005344444869792667   Iteration 30 of 100, loss = 0.0053061093824605145   Iteration 31 of 100, loss = 0.005353806375135337   Iteration 32 of 100, loss = 0.005462968940264545   Iteration 33 of 100, loss = 0.005456101022322069   Iteration 34 of 100, loss = 0.005571767400183222   Iteration 35 of 100, loss = 0.005529000769768443   Iteration 36 of 100, loss = 0.005560731631703675   Iteration 37 of 100, loss = 0.0057241973416829435   Iteration 38 of 100, loss = 0.005681010392053347   Iteration 39 of 100, loss = 0.005678644773956292   Iteration 40 of 100, loss = 0.005720393685624004   Iteration 41 of 100, loss = 0.0057385590427168984   Iteration 42 of 100, loss = 0.0056670659133011385   Iteration 43 of 100, loss = 0.0057069207649937895   Iteration 44 of 100, loss = 0.005765882744030519   Iteration 45 of 100, loss = 0.005795652667681376   Iteration 46 of 100, loss = 0.0058209901149182215   Iteration 47 of 100, loss = 0.005845767990785076   Iteration 48 of 100, loss = 0.005892438377486542   Iteration 49 of 100, loss = 0.005962293756631564   Iteration 50 of 100, loss = 0.0059353414550423625   Iteration 51 of 100, loss = 0.005944554821825495   Iteration 52 of 100, loss = 0.005907705546213457   Iteration 53 of 100, loss = 0.005941577378730729   Iteration 54 of 100, loss = 0.005895949085243046   Iteration 55 of 100, loss = 0.005935440021990375   Iteration 56 of 100, loss = 0.005956700616349865   Iteration 57 of 100, loss = 0.005931481894661198   Iteration 58 of 100, loss = 0.005904297597288829   Iteration 59 of 100, loss = 0.005897643719405188   Iteration 60 of 100, loss = 0.006012266622080157   Iteration 61 of 100, loss = 0.0059724886420747785   Iteration 62 of 100, loss = 0.005985815637564707   Iteration 63 of 100, loss = 0.006031213834556559   Iteration 64 of 100, loss = 0.00599361597414827   Iteration 65 of 100, loss = 0.006007347563998057   Iteration 66 of 100, loss = 0.005999047654878461   Iteration 67 of 100, loss = 0.0059391829748151465   Iteration 68 of 100, loss = 0.00590026457040735   Iteration 69 of 100, loss = 0.0058722926634431315   Iteration 70 of 100, loss = 0.005852967843280307   Iteration 71 of 100, loss = 0.00579990926657764   Iteration 72 of 100, loss = 0.00579280362257527   Iteration 73 of 100, loss = 0.005750063876940372   Iteration 74 of 100, loss = 0.005734978784882539   Iteration 75 of 100, loss = 0.005804731522997221   Iteration 76 of 100, loss = 0.005857507759509118   Iteration 77 of 100, loss = 0.005819242384115403   Iteration 78 of 100, loss = 0.005793744483246253   Iteration 79 of 100, loss = 0.005780704272321508   Iteration 80 of 100, loss = 0.005740380147472024   Iteration 81 of 100, loss = 0.005795134277439412   Iteration 82 of 100, loss = 0.0057951088756232   Iteration 83 of 100, loss = 0.005745549805473581   Iteration 84 of 100, loss = 0.005776914896809363   Iteration 85 of 100, loss = 0.005752895798479371   Iteration 86 of 100, loss = 0.0057335532105224594   Iteration 87 of 100, loss = 0.005729804311921799   Iteration 88 of 100, loss = 0.005741394991425544   Iteration 89 of 100, loss = 0.005707368548969958   Iteration 90 of 100, loss = 0.005776394201287379   Iteration 91 of 100, loss = 0.005856450085507726   Iteration 92 of 100, loss = 0.005851523476177017   Iteration 93 of 100, loss = 0.005862251776570995   Iteration 94 of 100, loss = 0.005831297527889702   Iteration 95 of 100, loss = 0.005812940071336925   Iteration 96 of 100, loss = 0.005833777464431478   Iteration 97 of 100, loss = 0.005863986190494879   Iteration 98 of 100, loss = 0.0058605997283866975   Iteration 99 of 100, loss = 0.00584897344503928   Iteration 100 of 100, loss = 0.005851019291440025
   End of epoch 41; saving model... 

Epoch 42 of 2000
   Iteration 1 of 100, loss = 0.005513378884643316   Iteration 2 of 100, loss = 0.006269307341426611   Iteration 3 of 100, loss = 0.005376209349681933   Iteration 4 of 100, loss = 0.004706872336100787   Iteration 5 of 100, loss = 0.004900136822834611   Iteration 6 of 100, loss = 0.005022239754907787   Iteration 7 of 100, loss = 0.005665204654048596   Iteration 8 of 100, loss = 0.0055665595282334834   Iteration 9 of 100, loss = 0.0058749639170451295   Iteration 10 of 100, loss = 0.005773742427118122   Iteration 11 of 100, loss = 0.0060167268807576465   Iteration 12 of 100, loss = 0.006137538216232012   Iteration 13 of 100, loss = 0.006289364393943777   Iteration 14 of 100, loss = 0.006320921354927123   Iteration 15 of 100, loss = 0.006489616182322303   Iteration 16 of 100, loss = 0.006660469618509524   Iteration 17 of 100, loss = 0.006575637264177203   Iteration 18 of 100, loss = 0.0068420704014392365   Iteration 19 of 100, loss = 0.006885845422450649   Iteration 20 of 100, loss = 0.006889111350756138   Iteration 21 of 100, loss = 0.00679072865196282   Iteration 22 of 100, loss = 0.006605697732249444   Iteration 23 of 100, loss = 0.006534454311527636   Iteration 24 of 100, loss = 0.006800073412402223   Iteration 25 of 100, loss = 0.006764383651316166   Iteration 26 of 100, loss = 0.006926839454815938   Iteration 27 of 100, loss = 0.006851574492261365   Iteration 28 of 100, loss = 0.0067695618074919495   Iteration 29 of 100, loss = 0.006719773940356641   Iteration 30 of 100, loss = 0.006780836901937922   Iteration 31 of 100, loss = 0.006737815741930277   Iteration 32 of 100, loss = 0.006699449266307056   Iteration 33 of 100, loss = 0.0067092978085080785   Iteration 34 of 100, loss = 0.006602952188319143   Iteration 35 of 100, loss = 0.0067125702143779825   Iteration 36 of 100, loss = 0.006632877707791825   Iteration 37 of 100, loss = 0.006608894384289916   Iteration 38 of 100, loss = 0.006700060293568592   Iteration 39 of 100, loss = 0.006706293266362105   Iteration 40 of 100, loss = 0.006668845051899552   Iteration 41 of 100, loss = 0.006676085815742248   Iteration 42 of 100, loss = 0.006647156884095499   Iteration 43 of 100, loss = 0.006589086130694594   Iteration 44 of 100, loss = 0.006510025345381688   Iteration 45 of 100, loss = 0.006618627502272527   Iteration 46 of 100, loss = 0.006601827249497823   Iteration 47 of 100, loss = 0.0065089537207275   Iteration 48 of 100, loss = 0.0065696933985843016   Iteration 49 of 100, loss = 0.006484301432929173   Iteration 50 of 100, loss = 0.006441405895166099   Iteration 51 of 100, loss = 0.006403734610762959   Iteration 52 of 100, loss = 0.006480447352469827   Iteration 53 of 100, loss = 0.0065805840455347075   Iteration 54 of 100, loss = 0.0066951263342397635   Iteration 55 of 100, loss = 0.006665641886436127   Iteration 56 of 100, loss = 0.006683960245157193   Iteration 57 of 100, loss = 0.0066347674777110415   Iteration 58 of 100, loss = 0.006607281349213986   Iteration 59 of 100, loss = 0.006553692178863843   Iteration 60 of 100, loss = 0.0067043559974990785   Iteration 61 of 100, loss = 0.006663844542822144   Iteration 62 of 100, loss = 0.006658501325986318   Iteration 63 of 100, loss = 0.006657293277038704   Iteration 64 of 100, loss = 0.006658208414592082   Iteration 65 of 100, loss = 0.0066604193264188675   Iteration 66 of 100, loss = 0.006663634297155747   Iteration 67 of 100, loss = 0.006642339372340201   Iteration 68 of 100, loss = 0.0066609730882405795   Iteration 69 of 100, loss = 0.006641295883615596   Iteration 70 of 100, loss = 0.006602148448915354   Iteration 71 of 100, loss = 0.006578258576501213   Iteration 72 of 100, loss = 0.006527249998826947   Iteration 73 of 100, loss = 0.006556311060916887   Iteration 74 of 100, loss = 0.0065865084856144476   Iteration 75 of 100, loss = 0.006532696889092525   Iteration 76 of 100, loss = 0.00651657693455682   Iteration 77 of 100, loss = 0.006474027122890988   Iteration 78 of 100, loss = 0.0064343003383001834   Iteration 79 of 100, loss = 0.006463002917486467   Iteration 80 of 100, loss = 0.006531424235436134   Iteration 81 of 100, loss = 0.006531458368156979   Iteration 82 of 100, loss = 0.006537413227417302   Iteration 83 of 100, loss = 0.006514367756871395   Iteration 84 of 100, loss = 0.006581331811113549   Iteration 85 of 100, loss = 0.006563487947534989   Iteration 86 of 100, loss = 0.00652563605771595   Iteration 87 of 100, loss = 0.006485802763751869   Iteration 88 of 100, loss = 0.006444852693345059   Iteration 89 of 100, loss = 0.006405460172113073   Iteration 90 of 100, loss = 0.006403274259840449   Iteration 91 of 100, loss = 0.006434167975784986   Iteration 92 of 100, loss = 0.006493221264858933   Iteration 93 of 100, loss = 0.0064558829281038494   Iteration 94 of 100, loss = 0.006457490722668615   Iteration 95 of 100, loss = 0.006420942273383078   Iteration 96 of 100, loss = 0.006444920635355326   Iteration 97 of 100, loss = 0.006446448140345591   Iteration 98 of 100, loss = 0.006462676284302559   Iteration 99 of 100, loss = 0.006438070075642882   Iteration 100 of 100, loss = 0.006468231468461454
   End of epoch 42; saving model... 

Epoch 43 of 2000
   Iteration 1 of 100, loss = 0.010930447839200497   Iteration 2 of 100, loss = 0.009584429673850536   Iteration 3 of 100, loss = 0.008084085614730915   Iteration 4 of 100, loss = 0.007350387633778155   Iteration 5 of 100, loss = 0.007150146923959255   Iteration 6 of 100, loss = 0.006853628437966108   Iteration 7 of 100, loss = 0.006658241086240325   Iteration 8 of 100, loss = 0.006546453223563731   Iteration 9 of 100, loss = 0.006365026813000441   Iteration 10 of 100, loss = 0.00631715557537973   Iteration 11 of 100, loss = 0.006255860694430091   Iteration 12 of 100, loss = 0.006274068689284225   Iteration 13 of 100, loss = 0.006086774349499207   Iteration 14 of 100, loss = 0.006099584279581904   Iteration 15 of 100, loss = 0.005880657738695542   Iteration 16 of 100, loss = 0.0059573228063527495   Iteration 17 of 100, loss = 0.006156766924130566   Iteration 18 of 100, loss = 0.006149009982537892   Iteration 19 of 100, loss = 0.006286481321838342   Iteration 20 of 100, loss = 0.006193805602379143   Iteration 21 of 100, loss = 0.006033116108959629   Iteration 22 of 100, loss = 0.006068860286508094   Iteration 23 of 100, loss = 0.006093061225407798   Iteration 24 of 100, loss = 0.006170413786700617   Iteration 25 of 100, loss = 0.0061749909445643425   Iteration 26 of 100, loss = 0.006313091502166712   Iteration 27 of 100, loss = 0.0064665863152455405   Iteration 28 of 100, loss = 0.00637791961032365   Iteration 29 of 100, loss = 0.00629617989962471   Iteration 30 of 100, loss = 0.006316663340354959   Iteration 31 of 100, loss = 0.006301643462070535   Iteration 32 of 100, loss = 0.0062543236708734185   Iteration 33 of 100, loss = 0.0061477681650131035   Iteration 34 of 100, loss = 0.006169781143612722   Iteration 35 of 100, loss = 0.006169068839933191   Iteration 36 of 100, loss = 0.0061706661169106765   Iteration 37 of 100, loss = 0.006130443483188345   Iteration 38 of 100, loss = 0.006312893752596881   Iteration 39 of 100, loss = 0.006235631397710397   Iteration 40 of 100, loss = 0.006285933824256062   Iteration 41 of 100, loss = 0.0062143979253383675   Iteration 42 of 100, loss = 0.006134115902352191   Iteration 43 of 100, loss = 0.0060862344689667225   Iteration 44 of 100, loss = 0.006082721710713072   Iteration 45 of 100, loss = 0.006034436107923587   Iteration 46 of 100, loss = 0.0059757738971434856   Iteration 47 of 100, loss = 0.006018913326230138   Iteration 48 of 100, loss = 0.006038133389665745   Iteration 49 of 100, loss = 0.006146555904261008   Iteration 50 of 100, loss = 0.006175158419646323   Iteration 51 of 100, loss = 0.006146364603374226   Iteration 52 of 100, loss = 0.006205134841506011   Iteration 53 of 100, loss = 0.0062619662922719175   Iteration 54 of 100, loss = 0.0062269764409090085   Iteration 55 of 100, loss = 0.006213790309530768   Iteration 56 of 100, loss = 0.006155921620250281   Iteration 57 of 100, loss = 0.006132231502417932   Iteration 58 of 100, loss = 0.00611901488797418   Iteration 59 of 100, loss = 0.0062465724866774125   Iteration 60 of 100, loss = 0.0062470746769880256   Iteration 61 of 100, loss = 0.006255069556722387   Iteration 62 of 100, loss = 0.0062602656187429545   Iteration 63 of 100, loss = 0.006231993880300294   Iteration 64 of 100, loss = 0.006252758343180176   Iteration 65 of 100, loss = 0.006234363867686345   Iteration 66 of 100, loss = 0.006240695122290741   Iteration 67 of 100, loss = 0.006265883723190471   Iteration 68 of 100, loss = 0.0062784266671823226   Iteration 69 of 100, loss = 0.006252911859664364   Iteration 70 of 100, loss = 0.006279053006853376   Iteration 71 of 100, loss = 0.006270195646080333   Iteration 72 of 100, loss = 0.006312720361165702   Iteration 73 of 100, loss = 0.006253338135038949   Iteration 74 of 100, loss = 0.00628215991703139   Iteration 75 of 100, loss = 0.006277122320607304   Iteration 76 of 100, loss = 0.0063002427372052085   Iteration 77 of 100, loss = 0.00631484228137929   Iteration 78 of 100, loss = 0.006294354853124764   Iteration 79 of 100, loss = 0.0062836380999629635   Iteration 80 of 100, loss = 0.006339808469056152   Iteration 81 of 100, loss = 0.006322076069880967   Iteration 82 of 100, loss = 0.006312156098940205   Iteration 83 of 100, loss = 0.006287029745191874   Iteration 84 of 100, loss = 0.006295649503867719   Iteration 85 of 100, loss = 0.006299044205533231   Iteration 86 of 100, loss = 0.006277932149228142   Iteration 87 of 100, loss = 0.006312139752460109   Iteration 88 of 100, loss = 0.0062758286896331065   Iteration 89 of 100, loss = 0.006279674175540718   Iteration 90 of 100, loss = 0.006244826187483139   Iteration 91 of 100, loss = 0.0062226636263613515   Iteration 92 of 100, loss = 0.006191738278847997   Iteration 93 of 100, loss = 0.006207297120483652   Iteration 94 of 100, loss = 0.006198268373833692   Iteration 95 of 100, loss = 0.006167762157948393   Iteration 96 of 100, loss = 0.006170059243837993   Iteration 97 of 100, loss = 0.006143566830679006   Iteration 98 of 100, loss = 0.006119579780010545   Iteration 99 of 100, loss = 0.006098038573382479   Iteration 100 of 100, loss = 0.006080861547961831
   End of epoch 43; saving model... 

Epoch 44 of 2000
   Iteration 1 of 100, loss = 0.005704168695956469   Iteration 2 of 100, loss = 0.007835766533389688   Iteration 3 of 100, loss = 0.007434451797356208   Iteration 4 of 100, loss = 0.00667399272788316   Iteration 5 of 100, loss = 0.007075340207666159   Iteration 6 of 100, loss = 0.006887504132464528   Iteration 7 of 100, loss = 0.006987463483320815   Iteration 8 of 100, loss = 0.0067456819815561175   Iteration 9 of 100, loss = 0.006433669167260329   Iteration 10 of 100, loss = 0.0062931232620030645   Iteration 11 of 100, loss = 0.006191213996234265   Iteration 12 of 100, loss = 0.006189577320280175   Iteration 13 of 100, loss = 0.006587735771273191   Iteration 14 of 100, loss = 0.006400339737800615   Iteration 15 of 100, loss = 0.006701827763269345   Iteration 16 of 100, loss = 0.006713726703310385   Iteration 17 of 100, loss = 0.006850779741345083   Iteration 18 of 100, loss = 0.006798446074955993   Iteration 19 of 100, loss = 0.006864188435046296   Iteration 20 of 100, loss = 0.00697160535492003   Iteration 21 of 100, loss = 0.006973581078151862   Iteration 22 of 100, loss = 0.007075435100969943   Iteration 23 of 100, loss = 0.007094691467026006   Iteration 24 of 100, loss = 0.006954683262544374   Iteration 25 of 100, loss = 0.006983588375151157   Iteration 26 of 100, loss = 0.0068525237640222674   Iteration 27 of 100, loss = 0.006764984258485061   Iteration 28 of 100, loss = 0.006803825148381293   Iteration 29 of 100, loss = 0.006684701962011127   Iteration 30 of 100, loss = 0.006577680384119352   Iteration 31 of 100, loss = 0.0064836062430854765   Iteration 32 of 100, loss = 0.006494474451756105   Iteration 33 of 100, loss = 0.0063888259500152235   Iteration 34 of 100, loss = 0.006252371086328126   Iteration 35 of 100, loss = 0.006185057696088084   Iteration 36 of 100, loss = 0.0060939598058919525   Iteration 37 of 100, loss = 0.00610766201468839   Iteration 38 of 100, loss = 0.006009702291952348   Iteration 39 of 100, loss = 0.006010276853488997   Iteration 40 of 100, loss = 0.0059538919565966355   Iteration 41 of 100, loss = 0.005894885668190333   Iteration 42 of 100, loss = 0.005956732975651643   Iteration 43 of 100, loss = 0.005932395473707381   Iteration 44 of 100, loss = 0.005898644457126714   Iteration 45 of 100, loss = 0.0059864170099091195   Iteration 46 of 100, loss = 0.006024338515050224   Iteration 47 of 100, loss = 0.006097224251208629   Iteration 48 of 100, loss = 0.006138800980503826   Iteration 49 of 100, loss = 0.006124176747849857   Iteration 50 of 100, loss = 0.006101272709202021   Iteration 51 of 100, loss = 0.006115351600444638   Iteration 52 of 100, loss = 0.006108376302738459   Iteration 53 of 100, loss = 0.006081509647697632   Iteration 54 of 100, loss = 0.006099919501812784   Iteration 55 of 100, loss = 0.0060699077555909755   Iteration 56 of 100, loss = 0.006098909875228336   Iteration 57 of 100, loss = 0.006116791667106251   Iteration 58 of 100, loss = 0.0060849055659893   Iteration 59 of 100, loss = 0.006089069925927383   Iteration 60 of 100, loss = 0.006082877879574274   Iteration 61 of 100, loss = 0.00614838403474051   Iteration 62 of 100, loss = 0.006090916559896281   Iteration 63 of 100, loss = 0.006085055808181919   Iteration 64 of 100, loss = 0.006081205277951085   Iteration 65 of 100, loss = 0.006012200139677869   Iteration 66 of 100, loss = 0.005991258113433353   Iteration 67 of 100, loss = 0.005989641387279688   Iteration 68 of 100, loss = 0.006077943347490337   Iteration 69 of 100, loss = 0.0061263994134935565   Iteration 70 of 100, loss = 0.006142357642030609   Iteration 71 of 100, loss = 0.006096132081592272   Iteration 72 of 100, loss = 0.006181997850136314   Iteration 73 of 100, loss = 0.006182978263010003   Iteration 74 of 100, loss = 0.006131826662395552   Iteration 75 of 100, loss = 0.006134047366989155   Iteration 76 of 100, loss = 0.006121481457835455   Iteration 77 of 100, loss = 0.006100737025610522   Iteration 78 of 100, loss = 0.0060806169535797564   Iteration 79 of 100, loss = 0.006084007990570102   Iteration 80 of 100, loss = 0.006100113586580846   Iteration 81 of 100, loss = 0.006155537373823241   Iteration 82 of 100, loss = 0.006138873674123116   Iteration 83 of 100, loss = 0.006119568856062749   Iteration 84 of 100, loss = 0.0061526547222109955   Iteration 85 of 100, loss = 0.006131969256710042   Iteration 86 of 100, loss = 0.006125699800471667   Iteration 87 of 100, loss = 0.006155939832939927   Iteration 88 of 100, loss = 0.00610643473919481   Iteration 89 of 100, loss = 0.006132153658133545   Iteration 90 of 100, loss = 0.006153899689929353   Iteration 91 of 100, loss = 0.0061506263062276025   Iteration 92 of 100, loss = 0.006155199325724464   Iteration 93 of 100, loss = 0.00615121589432801   Iteration 94 of 100, loss = 0.006126122165253346   Iteration 95 of 100, loss = 0.0061040300459257865   Iteration 96 of 100, loss = 0.006127489088006162   Iteration 97 of 100, loss = 0.0061306386499560064   Iteration 98 of 100, loss = 0.006158911397357528   Iteration 99 of 100, loss = 0.00614312648857859   Iteration 100 of 100, loss = 0.006151318515185267
   End of epoch 44; saving model... 

Epoch 45 of 2000
   Iteration 1 of 100, loss = 0.0038158679381012917   Iteration 2 of 100, loss = 0.0037845178740099072   Iteration 3 of 100, loss = 0.004106003713483612   Iteration 4 of 100, loss = 0.004215712135192007   Iteration 5 of 100, loss = 0.0052813052665442225   Iteration 6 of 100, loss = 0.005143315337287883   Iteration 7 of 100, loss = 0.005417625586103115   Iteration 8 of 100, loss = 0.006258156878175214   Iteration 9 of 100, loss = 0.006403503344497747   Iteration 10 of 100, loss = 0.006487058545462787   Iteration 11 of 100, loss = 0.006582072491503574   Iteration 12 of 100, loss = 0.006661901037053515   Iteration 13 of 100, loss = 0.006590737585121622   Iteration 14 of 100, loss = 0.006459311365948192   Iteration 15 of 100, loss = 0.006583337966973583   Iteration 16 of 100, loss = 0.006530711645609699   Iteration 17 of 100, loss = 0.006476957501624437   Iteration 18 of 100, loss = 0.006315824730942647   Iteration 19 of 100, loss = 0.006567025900279221   Iteration 20 of 100, loss = 0.006480300938710571   Iteration 21 of 100, loss = 0.006415396108336392   Iteration 22 of 100, loss = 0.00637584137306972   Iteration 23 of 100, loss = 0.006293928088701289   Iteration 24 of 100, loss = 0.0061221011662079645   Iteration 25 of 100, loss = 0.006019458593800664   Iteration 26 of 100, loss = 0.0059357331438849754   Iteration 27 of 100, loss = 0.006006927858969128   Iteration 28 of 100, loss = 0.0059327317285351455   Iteration 29 of 100, loss = 0.006018452097436991   Iteration 30 of 100, loss = 0.006021961267106235   Iteration 31 of 100, loss = 0.005969289036828184   Iteration 32 of 100, loss = 0.005921378840866964   Iteration 33 of 100, loss = 0.005920918721875007   Iteration 34 of 100, loss = 0.00595079137094538   Iteration 35 of 100, loss = 0.005966873473620841   Iteration 36 of 100, loss = 0.005941485630400065   Iteration 37 of 100, loss = 0.005872995655580952   Iteration 38 of 100, loss = 0.005894126027430359   Iteration 39 of 100, loss = 0.00585419300179451   Iteration 40 of 100, loss = 0.005940779461525381   Iteration 41 of 100, loss = 0.005891664612402276   Iteration 42 of 100, loss = 0.005926057840475724   Iteration 43 of 100, loss = 0.0058660018799263376   Iteration 44 of 100, loss = 0.005800893921828406   Iteration 45 of 100, loss = 0.00582757212428583   Iteration 46 of 100, loss = 0.005788061514739757   Iteration 47 of 100, loss = 0.0058329187115614715   Iteration 48 of 100, loss = 0.005929976284581547   Iteration 49 of 100, loss = 0.005877156760923716   Iteration 50 of 100, loss = 0.005858915522694587   Iteration 51 of 100, loss = 0.0059107859418088314   Iteration 52 of 100, loss = 0.00593699119053781   Iteration 53 of 100, loss = 0.005938803276293121   Iteration 54 of 100, loss = 0.0059182630093009385   Iteration 55 of 100, loss = 0.005935663247311657   Iteration 56 of 100, loss = 0.005912039927872164   Iteration 57 of 100, loss = 0.005874894918841228   Iteration 58 of 100, loss = 0.005884465400193785   Iteration 59 of 100, loss = 0.005888722000359479   Iteration 60 of 100, loss = 0.005955667685096463   Iteration 61 of 100, loss = 0.005993347981425583   Iteration 62 of 100, loss = 0.006020155051843294   Iteration 63 of 100, loss = 0.005985630461798301   Iteration 64 of 100, loss = 0.005972431878035422   Iteration 65 of 100, loss = 0.005944701857291735   Iteration 66 of 100, loss = 0.005942449446372462   Iteration 67 of 100, loss = 0.005915347153126304   Iteration 68 of 100, loss = 0.0058938257930362045   Iteration 69 of 100, loss = 0.005888412949507651   Iteration 70 of 100, loss = 0.005923283060214349   Iteration 71 of 100, loss = 0.00590263018515748   Iteration 72 of 100, loss = 0.005883818647513787   Iteration 73 of 100, loss = 0.005903885355346823   Iteration 74 of 100, loss = 0.005882427694175292   Iteration 75 of 100, loss = 0.005873830101142327   Iteration 76 of 100, loss = 0.0058498401378624535   Iteration 77 of 100, loss = 0.005837682840208728   Iteration 78 of 100, loss = 0.005798492126930983   Iteration 79 of 100, loss = 0.0058327701909444   Iteration 80 of 100, loss = 0.005845347093418241   Iteration 81 of 100, loss = 0.005840540587626121   Iteration 82 of 100, loss = 0.005822694332270724   Iteration 83 of 100, loss = 0.005880444383540426   Iteration 84 of 100, loss = 0.005934803685661228   Iteration 85 of 100, loss = 0.005971574076615712   Iteration 86 of 100, loss = 0.005965053287962842   Iteration 87 of 100, loss = 0.00594782438022138   Iteration 88 of 100, loss = 0.005963669782927768   Iteration 89 of 100, loss = 0.005971453058418263   Iteration 90 of 100, loss = 0.005967198467502991   Iteration 91 of 100, loss = 0.006050275720574044   Iteration 92 of 100, loss = 0.006045978253140398   Iteration 93 of 100, loss = 0.006100938304938296   Iteration 94 of 100, loss = 0.006143186697141922   Iteration 95 of 100, loss = 0.006127442458742543   Iteration 96 of 100, loss = 0.006086221413473443   Iteration 97 of 100, loss = 0.006099793980781411   Iteration 98 of 100, loss = 0.006072623099257447   Iteration 99 of 100, loss = 0.006066511267551569   Iteration 100 of 100, loss = 0.006070878277532756
   End of epoch 45; saving model... 

Epoch 46 of 2000
   Iteration 1 of 100, loss = 0.003541188081726432   Iteration 2 of 100, loss = 0.004778455826453865   Iteration 3 of 100, loss = 0.004828988496835033   Iteration 4 of 100, loss = 0.005021023971494287   Iteration 5 of 100, loss = 0.005666600121185183   Iteration 6 of 100, loss = 0.006400700309313834   Iteration 7 of 100, loss = 0.0066448012034275705   Iteration 8 of 100, loss = 0.006385307089658454   Iteration 9 of 100, loss = 0.006134956117926372   Iteration 10 of 100, loss = 0.0063743641367182136   Iteration 11 of 100, loss = 0.006187205647372387   Iteration 12 of 100, loss = 0.00595970773914208   Iteration 13 of 100, loss = 0.0056946922559291124   Iteration 14 of 100, loss = 0.005524652195163071   Iteration 15 of 100, loss = 0.005544549024974307   Iteration 16 of 100, loss = 0.005478509629028849   Iteration 17 of 100, loss = 0.005454998394912656   Iteration 18 of 100, loss = 0.00563185572779427   Iteration 19 of 100, loss = 0.005723218984999939   Iteration 20 of 100, loss = 0.005931129131931811   Iteration 21 of 100, loss = 0.005977291225766142   Iteration 22 of 100, loss = 0.006039833343079822   Iteration 23 of 100, loss = 0.006092678522691131   Iteration 24 of 100, loss = 0.00617111199729455   Iteration 25 of 100, loss = 0.006106569031253457   Iteration 26 of 100, loss = 0.006020466528403072   Iteration 27 of 100, loss = 0.006015690905904329   Iteration 28 of 100, loss = 0.005978223202483994   Iteration 29 of 100, loss = 0.006002294381373915   Iteration 30 of 100, loss = 0.006052259433393677   Iteration 31 of 100, loss = 0.005993947687168275   Iteration 32 of 100, loss = 0.006096371362218633   Iteration 33 of 100, loss = 0.006047967228699814   Iteration 34 of 100, loss = 0.006016967160736813   Iteration 35 of 100, loss = 0.005946343751358134   Iteration 36 of 100, loss = 0.006013256458876033   Iteration 37 of 100, loss = 0.00607827677064248   Iteration 38 of 100, loss = 0.006071791910615407   Iteration 39 of 100, loss = 0.005952341929794504   Iteration 40 of 100, loss = 0.006041351769817993   Iteration 41 of 100, loss = 0.005954059823302597   Iteration 42 of 100, loss = 0.005914120740878086   Iteration 43 of 100, loss = 0.005944190833847536   Iteration 44 of 100, loss = 0.0058800144946541295   Iteration 45 of 100, loss = 0.005847843901978599   Iteration 46 of 100, loss = 0.005918993634860153   Iteration 47 of 100, loss = 0.005947355983501419   Iteration 48 of 100, loss = 0.006014626521694784   Iteration 49 of 100, loss = 0.006114345129427253   Iteration 50 of 100, loss = 0.006064390549436211   Iteration 51 of 100, loss = 0.006028535602358626   Iteration 52 of 100, loss = 0.005991221799586828   Iteration 53 of 100, loss = 0.005989293488761726   Iteration 54 of 100, loss = 0.005981561624341541   Iteration 55 of 100, loss = 0.005983090646226298   Iteration 56 of 100, loss = 0.005987235536200127   Iteration 57 of 100, loss = 0.005968513383873199   Iteration 58 of 100, loss = 0.006072948229145901   Iteration 59 of 100, loss = 0.006121996214013483   Iteration 60 of 100, loss = 0.006113441614434123   Iteration 61 of 100, loss = 0.006066909151487663   Iteration 62 of 100, loss = 0.006164463417183968   Iteration 63 of 100, loss = 0.006196068599820137   Iteration 64 of 100, loss = 0.006193955741764512   Iteration 65 of 100, loss = 0.006180247514007183   Iteration 66 of 100, loss = 0.006218212409735177   Iteration 67 of 100, loss = 0.006217870659737   Iteration 68 of 100, loss = 0.006274802548646489   Iteration 69 of 100, loss = 0.006259361673416435   Iteration 70 of 100, loss = 0.00620727286274944   Iteration 71 of 100, loss = 0.006163032873022094   Iteration 72 of 100, loss = 0.006215997392751483   Iteration 73 of 100, loss = 0.006219648121384113   Iteration 74 of 100, loss = 0.00625202851684613   Iteration 75 of 100, loss = 0.006242278569067518   Iteration 76 of 100, loss = 0.006220618658086383   Iteration 77 of 100, loss = 0.006173058666966178   Iteration 78 of 100, loss = 0.006122433270017306   Iteration 79 of 100, loss = 0.0061434854847626594   Iteration 80 of 100, loss = 0.006133785605197772   Iteration 81 of 100, loss = 0.006146125299971045   Iteration 82 of 100, loss = 0.006141817935447141   Iteration 83 of 100, loss = 0.006111262450331306   Iteration 84 of 100, loss = 0.006105140350492937   Iteration 85 of 100, loss = 0.006149587539189002   Iteration 86 of 100, loss = 0.006114221592217164   Iteration 87 of 100, loss = 0.006130220917128454   Iteration 88 of 100, loss = 0.0061292353017382666   Iteration 89 of 100, loss = 0.006150292993910359   Iteration 90 of 100, loss = 0.006162680791587465   Iteration 91 of 100, loss = 0.006140988025875701   Iteration 92 of 100, loss = 0.006091541347458311   Iteration 93 of 100, loss = 0.006120916796467637   Iteration 94 of 100, loss = 0.0061539359232212635   Iteration 95 of 100, loss = 0.006165575314509241   Iteration 96 of 100, loss = 0.00615053296496626   Iteration 97 of 100, loss = 0.006137522955223457   Iteration 98 of 100, loss = 0.006143684807822717   Iteration 99 of 100, loss = 0.006151094802213136   Iteration 100 of 100, loss = 0.006151512088254094
   End of epoch 46; saving model... 

Epoch 47 of 2000
   Iteration 1 of 100, loss = 0.005055776797235012   Iteration 2 of 100, loss = 0.0059176343493163586   Iteration 3 of 100, loss = 0.007204155437648296   Iteration 4 of 100, loss = 0.007211207994259894   Iteration 5 of 100, loss = 0.007474380824714899   Iteration 6 of 100, loss = 0.007371754385530949   Iteration 7 of 100, loss = 0.00688339357397386   Iteration 8 of 100, loss = 0.006403858715202659   Iteration 9 of 100, loss = 0.006139645922101206   Iteration 10 of 100, loss = 0.006107140053063631   Iteration 11 of 100, loss = 0.0058331864208660345   Iteration 12 of 100, loss = 0.0057774343295022845   Iteration 13 of 100, loss = 0.00573590172168154   Iteration 14 of 100, loss = 0.006005502073094249   Iteration 15 of 100, loss = 0.006150628719478845   Iteration 16 of 100, loss = 0.006161433149827644   Iteration 17 of 100, loss = 0.006141047733014121   Iteration 18 of 100, loss = 0.006018821020714111   Iteration 19 of 100, loss = 0.006073312441769399   Iteration 20 of 100, loss = 0.006171556375920773   Iteration 21 of 100, loss = 0.006189455876925162   Iteration 22 of 100, loss = 0.00604143236044117   Iteration 23 of 100, loss = 0.005967065459117293   Iteration 24 of 100, loss = 0.005989340357094382   Iteration 25 of 100, loss = 0.006053751772269606   Iteration 26 of 100, loss = 0.00607975700404495   Iteration 27 of 100, loss = 0.005977395982309072   Iteration 28 of 100, loss = 0.006076148336952818   Iteration 29 of 100, loss = 0.006012091148195082   Iteration 30 of 100, loss = 0.005951810092665255   Iteration 31 of 100, loss = 0.005948666640887818   Iteration 32 of 100, loss = 0.005899374089494813   Iteration 33 of 100, loss = 0.006008714021211772   Iteration 34 of 100, loss = 0.006042340873083209   Iteration 35 of 100, loss = 0.005992768831284983   Iteration 36 of 100, loss = 0.005955609577035325   Iteration 37 of 100, loss = 0.0059293195844401375   Iteration 38 of 100, loss = 0.005969326557150404   Iteration 39 of 100, loss = 0.005875530133310419   Iteration 40 of 100, loss = 0.005873320909449831   Iteration 41 of 100, loss = 0.0058711142813014545   Iteration 42 of 100, loss = 0.005832589891118308   Iteration 43 of 100, loss = 0.005757625539635503   Iteration 44 of 100, loss = 0.005684782443991439   Iteration 45 of 100, loss = 0.005662498912877506   Iteration 46 of 100, loss = 0.005706597018339064   Iteration 47 of 100, loss = 0.005747014884539741   Iteration 48 of 100, loss = 0.005800763504036392   Iteration 49 of 100, loss = 0.005790894508970027   Iteration 50 of 100, loss = 0.005750467423349619   Iteration 51 of 100, loss = 0.005710047208612748   Iteration 52 of 100, loss = 0.005651733009681965   Iteration 53 of 100, loss = 0.005618906680951422   Iteration 54 of 100, loss = 0.005613173146870125   Iteration 55 of 100, loss = 0.005632289427078583   Iteration 56 of 100, loss = 0.005615797355338665   Iteration 57 of 100, loss = 0.005615308582619356   Iteration 58 of 100, loss = 0.005587439964011568   Iteration 59 of 100, loss = 0.005590661353889411   Iteration 60 of 100, loss = 0.005617851271138837   Iteration 61 of 100, loss = 0.005587989746852488   Iteration 62 of 100, loss = 0.005653046965298634   Iteration 63 of 100, loss = 0.005638180507553948   Iteration 64 of 100, loss = 0.005675741194863804   Iteration 65 of 100, loss = 0.005660238682937163   Iteration 66 of 100, loss = 0.005703889052242492   Iteration 67 of 100, loss = 0.005682699291952955   Iteration 68 of 100, loss = 0.005758413682034349   Iteration 69 of 100, loss = 0.005808676586256943   Iteration 70 of 100, loss = 0.005779636358576161   Iteration 71 of 100, loss = 0.005722922868174041   Iteration 72 of 100, loss = 0.005800764430508328   Iteration 73 of 100, loss = 0.0058198894600524275   Iteration 74 of 100, loss = 0.005813695312590917   Iteration 75 of 100, loss = 0.00580499793558071   Iteration 76 of 100, loss = 0.005774659035715128   Iteration 77 of 100, loss = 0.005760776566934179   Iteration 78 of 100, loss = 0.005745711806528748   Iteration 79 of 100, loss = 0.005752562885644221   Iteration 80 of 100, loss = 0.005711999868799467   Iteration 81 of 100, loss = 0.005715946472870807   Iteration 82 of 100, loss = 0.0057370324644668985   Iteration 83 of 100, loss = 0.005784682117413774   Iteration 84 of 100, loss = 0.0057658126835511735   Iteration 85 of 100, loss = 0.0057458239347290465   Iteration 86 of 100, loss = 0.005736086508096737   Iteration 87 of 100, loss = 0.005722811612857227   Iteration 88 of 100, loss = 0.005702249939945018   Iteration 89 of 100, loss = 0.00570849561671402   Iteration 90 of 100, loss = 0.005720501239152832   Iteration 91 of 100, loss = 0.005694033402775588   Iteration 92 of 100, loss = 0.005691392599028009   Iteration 93 of 100, loss = 0.005707421088441004   Iteration 94 of 100, loss = 0.005717571496596917   Iteration 95 of 100, loss = 0.005740750952329682   Iteration 96 of 100, loss = 0.00578795232650009   Iteration 97 of 100, loss = 0.0057767897006604325   Iteration 98 of 100, loss = 0.005768623886088252   Iteration 99 of 100, loss = 0.005744141991005627   Iteration 100 of 100, loss = 0.005750106432242319
   End of epoch 47; saving model... 

Epoch 48 of 2000
   Iteration 1 of 100, loss = 0.004106887616217136   Iteration 2 of 100, loss = 0.0050045468378812075   Iteration 3 of 100, loss = 0.005716354741404454   Iteration 4 of 100, loss = 0.005967269418761134   Iteration 5 of 100, loss = 0.005666912347078323   Iteration 6 of 100, loss = 0.005442943889647722   Iteration 7 of 100, loss = 0.00559886491724423   Iteration 8 of 100, loss = 0.005398096924182028   Iteration 9 of 100, loss = 0.005822408271746503   Iteration 10 of 100, loss = 0.006165567925199867   Iteration 11 of 100, loss = 0.006059827452356165   Iteration 12 of 100, loss = 0.006410849513486028   Iteration 13 of 100, loss = 0.006300541715553174   Iteration 14 of 100, loss = 0.00658429620255317   Iteration 15 of 100, loss = 0.0064273181681831675   Iteration 16 of 100, loss = 0.006375637720339   Iteration 17 of 100, loss = 0.006448634078397471   Iteration 18 of 100, loss = 0.006516504722336928   Iteration 19 of 100, loss = 0.006364399640771903   Iteration 20 of 100, loss = 0.00635679280385375   Iteration 21 of 100, loss = 0.006396310670035226   Iteration 22 of 100, loss = 0.006412737262011929   Iteration 23 of 100, loss = 0.006326511886942646   Iteration 24 of 100, loss = 0.006415061051181207   Iteration 25 of 100, loss = 0.006291955029591918   Iteration 26 of 100, loss = 0.006375715020112693   Iteration 27 of 100, loss = 0.006437232122860021   Iteration 28 of 100, loss = 0.0062903052811244765   Iteration 29 of 100, loss = 0.006215220196814886   Iteration 30 of 100, loss = 0.0061709600733593105   Iteration 31 of 100, loss = 0.006095791258098137   Iteration 32 of 100, loss = 0.00615819819358876   Iteration 33 of 100, loss = 0.006175773902655099   Iteration 34 of 100, loss = 0.006244729909881511   Iteration 35 of 100, loss = 0.006288275461910026   Iteration 36 of 100, loss = 0.006284223630144779   Iteration 37 of 100, loss = 0.0062135255618675335   Iteration 38 of 100, loss = 0.006258529708965828   Iteration 39 of 100, loss = 0.006264665534194463   Iteration 40 of 100, loss = 0.006193019391503185   Iteration 41 of 100, loss = 0.006124638287895699   Iteration 42 of 100, loss = 0.006225770200780105   Iteration 43 of 100, loss = 0.006185439745570684   Iteration 44 of 100, loss = 0.006234108750835399   Iteration 45 of 100, loss = 0.0062568834931072265   Iteration 46 of 100, loss = 0.006290058094157796   Iteration 47 of 100, loss = 0.006243782955162386   Iteration 48 of 100, loss = 0.006229169312670517   Iteration 49 of 100, loss = 0.006372433398109005   Iteration 50 of 100, loss = 0.006295079779811204   Iteration 51 of 100, loss = 0.006341864706437085   Iteration 52 of 100, loss = 0.006315238742480198   Iteration 53 of 100, loss = 0.006321816621699704   Iteration 54 of 100, loss = 0.006280709502149235   Iteration 55 of 100, loss = 0.006336162827739662   Iteration 56 of 100, loss = 0.006311112170806155   Iteration 57 of 100, loss = 0.006246632279566767   Iteration 58 of 100, loss = 0.00620470245384836   Iteration 59 of 100, loss = 0.00615072203405454   Iteration 60 of 100, loss = 0.006224968753910313   Iteration 61 of 100, loss = 0.006146209259120534   Iteration 62 of 100, loss = 0.006138791763899668   Iteration 63 of 100, loss = 0.0061622169589446414   Iteration 64 of 100, loss = 0.006171720624479349   Iteration 65 of 100, loss = 0.006142440307527208   Iteration 66 of 100, loss = 0.006091373409920682   Iteration 67 of 100, loss = 0.006083737393326835   Iteration 68 of 100, loss = 0.006073204069466823   Iteration 69 of 100, loss = 0.006108078925087508   Iteration 70 of 100, loss = 0.006090975534503482   Iteration 71 of 100, loss = 0.00604567600866701   Iteration 72 of 100, loss = 0.006120748146915705   Iteration 73 of 100, loss = 0.006148822364805598   Iteration 74 of 100, loss = 0.006121568540677529   Iteration 75 of 100, loss = 0.0061705179962640005   Iteration 76 of 100, loss = 0.0061922544003831905   Iteration 77 of 100, loss = 0.006188858241483859   Iteration 78 of 100, loss = 0.006183905307597552   Iteration 79 of 100, loss = 0.006175352073321708   Iteration 80 of 100, loss = 0.006197986054758076   Iteration 81 of 100, loss = 0.0062313802600665776   Iteration 82 of 100, loss = 0.006193946673614313   Iteration 83 of 100, loss = 0.006165773600777499   Iteration 84 of 100, loss = 0.0061676290227166775   Iteration 85 of 100, loss = 0.0061387181761400665   Iteration 86 of 100, loss = 0.006160357093904167   Iteration 87 of 100, loss = 0.0061323627516434625   Iteration 88 of 100, loss = 0.006153615782915784   Iteration 89 of 100, loss = 0.006152837609171114   Iteration 90 of 100, loss = 0.006213271657988015   Iteration 91 of 100, loss = 0.006182862429081329   Iteration 92 of 100, loss = 0.006183708890128638   Iteration 93 of 100, loss = 0.0061568983101976974   Iteration 94 of 100, loss = 0.00614425705057232   Iteration 95 of 100, loss = 0.006129836924619188   Iteration 96 of 100, loss = 0.006100052716647042   Iteration 97 of 100, loss = 0.006074948194340716   Iteration 98 of 100, loss = 0.0060341765650319965   Iteration 99 of 100, loss = 0.006085253053702264   Iteration 100 of 100, loss = 0.006075901031726972
   End of epoch 48; saving model... 

Epoch 49 of 2000
   Iteration 1 of 100, loss = 0.005952985025942326   Iteration 2 of 100, loss = 0.006276827305555344   Iteration 3 of 100, loss = 0.005847382514427106   Iteration 4 of 100, loss = 0.006049551302567124   Iteration 5 of 100, loss = 0.005805372912436724   Iteration 6 of 100, loss = 0.006384489048893253   Iteration 7 of 100, loss = 0.007179200050554105   Iteration 8 of 100, loss = 0.006674315838608891   Iteration 9 of 100, loss = 0.006786772774325477   Iteration 10 of 100, loss = 0.006641161674633622   Iteration 11 of 100, loss = 0.00677195331081748   Iteration 12 of 100, loss = 0.006579639661746721   Iteration 13 of 100, loss = 0.0064372088616857165   Iteration 14 of 100, loss = 0.006440665705927781   Iteration 15 of 100, loss = 0.006293614270786444   Iteration 16 of 100, loss = 0.0061788405873812735   Iteration 17 of 100, loss = 0.006298826788278187   Iteration 18 of 100, loss = 0.006262894719839096   Iteration 19 of 100, loss = 0.006293683386358775   Iteration 20 of 100, loss = 0.006279056705534458   Iteration 21 of 100, loss = 0.006436568729224659   Iteration 22 of 100, loss = 0.006425327896563845   Iteration 23 of 100, loss = 0.006251289367513812   Iteration 24 of 100, loss = 0.006362973731787254   Iteration 25 of 100, loss = 0.006330769024789334   Iteration 26 of 100, loss = 0.00640518103654568   Iteration 27 of 100, loss = 0.006379928629569433   Iteration 28 of 100, loss = 0.006467912096663245   Iteration 29 of 100, loss = 0.006447617301781629   Iteration 30 of 100, loss = 0.006314660763988892   Iteration 31 of 100, loss = 0.006327314602751885   Iteration 32 of 100, loss = 0.006263516726903617   Iteration 33 of 100, loss = 0.006132946702454126   Iteration 34 of 100, loss = 0.006049554993617623   Iteration 35 of 100, loss = 0.0059209260424332956   Iteration 36 of 100, loss = 0.006042858728000687   Iteration 37 of 100, loss = 0.0060061834047775015   Iteration 38 of 100, loss = 0.006003393460751364   Iteration 39 of 100, loss = 0.006044001151353885   Iteration 40 of 100, loss = 0.0060981653397902845   Iteration 41 of 100, loss = 0.006064661596788139   Iteration 42 of 100, loss = 0.006046751137113287   Iteration 43 of 100, loss = 0.006114908407420613   Iteration 44 of 100, loss = 0.006031225149689073   Iteration 45 of 100, loss = 0.006030981139176422   Iteration 46 of 100, loss = 0.0060327040213767604   Iteration 47 of 100, loss = 0.006070944966074634   Iteration 48 of 100, loss = 0.006001985311741009   Iteration 49 of 100, loss = 0.006072513559567077   Iteration 50 of 100, loss = 0.00600799101870507   Iteration 51 of 100, loss = 0.00604955336608577   Iteration 52 of 100, loss = 0.006013626702882063   Iteration 53 of 100, loss = 0.005980033168288053   Iteration 54 of 100, loss = 0.005969589485579895   Iteration 55 of 100, loss = 0.0059475927910005505   Iteration 56 of 100, loss = 0.005968901041861889   Iteration 57 of 100, loss = 0.0059172532382306825   Iteration 58 of 100, loss = 0.005917271450643653   Iteration 59 of 100, loss = 0.0059947163711096775   Iteration 60 of 100, loss = 0.005997106630820781   Iteration 61 of 100, loss = 0.005976808169612386   Iteration 62 of 100, loss = 0.0059419594021634225   Iteration 63 of 100, loss = 0.005976866062227932   Iteration 64 of 100, loss = 0.005987696418742416   Iteration 65 of 100, loss = 0.0059961459348694636   Iteration 66 of 100, loss = 0.005966634471957205   Iteration 67 of 100, loss = 0.005968191191804276   Iteration 68 of 100, loss = 0.00600182794048177   Iteration 69 of 100, loss = 0.005958753236420993   Iteration 70 of 100, loss = 0.006036523905848818   Iteration 71 of 100, loss = 0.006028432599072095   Iteration 72 of 100, loss = 0.005971009527759937   Iteration 73 of 100, loss = 0.005976612464371711   Iteration 74 of 100, loss = 0.005931416273154822   Iteration 75 of 100, loss = 0.005890769087709486   Iteration 76 of 100, loss = 0.005862063015994959   Iteration 77 of 100, loss = 0.005869389806462863   Iteration 78 of 100, loss = 0.005881925768708476   Iteration 79 of 100, loss = 0.0058817565662173344   Iteration 80 of 100, loss = 0.005936834086605813   Iteration 81 of 100, loss = 0.005963932008505511   Iteration 82 of 100, loss = 0.005945474203255754   Iteration 83 of 100, loss = 0.005915731863477772   Iteration 84 of 100, loss = 0.00588086598491784   Iteration 85 of 100, loss = 0.005856030857573975   Iteration 86 of 100, loss = 0.005835231985127943   Iteration 87 of 100, loss = 0.005810306002064769   Iteration 88 of 100, loss = 0.005868922846275382   Iteration 89 of 100, loss = 0.005892278879012368   Iteration 90 of 100, loss = 0.005929630716693484   Iteration 91 of 100, loss = 0.005940115044742905   Iteration 92 of 100, loss = 0.005960736055504126   Iteration 93 of 100, loss = 0.005940000467773487   Iteration 94 of 100, loss = 0.005915248829702986   Iteration 95 of 100, loss = 0.005906349002677751   Iteration 96 of 100, loss = 0.005875796818145318   Iteration 97 of 100, loss = 0.005879405503084441   Iteration 98 of 100, loss = 0.005867862590465086   Iteration 99 of 100, loss = 0.005825602603521236   Iteration 100 of 100, loss = 0.005865889139240608
   End of epoch 49; saving model... 

Epoch 50 of 2000
   Iteration 1 of 100, loss = 0.005317068193107843   Iteration 2 of 100, loss = 0.005612639943137765   Iteration 3 of 100, loss = 0.006166758170972268   Iteration 4 of 100, loss = 0.005897081457078457   Iteration 5 of 100, loss = 0.005321514699608088   Iteration 6 of 100, loss = 0.00585281359963119   Iteration 7 of 100, loss = 0.006262671002852065   Iteration 8 of 100, loss = 0.006039044237695634   Iteration 9 of 100, loss = 0.0055422015074226595   Iteration 10 of 100, loss = 0.0054361394606530665   Iteration 11 of 100, loss = 0.005626618777486411   Iteration 12 of 100, loss = 0.005438602898114671   Iteration 13 of 100, loss = 0.005765021904013478   Iteration 14 of 100, loss = 0.005639235938100943   Iteration 15 of 100, loss = 0.005543208417172233   Iteration 16 of 100, loss = 0.005462973305839114   Iteration 17 of 100, loss = 0.005365370307117701   Iteration 18 of 100, loss = 0.005462995109458764   Iteration 19 of 100, loss = 0.005409035366028547   Iteration 20 of 100, loss = 0.005666488013230264   Iteration 21 of 100, loss = 0.005681198134663559   Iteration 22 of 100, loss = 0.005739119306037372   Iteration 23 of 100, loss = 0.00608364247676471   Iteration 24 of 100, loss = 0.005960671085631475   Iteration 25 of 100, loss = 0.006042659403756261   Iteration 26 of 100, loss = 0.006005368974561302   Iteration 27 of 100, loss = 0.006021895557986917   Iteration 28 of 100, loss = 0.0060294210727858755   Iteration 29 of 100, loss = 0.005900197879186478   Iteration 30 of 100, loss = 0.005864570639096201   Iteration 31 of 100, loss = 0.005959923326548549   Iteration 32 of 100, loss = 0.006070072158763651   Iteration 33 of 100, loss = 0.005998139700033899   Iteration 34 of 100, loss = 0.005875654258381794   Iteration 35 of 100, loss = 0.005859087168106011   Iteration 36 of 100, loss = 0.005887472885660827   Iteration 37 of 100, loss = 0.005845292836327005   Iteration 38 of 100, loss = 0.0058519172629243445   Iteration 39 of 100, loss = 0.005917147757151188   Iteration 40 of 100, loss = 0.005888880172278732   Iteration 41 of 100, loss = 0.005843666313988406   Iteration 42 of 100, loss = 0.005834844517743304   Iteration 43 of 100, loss = 0.0057721247268450815   Iteration 44 of 100, loss = 0.005762373996813866   Iteration 45 of 100, loss = 0.005829807091504336   Iteration 46 of 100, loss = 0.005807929652054672   Iteration 47 of 100, loss = 0.005886837106911426   Iteration 48 of 100, loss = 0.005952888207199673   Iteration 49 of 100, loss = 0.005923633653746575   Iteration 50 of 100, loss = 0.00595995707437396   Iteration 51 of 100, loss = 0.005944766779886741   Iteration 52 of 100, loss = 0.00605995636075162   Iteration 53 of 100, loss = 0.006098502965749435   Iteration 54 of 100, loss = 0.0060831914414410234   Iteration 55 of 100, loss = 0.00606751750138673   Iteration 56 of 100, loss = 0.006037344973135207   Iteration 57 of 100, loss = 0.0060200037254968235   Iteration 58 of 100, loss = 0.006021670089906146   Iteration 59 of 100, loss = 0.0060364070143234935   Iteration 60 of 100, loss = 0.006050939206033945   Iteration 61 of 100, loss = 0.006061785091020045   Iteration 62 of 100, loss = 0.006054178924269734   Iteration 63 of 100, loss = 0.0060948133099055475   Iteration 64 of 100, loss = 0.0061106495559215546   Iteration 65 of 100, loss = 0.006118688281052388   Iteration 66 of 100, loss = 0.006086940728974613   Iteration 67 of 100, loss = 0.006162615930800562   Iteration 68 of 100, loss = 0.006152618532616864   Iteration 69 of 100, loss = 0.006147682275353134   Iteration 70 of 100, loss = 0.006111668196639844   Iteration 71 of 100, loss = 0.0061073446003588995   Iteration 72 of 100, loss = 0.006121184036601335   Iteration 73 of 100, loss = 0.006157825796622528   Iteration 74 of 100, loss = 0.006174696886257545   Iteration 75 of 100, loss = 0.006128857644895713   Iteration 76 of 100, loss = 0.0062022036382634385   Iteration 77 of 100, loss = 0.006227205737264125   Iteration 78 of 100, loss = 0.006185855797062127   Iteration 79 of 100, loss = 0.006212207132101625   Iteration 80 of 100, loss = 0.00623946585401427   Iteration 81 of 100, loss = 0.0062088496051728725   Iteration 82 of 100, loss = 0.006179268880769974   Iteration 83 of 100, loss = 0.006172756288559681   Iteration 84 of 100, loss = 0.006208129354663903   Iteration 85 of 100, loss = 0.006199021462131949   Iteration 86 of 100, loss = 0.006236303987544637   Iteration 87 of 100, loss = 0.006221013812712212   Iteration 88 of 100, loss = 0.006208881137850271   Iteration 89 of 100, loss = 0.006179607850028558   Iteration 90 of 100, loss = 0.006192704616114497   Iteration 91 of 100, loss = 0.006172223359469202   Iteration 92 of 100, loss = 0.00615566864144057   Iteration 93 of 100, loss = 0.006182455062185244   Iteration 94 of 100, loss = 0.006162103978877372   Iteration 95 of 100, loss = 0.00612723765110499   Iteration 96 of 100, loss = 0.006114691379480064   Iteration 97 of 100, loss = 0.006113609452683901   Iteration 98 of 100, loss = 0.00607492024202508   Iteration 99 of 100, loss = 0.00608594647627512   Iteration 100 of 100, loss = 0.00606109756976366
   End of epoch 50; saving model... 

Epoch 51 of 2000
   Iteration 1 of 100, loss = 0.009627360850572586   Iteration 2 of 100, loss = 0.007336234441027045   Iteration 3 of 100, loss = 0.006579977925866842   Iteration 4 of 100, loss = 0.006710409536026418   Iteration 5 of 100, loss = 0.006291434075683356   Iteration 6 of 100, loss = 0.005880478847151001   Iteration 7 of 100, loss = 0.00644518095733864   Iteration 8 of 100, loss = 0.006243970652576536   Iteration 9 of 100, loss = 0.00596926635545161   Iteration 10 of 100, loss = 0.00568007689435035   Iteration 11 of 100, loss = 0.005793293112550269   Iteration 12 of 100, loss = 0.005646235290138672   Iteration 13 of 100, loss = 0.005704781703221111   Iteration 14 of 100, loss = 0.005733274638519755   Iteration 15 of 100, loss = 0.005716587587570151   Iteration 16 of 100, loss = 0.005815331111080013   Iteration 17 of 100, loss = 0.005727899247123038   Iteration 18 of 100, loss = 0.005650646661201285   Iteration 19 of 100, loss = 0.005949479564534206   Iteration 20 of 100, loss = 0.005944714380893857   Iteration 21 of 100, loss = 0.005911789934283921   Iteration 22 of 100, loss = 0.005957098815336146   Iteration 23 of 100, loss = 0.005943364980023192   Iteration 24 of 100, loss = 0.006029105657944456   Iteration 25 of 100, loss = 0.006196064902469516   Iteration 26 of 100, loss = 0.006105446014911509   Iteration 27 of 100, loss = 0.006009279370859817   Iteration 28 of 100, loss = 0.006017298171562808   Iteration 29 of 100, loss = 0.005896030331094717   Iteration 30 of 100, loss = 0.0058529512335856754   Iteration 31 of 100, loss = 0.005808310913703134   Iteration 32 of 100, loss = 0.005933083884883672   Iteration 33 of 100, loss = 0.005930142096159133   Iteration 34 of 100, loss = 0.00600148957934888   Iteration 35 of 100, loss = 0.005944811552762985   Iteration 36 of 100, loss = 0.006075919166000353   Iteration 37 of 100, loss = 0.006001048494835157   Iteration 38 of 100, loss = 0.006034160939682471   Iteration 39 of 100, loss = 0.005982253509454238   Iteration 40 of 100, loss = 0.005994347354862839   Iteration 41 of 100, loss = 0.006003761493669051   Iteration 42 of 100, loss = 0.005938355106904748   Iteration 43 of 100, loss = 0.005891564708246395   Iteration 44 of 100, loss = 0.006030259923797778   Iteration 45 of 100, loss = 0.0059777931155016025   Iteration 46 of 100, loss = 0.005975768633146325   Iteration 47 of 100, loss = 0.00601954397032077   Iteration 48 of 100, loss = 0.006061911306460388   Iteration 49 of 100, loss = 0.006100833145141297   Iteration 50 of 100, loss = 0.006114959050901234   Iteration 51 of 100, loss = 0.006092188354837252   Iteration 52 of 100, loss = 0.006130572484555439   Iteration 53 of 100, loss = 0.006105228841199346   Iteration 54 of 100, loss = 0.006230059101384271   Iteration 55 of 100, loss = 0.006155692650513215   Iteration 56 of 100, loss = 0.006167550371693713   Iteration 57 of 100, loss = 0.006173685969163974   Iteration 58 of 100, loss = 0.006192043359423506   Iteration 59 of 100, loss = 0.006242125579234907   Iteration 60 of 100, loss = 0.006239317590370774   Iteration 61 of 100, loss = 0.0062106180493338185   Iteration 62 of 100, loss = 0.00615687200784563   Iteration 63 of 100, loss = 0.006099750675881903   Iteration 64 of 100, loss = 0.006104741729359375   Iteration 65 of 100, loss = 0.0061004536118931495   Iteration 66 of 100, loss = 0.0060826200730816436   Iteration 67 of 100, loss = 0.00609853487364503   Iteration 68 of 100, loss = 0.006106951722519144   Iteration 69 of 100, loss = 0.006080157396828999   Iteration 70 of 100, loss = 0.006087477122699576   Iteration 71 of 100, loss = 0.006082823765660886   Iteration 72 of 100, loss = 0.0060788663524565184   Iteration 73 of 100, loss = 0.006046626037497022   Iteration 74 of 100, loss = 0.006009712821577449   Iteration 75 of 100, loss = 0.005985760278999806   Iteration 76 of 100, loss = 0.0060200023734451906   Iteration 77 of 100, loss = 0.005962289408659683   Iteration 78 of 100, loss = 0.005957364180805878   Iteration 79 of 100, loss = 0.005985658608459502   Iteration 80 of 100, loss = 0.005969908628321719   Iteration 81 of 100, loss = 0.005965956537064487   Iteration 82 of 100, loss = 0.005928250215663688   Iteration 83 of 100, loss = 0.005913989835822708   Iteration 84 of 100, loss = 0.005943357638205357   Iteration 85 of 100, loss = 0.005994789372198284   Iteration 86 of 100, loss = 0.006005862872603587   Iteration 87 of 100, loss = 0.00602244044488146   Iteration 88 of 100, loss = 0.006024508264751851   Iteration 89 of 100, loss = 0.0060670937691407086   Iteration 90 of 100, loss = 0.006096320489369747   Iteration 91 of 100, loss = 0.006128328979005116   Iteration 92 of 100, loss = 0.0061561232065761706   Iteration 93 of 100, loss = 0.006166598968638448   Iteration 94 of 100, loss = 0.006148036211441727   Iteration 95 of 100, loss = 0.00615720719858808   Iteration 96 of 100, loss = 0.006146224495751085   Iteration 97 of 100, loss = 0.006137972489988297   Iteration 98 of 100, loss = 0.00614016860300599   Iteration 99 of 100, loss = 0.006105288469251433   Iteration 100 of 100, loss = 0.006118363469140604
   End of epoch 51; saving model... 

Epoch 52 of 2000
   Iteration 1 of 100, loss = 0.007179290056228638   Iteration 2 of 100, loss = 0.006562799913808703   Iteration 3 of 100, loss = 0.00603451719507575   Iteration 4 of 100, loss = 0.0060056253569200635   Iteration 5 of 100, loss = 0.006267914827913046   Iteration 6 of 100, loss = 0.005961173524459203   Iteration 7 of 100, loss = 0.005882506192262683   Iteration 8 of 100, loss = 0.005688136036042124   Iteration 9 of 100, loss = 0.006163698983275228   Iteration 10 of 100, loss = 0.006417245464399457   Iteration 11 of 100, loss = 0.006188847166909413   Iteration 12 of 100, loss = 0.0062768406157071395   Iteration 13 of 100, loss = 0.006386949430004909   Iteration 14 of 100, loss = 0.006180308343443487   Iteration 15 of 100, loss = 0.006445572944357991   Iteration 16 of 100, loss = 0.00635079039784614   Iteration 17 of 100, loss = 0.006238209042588577   Iteration 18 of 100, loss = 0.0061142329359427094   Iteration 19 of 100, loss = 0.006190457467087789   Iteration 20 of 100, loss = 0.00613555641612038   Iteration 21 of 100, loss = 0.00604428848739536   Iteration 22 of 100, loss = 0.006098718393001367   Iteration 23 of 100, loss = 0.006050761455022122   Iteration 24 of 100, loss = 0.0062999280538254725   Iteration 25 of 100, loss = 0.006286930860951543   Iteration 26 of 100, loss = 0.006130642956122756   Iteration 27 of 100, loss = 0.006121715737713708   Iteration 28 of 100, loss = 0.006081305710332734   Iteration 29 of 100, loss = 0.006043206739785342   Iteration 30 of 100, loss = 0.005985346467544635   Iteration 31 of 100, loss = 0.005940257316274989   Iteration 32 of 100, loss = 0.005976247048238292   Iteration 33 of 100, loss = 0.005992346612567251   Iteration 34 of 100, loss = 0.006001419428845539   Iteration 35 of 100, loss = 0.006008852792105505   Iteration 36 of 100, loss = 0.005968979766799344   Iteration 37 of 100, loss = 0.006076081605577791   Iteration 38 of 100, loss = 0.006053576245903969   Iteration 39 of 100, loss = 0.0060183501277023405   Iteration 40 of 100, loss = 0.006055649183690548   Iteration 41 of 100, loss = 0.006093589032477722   Iteration 42 of 100, loss = 0.0060779499333529245   Iteration 43 of 100, loss = 0.0060523005289047265   Iteration 44 of 100, loss = 0.005979638208042492   Iteration 45 of 100, loss = 0.0060289463235272305   Iteration 46 of 100, loss = 0.00602969860293619   Iteration 47 of 100, loss = 0.005957961468858288   Iteration 48 of 100, loss = 0.005957191092117379   Iteration 49 of 100, loss = 0.005889685662957478   Iteration 50 of 100, loss = 0.005864163497462869   Iteration 51 of 100, loss = 0.005840436208481882   Iteration 52 of 100, loss = 0.005775824538432062   Iteration 53 of 100, loss = 0.005748119222808559   Iteration 54 of 100, loss = 0.005778764736735159   Iteration 55 of 100, loss = 0.005814119301397692   Iteration 56 of 100, loss = 0.005774006617554862   Iteration 57 of 100, loss = 0.005777035786753945   Iteration 58 of 100, loss = 0.005760492319401739   Iteration 59 of 100, loss = 0.005710770814063943   Iteration 60 of 100, loss = 0.00572882363339886   Iteration 61 of 100, loss = 0.005694862390242395   Iteration 62 of 100, loss = 0.005652562384643863   Iteration 63 of 100, loss = 0.005749064113294322   Iteration 64 of 100, loss = 0.005761913096648641   Iteration 65 of 100, loss = 0.005800473360488048   Iteration 66 of 100, loss = 0.005873235436438611   Iteration 67 of 100, loss = 0.0059297977487987544   Iteration 68 of 100, loss = 0.0059101316488950565   Iteration 69 of 100, loss = 0.005873992067316304   Iteration 70 of 100, loss = 0.005873551219701767   Iteration 71 of 100, loss = 0.00582430049003115   Iteration 72 of 100, loss = 0.00578684529561239   Iteration 73 of 100, loss = 0.005788123263811616   Iteration 74 of 100, loss = 0.005811744014027755   Iteration 75 of 100, loss = 0.005799340701972445   Iteration 76 of 100, loss = 0.005778991957317646   Iteration 77 of 100, loss = 0.005798420345700987   Iteration 78 of 100, loss = 0.005781831336207688   Iteration 79 of 100, loss = 0.005791195293982761   Iteration 80 of 100, loss = 0.005759166888310574   Iteration 81 of 100, loss = 0.005710986503227441   Iteration 82 of 100, loss = 0.0056920591088738745   Iteration 83 of 100, loss = 0.005690026975023639   Iteration 84 of 100, loss = 0.005675746884662658   Iteration 85 of 100, loss = 0.005679467487532426   Iteration 86 of 100, loss = 0.005682765270669966   Iteration 87 of 100, loss = 0.005685597805349135   Iteration 88 of 100, loss = 0.005692878015741537   Iteration 89 of 100, loss = 0.005711666070280618   Iteration 90 of 100, loss = 0.0056773240108870795   Iteration 91 of 100, loss = 0.0056511260630501495   Iteration 92 of 100, loss = 0.005636800703106691   Iteration 93 of 100, loss = 0.005655644266235251   Iteration 94 of 100, loss = 0.00566415570953742   Iteration 95 of 100, loss = 0.005648744846449087   Iteration 96 of 100, loss = 0.005613903277359593   Iteration 97 of 100, loss = 0.005607102320711945   Iteration 98 of 100, loss = 0.0055892162229295595   Iteration 99 of 100, loss = 0.005621227198233357   Iteration 100 of 100, loss = 0.005590274285059422
   End of epoch 52; saving model... 

Epoch 53 of 2000
   Iteration 1 of 100, loss = 0.006695382762700319   Iteration 2 of 100, loss = 0.005463333101943135   Iteration 3 of 100, loss = 0.004989676953603824   Iteration 4 of 100, loss = 0.005865375394932926   Iteration 5 of 100, loss = 0.007061041053384542   Iteration 6 of 100, loss = 0.007092818074549238   Iteration 7 of 100, loss = 0.006399139695401702   Iteration 8 of 100, loss = 0.006343534856569022   Iteration 9 of 100, loss = 0.006579247148086627   Iteration 10 of 100, loss = 0.006174829159863293   Iteration 11 of 100, loss = 0.006126183444972743   Iteration 12 of 100, loss = 0.006290459248702973   Iteration 13 of 100, loss = 0.006112449820368336   Iteration 14 of 100, loss = 0.006058279707628701   Iteration 15 of 100, loss = 0.006309328057492773   Iteration 16 of 100, loss = 0.00630096068198327   Iteration 17 of 100, loss = 0.00615920262027751   Iteration 18 of 100, loss = 0.006157056519037319   Iteration 19 of 100, loss = 0.006171796434117775   Iteration 20 of 100, loss = 0.0061257521971128884   Iteration 21 of 100, loss = 0.006374929177885254   Iteration 22 of 100, loss = 0.006444609459404918   Iteration 23 of 100, loss = 0.006385567182998942   Iteration 24 of 100, loss = 0.0063682443675740314   Iteration 25 of 100, loss = 0.006295652305707336   Iteration 26 of 100, loss = 0.006454328925778659   Iteration 27 of 100, loss = 0.006387693488418504   Iteration 28 of 100, loss = 0.006399466065756444   Iteration 29 of 100, loss = 0.00638800458822014   Iteration 30 of 100, loss = 0.006409871849852303   Iteration 31 of 100, loss = 0.006453800593472777   Iteration 32 of 100, loss = 0.006399497076927219   Iteration 33 of 100, loss = 0.006336805671735695   Iteration 34 of 100, loss = 0.006447281448773164   Iteration 35 of 100, loss = 0.006654279579275421   Iteration 36 of 100, loss = 0.006663188499967671   Iteration 37 of 100, loss = 0.006647307910276829   Iteration 38 of 100, loss = 0.006579710985533893   Iteration 39 of 100, loss = 0.006556090009279358   Iteration 40 of 100, loss = 0.0064921522105578335   Iteration 41 of 100, loss = 0.006428250287682182   Iteration 42 of 100, loss = 0.0064149618736423905   Iteration 43 of 100, loss = 0.006448635143812659   Iteration 44 of 100, loss = 0.006424277295908806   Iteration 45 of 100, loss = 0.0064002695234699385   Iteration 46 of 100, loss = 0.006436756938574431   Iteration 47 of 100, loss = 0.006370740992195429   Iteration 48 of 100, loss = 0.006306843638109664   Iteration 49 of 100, loss = 0.006284427743557156   Iteration 50 of 100, loss = 0.006287638200446964   Iteration 51 of 100, loss = 0.006226347736539501   Iteration 52 of 100, loss = 0.00616606775796614   Iteration 53 of 100, loss = 0.006217979593202472   Iteration 54 of 100, loss = 0.006210933564472254   Iteration 55 of 100, loss = 0.006295991540801796   Iteration 56 of 100, loss = 0.006353366558739383   Iteration 57 of 100, loss = 0.006310484572232031   Iteration 58 of 100, loss = 0.006320023752652623   Iteration 59 of 100, loss = 0.006321542410937659   Iteration 60 of 100, loss = 0.006317820520295451   Iteration 61 of 100, loss = 0.00627160641044134   Iteration 62 of 100, loss = 0.006255496052965041   Iteration 63 of 100, loss = 0.006237018395156142   Iteration 64 of 100, loss = 0.0062182794863474555   Iteration 65 of 100, loss = 0.0062253562805171195   Iteration 66 of 100, loss = 0.006164378973401405   Iteration 67 of 100, loss = 0.006150260407811225   Iteration 68 of 100, loss = 0.006114409657825223   Iteration 69 of 100, loss = 0.006067280013087219   Iteration 70 of 100, loss = 0.006070232467858919   Iteration 71 of 100, loss = 0.006081964371358634   Iteration 72 of 100, loss = 0.006127570028183982   Iteration 73 of 100, loss = 0.006114177306960911   Iteration 74 of 100, loss = 0.0060779433036726475   Iteration 75 of 100, loss = 0.006066670445725322   Iteration 76 of 100, loss = 0.006040423033195303   Iteration 77 of 100, loss = 0.0059933163733644915   Iteration 78 of 100, loss = 0.005984988284464448   Iteration 79 of 100, loss = 0.005970292270796586   Iteration 80 of 100, loss = 0.005968908953946084   Iteration 81 of 100, loss = 0.006011859122893692   Iteration 82 of 100, loss = 0.005958445644199212   Iteration 83 of 100, loss = 0.005930467709304249   Iteration 84 of 100, loss = 0.005960626725850272   Iteration 85 of 100, loss = 0.005948962428716614   Iteration 86 of 100, loss = 0.005991822621665982   Iteration 87 of 100, loss = 0.006071604353418553   Iteration 88 of 100, loss = 0.006070167650415731   Iteration 89 of 100, loss = 0.006079835784516894   Iteration 90 of 100, loss = 0.006079149591581275   Iteration 91 of 100, loss = 0.0060635292122222404   Iteration 92 of 100, loss = 0.006051268346314116   Iteration 93 of 100, loss = 0.00601844379292821   Iteration 94 of 100, loss = 0.0060168032601297375   Iteration 95 of 100, loss = 0.00603254647116716   Iteration 96 of 100, loss = 0.006060511338243184   Iteration 97 of 100, loss = 0.0060505639250419034   Iteration 98 of 100, loss = 0.006053599955428543   Iteration 99 of 100, loss = 0.006042888998336187   Iteration 100 of 100, loss = 0.006015196627704427
   End of epoch 53; saving model... 

Epoch 54 of 2000
   Iteration 1 of 100, loss = 0.0040522124618291855   Iteration 2 of 100, loss = 0.005743082147091627   Iteration 3 of 100, loss = 0.006060911963383357   Iteration 4 of 100, loss = 0.004927798989228904   Iteration 5 of 100, loss = 0.005922837276011705   Iteration 6 of 100, loss = 0.0059368503279984   Iteration 7 of 100, loss = 0.0057377793293978486   Iteration 8 of 100, loss = 0.005626736267004162   Iteration 9 of 100, loss = 0.005947931928353177   Iteration 10 of 100, loss = 0.005973597662523389   Iteration 11 of 100, loss = 0.006482480813495137   Iteration 12 of 100, loss = 0.006317635299637914   Iteration 13 of 100, loss = 0.0062132998584554745   Iteration 14 of 100, loss = 0.006597521049635751   Iteration 15 of 100, loss = 0.006781912843386332   Iteration 16 of 100, loss = 0.006594627251615748   Iteration 17 of 100, loss = 0.0066023206009584315   Iteration 18 of 100, loss = 0.006542146878523959   Iteration 19 of 100, loss = 0.0064377192113744585   Iteration 20 of 100, loss = 0.006320256227627397   Iteration 21 of 100, loss = 0.006350679589169366   Iteration 22 of 100, loss = 0.006306090117008848   Iteration 23 of 100, loss = 0.006219875816579746   Iteration 24 of 100, loss = 0.006526473773798595   Iteration 25 of 100, loss = 0.006382667394354939   Iteration 26 of 100, loss = 0.0064234408424594085   Iteration 27 of 100, loss = 0.006320260603118826   Iteration 28 of 100, loss = 0.006217188975175044   Iteration 29 of 100, loss = 0.006319722714673342   Iteration 30 of 100, loss = 0.006229257521529992   Iteration 31 of 100, loss = 0.00620725306291734   Iteration 32 of 100, loss = 0.006268990284297615   Iteration 33 of 100, loss = 0.006260319754029765   Iteration 34 of 100, loss = 0.006300693898297408   Iteration 35 of 100, loss = 0.006215300510770508   Iteration 36 of 100, loss = 0.006116453254233218   Iteration 37 of 100, loss = 0.006125134774609594   Iteration 38 of 100, loss = 0.006048135336880621   Iteration 39 of 100, loss = 0.006042764080354037   Iteration 40 of 100, loss = 0.006068044842686504   Iteration 41 of 100, loss = 0.00611761408835286   Iteration 42 of 100, loss = 0.006073187005573085   Iteration 43 of 100, loss = 0.006022545005476406   Iteration 44 of 100, loss = 0.00594630717321045   Iteration 45 of 100, loss = 0.005929664755240083   Iteration 46 of 100, loss = 0.005918521094945786   Iteration 47 of 100, loss = 0.0059711956567666   Iteration 48 of 100, loss = 0.006026808837001833   Iteration 49 of 100, loss = 0.00606797371838926   Iteration 50 of 100, loss = 0.006005489742383361   Iteration 51 of 100, loss = 0.006101457612114209   Iteration 52 of 100, loss = 0.006055611964816658   Iteration 53 of 100, loss = 0.0060021392737497695   Iteration 54 of 100, loss = 0.006005308107921371   Iteration 55 of 100, loss = 0.005989563778381456   Iteration 56 of 100, loss = 0.005955690426552402   Iteration 57 of 100, loss = 0.005930724774340266   Iteration 58 of 100, loss = 0.005893308428469403   Iteration 59 of 100, loss = 0.005896386998247797   Iteration 60 of 100, loss = 0.005894456105306744   Iteration 61 of 100, loss = 0.005913701198506551   Iteration 62 of 100, loss = 0.005944365079724981   Iteration 63 of 100, loss = 0.005962958640699822   Iteration 64 of 100, loss = 0.005958354093309026   Iteration 65 of 100, loss = 0.005904169387828845   Iteration 66 of 100, loss = 0.0059389314035687485   Iteration 67 of 100, loss = 0.005953722278962829   Iteration 68 of 100, loss = 0.0059488509055774874   Iteration 69 of 100, loss = 0.00590375408300779   Iteration 70 of 100, loss = 0.005982591780567808   Iteration 71 of 100, loss = 0.006057186258799383   Iteration 72 of 100, loss = 0.00601321365360895   Iteration 73 of 100, loss = 0.006038461043180464   Iteration 74 of 100, loss = 0.006036380466350631   Iteration 75 of 100, loss = 0.006023417167986433   Iteration 76 of 100, loss = 0.006084134327370282   Iteration 77 of 100, loss = 0.006067517857587376   Iteration 78 of 100, loss = 0.0060487034258981925   Iteration 79 of 100, loss = 0.006103142096861442   Iteration 80 of 100, loss = 0.006129011898883619   Iteration 81 of 100, loss = 0.00611215300662558   Iteration 82 of 100, loss = 0.006069825411342629   Iteration 83 of 100, loss = 0.006070735471614872   Iteration 84 of 100, loss = 0.006047901791697811   Iteration 85 of 100, loss = 0.006040582531953559   Iteration 86 of 100, loss = 0.006052741932487765   Iteration 87 of 100, loss = 0.006073958732872859   Iteration 88 of 100, loss = 0.006066457643596964   Iteration 89 of 100, loss = 0.006022130139172077   Iteration 90 of 100, loss = 0.006056196128742562   Iteration 91 of 100, loss = 0.006051542262986794   Iteration 92 of 100, loss = 0.006027670711299162   Iteration 93 of 100, loss = 0.006000346779542905   Iteration 94 of 100, loss = 0.006018720165965088   Iteration 95 of 100, loss = 0.006094316466662445   Iteration 96 of 100, loss = 0.006130200049180227   Iteration 97 of 100, loss = 0.006109678191276863   Iteration 98 of 100, loss = 0.006105109977973055   Iteration 99 of 100, loss = 0.006101037521442079   Iteration 100 of 100, loss = 0.0061441354779526594
   End of epoch 54; saving model... 

Epoch 55 of 2000
   Iteration 1 of 100, loss = 0.005687279626727104   Iteration 2 of 100, loss = 0.005577897885814309   Iteration 3 of 100, loss = 0.0049307590040067835   Iteration 4 of 100, loss = 0.005170122836716473   Iteration 5 of 100, loss = 0.006017465982586146   Iteration 6 of 100, loss = 0.006150870894392331   Iteration 7 of 100, loss = 0.006096368522516319   Iteration 8 of 100, loss = 0.005901748198084533   Iteration 9 of 100, loss = 0.0056211019141806495   Iteration 10 of 100, loss = 0.005366359488107264   Iteration 11 of 100, loss = 0.00519792384214022   Iteration 12 of 100, loss = 0.005033177129613857   Iteration 13 of 100, loss = 0.005191409602188147   Iteration 14 of 100, loss = 0.005146041645535401   Iteration 15 of 100, loss = 0.005362107666830222   Iteration 16 of 100, loss = 0.005249721114523709   Iteration 17 of 100, loss = 0.005256501437329194   Iteration 18 of 100, loss = 0.005524915668906437   Iteration 19 of 100, loss = 0.005487978213319653   Iteration 20 of 100, loss = 0.005527797294780612   Iteration 21 of 100, loss = 0.00549396417946333   Iteration 22 of 100, loss = 0.005392549411309036   Iteration 23 of 100, loss = 0.005342323009086692   Iteration 24 of 100, loss = 0.0053892751651195185   Iteration 25 of 100, loss = 0.005479173585772514   Iteration 26 of 100, loss = 0.00556435498695534   Iteration 27 of 100, loss = 0.005638181835550953   Iteration 28 of 100, loss = 0.005673587305604347   Iteration 29 of 100, loss = 0.005633404687175463   Iteration 30 of 100, loss = 0.005633590541159113   Iteration 31 of 100, loss = 0.005531815526586386   Iteration 32 of 100, loss = 0.0054879930394236   Iteration 33 of 100, loss = 0.005503846346541788   Iteration 34 of 100, loss = 0.005578602239599123   Iteration 35 of 100, loss = 0.005510031145864299   Iteration 36 of 100, loss = 0.005455576950528969   Iteration 37 of 100, loss = 0.005438729485094144   Iteration 38 of 100, loss = 0.005504990063950811   Iteration 39 of 100, loss = 0.005489010286207001   Iteration 40 of 100, loss = 0.005632010981207714   Iteration 41 of 100, loss = 0.005599708108958311   Iteration 42 of 100, loss = 0.005579990750577833   Iteration 43 of 100, loss = 0.005557343975619175   Iteration 44 of 100, loss = 0.005656342979901555   Iteration 45 of 100, loss = 0.00560759904070033   Iteration 46 of 100, loss = 0.005653231566690881   Iteration 47 of 100, loss = 0.00557363493259045   Iteration 48 of 100, loss = 0.005577967941159538   Iteration 49 of 100, loss = 0.005507092445385547   Iteration 50 of 100, loss = 0.005471060888376087   Iteration 51 of 100, loss = 0.005515691803713494   Iteration 52 of 100, loss = 0.0055013815760433385   Iteration 53 of 100, loss = 0.005461626609277753   Iteration 54 of 100, loss = 0.005414936823028795   Iteration 55 of 100, loss = 0.005395081489008259   Iteration 56 of 100, loss = 0.0054743284313839725   Iteration 57 of 100, loss = 0.005464949965754752   Iteration 58 of 100, loss = 0.005456398572403424   Iteration 59 of 100, loss = 0.00541174165722993   Iteration 60 of 100, loss = 0.005481512893068915   Iteration 61 of 100, loss = 0.00545926012106423   Iteration 62 of 100, loss = 0.005460351482108836   Iteration 63 of 100, loss = 0.005423225504937508   Iteration 64 of 100, loss = 0.005507873907845351   Iteration 65 of 100, loss = 0.005478553934237705   Iteration 66 of 100, loss = 0.005459880860254281   Iteration 67 of 100, loss = 0.005480765311200338   Iteration 68 of 100, loss = 0.005449672587393948   Iteration 69 of 100, loss = 0.005423792501223152   Iteration 70 of 100, loss = 0.005394054275737809   Iteration 71 of 100, loss = 0.005412602533166572   Iteration 72 of 100, loss = 0.005382008596724417   Iteration 73 of 100, loss = 0.005463083177383938   Iteration 74 of 100, loss = 0.005439029724928676   Iteration 75 of 100, loss = 0.005453554871492088   Iteration 76 of 100, loss = 0.005459921001027779   Iteration 77 of 100, loss = 0.005414992100680126   Iteration 78 of 100, loss = 0.00542571001763766   Iteration 79 of 100, loss = 0.005420361629310005   Iteration 80 of 100, loss = 0.0053817436782992445   Iteration 81 of 100, loss = 0.005417155180942773   Iteration 82 of 100, loss = 0.005484982698917298   Iteration 83 of 100, loss = 0.005475186152350023   Iteration 84 of 100, loss = 0.005577637685096956   Iteration 85 of 100, loss = 0.00553709823939511   Iteration 86 of 100, loss = 0.0055214886345120884   Iteration 87 of 100, loss = 0.005515627197696474   Iteration 88 of 100, loss = 0.005539240637021562   Iteration 89 of 100, loss = 0.005555115335390725   Iteration 90 of 100, loss = 0.005564498310236053   Iteration 91 of 100, loss = 0.005543170232008529   Iteration 92 of 100, loss = 0.005544205410051686   Iteration 93 of 100, loss = 0.0055406673833908095   Iteration 94 of 100, loss = 0.005524783237946239   Iteration 95 of 100, loss = 0.005533076015203015   Iteration 96 of 100, loss = 0.005540756611784066   Iteration 97 of 100, loss = 0.005601604801564256   Iteration 98 of 100, loss = 0.005580342836839584   Iteration 99 of 100, loss = 0.005564915577203713   Iteration 100 of 100, loss = 0.00557441370212473
   End of epoch 55; saving model... 

Epoch 56 of 2000
   Iteration 1 of 100, loss = 0.006758084520697594   Iteration 2 of 100, loss = 0.006031034747138619   Iteration 3 of 100, loss = 0.005979870446026325   Iteration 4 of 100, loss = 0.0075923181138932705   Iteration 5 of 100, loss = 0.006827956065535545   Iteration 6 of 100, loss = 0.007066469484319289   Iteration 7 of 100, loss = 0.006449559537161674   Iteration 8 of 100, loss = 0.00646399924880825   Iteration 9 of 100, loss = 0.0066299649317645365   Iteration 10 of 100, loss = 0.006627942784689367   Iteration 11 of 100, loss = 0.006497740682045167   Iteration 12 of 100, loss = 0.006508661065405856   Iteration 13 of 100, loss = 0.006415231207099099   Iteration 14 of 100, loss = 0.006136929865793458   Iteration 15 of 100, loss = 0.00615674457512796   Iteration 16 of 100, loss = 0.006164166275993921   Iteration 17 of 100, loss = 0.006206502192927634   Iteration 18 of 100, loss = 0.006238632356851465   Iteration 19 of 100, loss = 0.006078753902233745   Iteration 20 of 100, loss = 0.006202501605730504   Iteration 21 of 100, loss = 0.0060411925050651745   Iteration 22 of 100, loss = 0.00607898047151552   Iteration 23 of 100, loss = 0.006194365848584667   Iteration 24 of 100, loss = 0.006352230586344376   Iteration 25 of 100, loss = 0.006226527066901326   Iteration 26 of 100, loss = 0.00613718587332047   Iteration 27 of 100, loss = 0.006111382023879775   Iteration 28 of 100, loss = 0.006001678644679487   Iteration 29 of 100, loss = 0.005941500774873742   Iteration 30 of 100, loss = 0.005928885471075773   Iteration 31 of 100, loss = 0.005860719356625792   Iteration 32 of 100, loss = 0.005901710748730693   Iteration 33 of 100, loss = 0.005790109675603382   Iteration 34 of 100, loss = 0.005731838070513571   Iteration 35 of 100, loss = 0.005833963863551617   Iteration 36 of 100, loss = 0.005945977004658844   Iteration 37 of 100, loss = 0.005968589813926736   Iteration 38 of 100, loss = 0.006048735525262983   Iteration 39 of 100, loss = 0.006053990457589045   Iteration 40 of 100, loss = 0.006049840955529362   Iteration 41 of 100, loss = 0.006041598881072387   Iteration 42 of 100, loss = 0.006045419390180281   Iteration 43 of 100, loss = 0.005966737027128422   Iteration 44 of 100, loss = 0.005997507340825078   Iteration 45 of 100, loss = 0.0059096199098146625   Iteration 46 of 100, loss = 0.005850796911703504   Iteration 47 of 100, loss = 0.005805064834892116   Iteration 48 of 100, loss = 0.005782848971042161   Iteration 49 of 100, loss = 0.0057720496148175125   Iteration 50 of 100, loss = 0.0058392640762031075   Iteration 51 of 100, loss = 0.005788626619523354   Iteration 52 of 100, loss = 0.005826734172072834   Iteration 53 of 100, loss = 0.005815120831237368   Iteration 54 of 100, loss = 0.005844759267616879   Iteration 55 of 100, loss = 0.005894301438026808   Iteration 56 of 100, loss = 0.005911994205754516   Iteration 57 of 100, loss = 0.005924825609677978   Iteration 58 of 100, loss = 0.005912985375696986   Iteration 59 of 100, loss = 0.005878434287605144   Iteration 60 of 100, loss = 0.0058973531161124505   Iteration 61 of 100, loss = 0.005844687630773567   Iteration 62 of 100, loss = 0.005934522472201816   Iteration 63 of 100, loss = 0.005910695840915044   Iteration 64 of 100, loss = 0.005941038456512615   Iteration 65 of 100, loss = 0.0059342367574572565   Iteration 66 of 100, loss = 0.006040688251342737   Iteration 67 of 100, loss = 0.006012008011118689   Iteration 68 of 100, loss = 0.006008183426114128   Iteration 69 of 100, loss = 0.006042101724154275   Iteration 70 of 100, loss = 0.006017353418948395   Iteration 71 of 100, loss = 0.006032905488891501   Iteration 72 of 100, loss = 0.006064173144598802   Iteration 73 of 100, loss = 0.006029931745453648   Iteration 74 of 100, loss = 0.005993023341697817   Iteration 75 of 100, loss = 0.006003447463735938   Iteration 76 of 100, loss = 0.005976340417921739   Iteration 77 of 100, loss = 0.006032948240081405   Iteration 78 of 100, loss = 0.006033062030417988   Iteration 79 of 100, loss = 0.006005646693343415   Iteration 80 of 100, loss = 0.005969404662027955   Iteration 81 of 100, loss = 0.005962020809543721   Iteration 82 of 100, loss = 0.005936002617179439   Iteration 83 of 100, loss = 0.005937727255163243   Iteration 84 of 100, loss = 0.005977933802309313   Iteration 85 of 100, loss = 0.0059388905297964815   Iteration 86 of 100, loss = 0.005990768281937858   Iteration 87 of 100, loss = 0.006039068635403253   Iteration 88 of 100, loss = 0.006019725615095178   Iteration 89 of 100, loss = 0.006024773878809274   Iteration 90 of 100, loss = 0.006057649713733958   Iteration 91 of 100, loss = 0.00605847139249218   Iteration 92 of 100, loss = 0.006039570650065561   Iteration 93 of 100, loss = 0.006072142749764426   Iteration 94 of 100, loss = 0.006092621932460114   Iteration 95 of 100, loss = 0.0060739438024986735   Iteration 96 of 100, loss = 0.006032468508540963   Iteration 97 of 100, loss = 0.006021694448229271   Iteration 98 of 100, loss = 0.006013451452956212   Iteration 99 of 100, loss = 0.006015122806973228   Iteration 100 of 100, loss = 0.006032099188305437
   End of epoch 56; saving model... 

Epoch 57 of 2000
   Iteration 1 of 100, loss = 0.008853310719132423   Iteration 2 of 100, loss = 0.007589916465803981   Iteration 3 of 100, loss = 0.006809713784605265   Iteration 4 of 100, loss = 0.0060386992408894   Iteration 5 of 100, loss = 0.005773623613640666   Iteration 6 of 100, loss = 0.005236325707907478   Iteration 7 of 100, loss = 0.005429809181285756   Iteration 8 of 100, loss = 0.0055081978207454085   Iteration 9 of 100, loss = 0.0055356369767751955   Iteration 10 of 100, loss = 0.005271876230835915   Iteration 11 of 100, loss = 0.005067509937692772   Iteration 12 of 100, loss = 0.005705996726950009   Iteration 13 of 100, loss = 0.00578029382114227   Iteration 14 of 100, loss = 0.005605416738295129   Iteration 15 of 100, loss = 0.005911225980768601   Iteration 16 of 100, loss = 0.0060507327143568546   Iteration 17 of 100, loss = 0.006122417939717279   Iteration 18 of 100, loss = 0.0059476627761291135   Iteration 19 of 100, loss = 0.005969271357906492   Iteration 20 of 100, loss = 0.005992440739646554   Iteration 21 of 100, loss = 0.006035906173998401   Iteration 22 of 100, loss = 0.006035213041203943   Iteration 23 of 100, loss = 0.00598560824342396   Iteration 24 of 100, loss = 0.005947778913347672   Iteration 25 of 100, loss = 0.005810393197461963   Iteration 26 of 100, loss = 0.005928023386961565   Iteration 27 of 100, loss = 0.006152918726136839   Iteration 28 of 100, loss = 0.006165624621124672   Iteration 29 of 100, loss = 0.006125459696391019   Iteration 30 of 100, loss = 0.006005066897099217   Iteration 31 of 100, loss = 0.006005326781662241   Iteration 32 of 100, loss = 0.006023553927661851   Iteration 33 of 100, loss = 0.005969906366909995   Iteration 34 of 100, loss = 0.006026883171323468   Iteration 35 of 100, loss = 0.006030990702233144   Iteration 36 of 100, loss = 0.005970039075085272   Iteration 37 of 100, loss = 0.0060158658684608905   Iteration 38 of 100, loss = 0.005989770815511675   Iteration 39 of 100, loss = 0.005905783215824228   Iteration 40 of 100, loss = 0.005944506212836131   Iteration 41 of 100, loss = 0.005891645395355981   Iteration 42 of 100, loss = 0.005899006057353247   Iteration 43 of 100, loss = 0.005895971450521503   Iteration 44 of 100, loss = 0.0059414127926257524   Iteration 45 of 100, loss = 0.006046579426361455   Iteration 46 of 100, loss = 0.005988297482911983   Iteration 47 of 100, loss = 0.005937679061428346   Iteration 48 of 100, loss = 0.005891975883666116   Iteration 49 of 100, loss = 0.0058991037717811305   Iteration 50 of 100, loss = 0.005901610641740262   Iteration 51 of 100, loss = 0.005914191637809078   Iteration 52 of 100, loss = 0.005888169179133211   Iteration 53 of 100, loss = 0.005846092574087516   Iteration 54 of 100, loss = 0.005903723382356542   Iteration 55 of 100, loss = 0.005952309486879544   Iteration 56 of 100, loss = 0.005949359146013323   Iteration 57 of 100, loss = 0.005906822960496994   Iteration 58 of 100, loss = 0.005851455257627471   Iteration 59 of 100, loss = 0.005811436050492576   Iteration 60 of 100, loss = 0.005839195556472987   Iteration 61 of 100, loss = 0.005804003002580072   Iteration 62 of 100, loss = 0.005781576240194901   Iteration 63 of 100, loss = 0.005751065011801464   Iteration 64 of 100, loss = 0.0057512757448421326   Iteration 65 of 100, loss = 0.005807998672557565   Iteration 66 of 100, loss = 0.00576402225432861   Iteration 67 of 100, loss = 0.005791290360850407   Iteration 68 of 100, loss = 0.005907220659804914   Iteration 69 of 100, loss = 0.005872584757921489   Iteration 70 of 100, loss = 0.005861073286671723   Iteration 71 of 100, loss = 0.005848142305310344   Iteration 72 of 100, loss = 0.00584529030473075   Iteration 73 of 100, loss = 0.005843369111622849   Iteration 74 of 100, loss = 0.0058497501587545546   Iteration 75 of 100, loss = 0.005897076788047949   Iteration 76 of 100, loss = 0.005905270270120941   Iteration 77 of 100, loss = 0.0059267706782012795   Iteration 78 of 100, loss = 0.005905730297597937   Iteration 79 of 100, loss = 0.005901853748467527   Iteration 80 of 100, loss = 0.005898215982597321   Iteration 81 of 100, loss = 0.005887573469936112   Iteration 82 of 100, loss = 0.005931095515445965   Iteration 83 of 100, loss = 0.005939672661788133   Iteration 84 of 100, loss = 0.005938955333216914   Iteration 85 of 100, loss = 0.005931817636112956   Iteration 86 of 100, loss = 0.0059318902447473175   Iteration 87 of 100, loss = 0.005905376096930483   Iteration 88 of 100, loss = 0.00588447469106706   Iteration 89 of 100, loss = 0.005890452127715343   Iteration 90 of 100, loss = 0.005900114854901202   Iteration 91 of 100, loss = 0.005924037061529336   Iteration 92 of 100, loss = 0.005933011211353638   Iteration 93 of 100, loss = 0.005894448350293822   Iteration 94 of 100, loss = 0.005952295919067841   Iteration 95 of 100, loss = 0.005947453217384846   Iteration 96 of 100, loss = 0.006002265933299593   Iteration 97 of 100, loss = 0.005994910242266415   Iteration 98 of 100, loss = 0.006017424757782446   Iteration 99 of 100, loss = 0.005989487219432538   Iteration 100 of 100, loss = 0.005976965881418436
   End of epoch 57; saving model... 

Epoch 58 of 2000
   Iteration 1 of 100, loss = 0.009521839208900928   Iteration 2 of 100, loss = 0.00796030554920435   Iteration 3 of 100, loss = 0.008129860274493694   Iteration 4 of 100, loss = 0.007161302026361227   Iteration 5 of 100, loss = 0.008116795122623444   Iteration 6 of 100, loss = 0.007449612875158588   Iteration 7 of 100, loss = 0.0077898710566971984   Iteration 8 of 100, loss = 0.007697360997553915   Iteration 9 of 100, loss = 0.007684556974305047   Iteration 10 of 100, loss = 0.007615220546722412   Iteration 11 of 100, loss = 0.008066137405959043   Iteration 12 of 100, loss = 0.007806913849587242   Iteration 13 of 100, loss = 0.007799826669864929   Iteration 14 of 100, loss = 0.007679448163669024   Iteration 15 of 100, loss = 0.007501206360757351   Iteration 16 of 100, loss = 0.007225681722047739   Iteration 17 of 100, loss = 0.007139370598665932   Iteration 18 of 100, loss = 0.006916823706382679   Iteration 19 of 100, loss = 0.006783288793246213   Iteration 20 of 100, loss = 0.006851759541314095   Iteration 21 of 100, loss = 0.006775907318418224   Iteration 22 of 100, loss = 0.006737650636668232   Iteration 23 of 100, loss = 0.006704412552568576   Iteration 24 of 100, loss = 0.0067554683094689   Iteration 25 of 100, loss = 0.006955307526513934   Iteration 26 of 100, loss = 0.006856402050918684   Iteration 27 of 100, loss = 0.006778970800547136   Iteration 28 of 100, loss = 0.006765343057590404   Iteration 29 of 100, loss = 0.006823972196735698   Iteration 30 of 100, loss = 0.006823764904402197   Iteration 31 of 100, loss = 0.006730747416675571   Iteration 32 of 100, loss = 0.006686926928523462   Iteration 33 of 100, loss = 0.006631363289092074   Iteration 34 of 100, loss = 0.006569335586391389   Iteration 35 of 100, loss = 0.00653208039834031   Iteration 36 of 100, loss = 0.006520271346542156   Iteration 37 of 100, loss = 0.006518313818535692   Iteration 38 of 100, loss = 0.006529773015675968   Iteration 39 of 100, loss = 0.006483331973401782   Iteration 40 of 100, loss = 0.0065479026234243065   Iteration 41 of 100, loss = 0.006583149936731632   Iteration 42 of 100, loss = 0.006643046009620386   Iteration 43 of 100, loss = 0.006606211934541893   Iteration 44 of 100, loss = 0.006673177222678946   Iteration 45 of 100, loss = 0.006720350915566086   Iteration 46 of 100, loss = 0.006739444580212559   Iteration 47 of 100, loss = 0.006731067412592312   Iteration 48 of 100, loss = 0.006664847562205978   Iteration 49 of 100, loss = 0.0066904068059687105   Iteration 50 of 100, loss = 0.006606205464340747   Iteration 51 of 100, loss = 0.006657875165818077   Iteration 52 of 100, loss = 0.0066759635362989055   Iteration 53 of 100, loss = 0.006591488545725368   Iteration 54 of 100, loss = 0.006627358332345331   Iteration 55 of 100, loss = 0.006593554831025275   Iteration 56 of 100, loss = 0.006593122978561691   Iteration 57 of 100, loss = 0.006578392439048018   Iteration 58 of 100, loss = 0.006570103465868482   Iteration 59 of 100, loss = 0.006498576441811303   Iteration 60 of 100, loss = 0.006474598008207977   Iteration 61 of 100, loss = 0.006393317438539912   Iteration 62 of 100, loss = 0.00632923228606101   Iteration 63 of 100, loss = 0.006301008275754395   Iteration 64 of 100, loss = 0.00625800855414127   Iteration 65 of 100, loss = 0.006200066180183338   Iteration 66 of 100, loss = 0.006145448427449799   Iteration 67 of 100, loss = 0.006106539688476209   Iteration 68 of 100, loss = 0.006109796324060024   Iteration 69 of 100, loss = 0.00607309520136619   Iteration 70 of 100, loss = 0.0060541114969445125   Iteration 71 of 100, loss = 0.006062125872400865   Iteration 72 of 100, loss = 0.006035976079551296   Iteration 73 of 100, loss = 0.0060654695222332865   Iteration 74 of 100, loss = 0.006031274219748337   Iteration 75 of 100, loss = 0.00602230123244226   Iteration 76 of 100, loss = 0.006039527045734423   Iteration 77 of 100, loss = 0.0060054462179299686   Iteration 78 of 100, loss = 0.005984414449463097   Iteration 79 of 100, loss = 0.0059415791478432435   Iteration 80 of 100, loss = 0.005989943124586716   Iteration 81 of 100, loss = 0.005997906893169806   Iteration 82 of 100, loss = 0.006027670310265044   Iteration 83 of 100, loss = 0.006069056268960956   Iteration 84 of 100, loss = 0.006073186606434839   Iteration 85 of 100, loss = 0.006053828152225298   Iteration 86 of 100, loss = 0.006038807251295725   Iteration 87 of 100, loss = 0.006058604579590176   Iteration 88 of 100, loss = 0.006114494081967595   Iteration 89 of 100, loss = 0.006107315619926105   Iteration 90 of 100, loss = 0.006079440739833646   Iteration 91 of 100, loss = 0.006058682667111958   Iteration 92 of 100, loss = 0.0060659411626503516   Iteration 93 of 100, loss = 0.006065877134441048   Iteration 94 of 100, loss = 0.006055050559262646   Iteration 95 of 100, loss = 0.006065676361322403   Iteration 96 of 100, loss = 0.0060536751213173074   Iteration 97 of 100, loss = 0.0060408253933197445   Iteration 98 of 100, loss = 0.006011460069091801   Iteration 99 of 100, loss = 0.006006868436198794   Iteration 100 of 100, loss = 0.005966233455110341
   End of epoch 58; saving model... 

Epoch 59 of 2000
   Iteration 1 of 100, loss = 0.0038533147890120745   Iteration 2 of 100, loss = 0.006147957989014685   Iteration 3 of 100, loss = 0.005177749398474892   Iteration 4 of 100, loss = 0.004835904808714986   Iteration 5 of 100, loss = 0.005320502631366253   Iteration 6 of 100, loss = 0.00478374632075429   Iteration 7 of 100, loss = 0.004589598160237074   Iteration 8 of 100, loss = 0.004519543785136193   Iteration 9 of 100, loss = 0.0050279188176823985   Iteration 10 of 100, loss = 0.004944060323759913   Iteration 11 of 100, loss = 0.004865051416510885   Iteration 12 of 100, loss = 0.0047564392249720795   Iteration 13 of 100, loss = 0.004856354861448591   Iteration 14 of 100, loss = 0.004870368849619159   Iteration 15 of 100, loss = 0.005088797102992733   Iteration 16 of 100, loss = 0.005007610248867422   Iteration 17 of 100, loss = 0.004961279878283248   Iteration 18 of 100, loss = 0.005156396681235896   Iteration 19 of 100, loss = 0.0050962516841919795   Iteration 20 of 100, loss = 0.005426529375836253   Iteration 21 of 100, loss = 0.005441906728914806   Iteration 22 of 100, loss = 0.005454834360121326   Iteration 23 of 100, loss = 0.005303564400452635   Iteration 24 of 100, loss = 0.0052736941336964565   Iteration 25 of 100, loss = 0.005214772969484329   Iteration 26 of 100, loss = 0.0051600780929080565   Iteration 27 of 100, loss = 0.005079177889490017   Iteration 28 of 100, loss = 0.005174599330140544   Iteration 29 of 100, loss = 0.005352729586242088   Iteration 30 of 100, loss = 0.0055168091086670755   Iteration 31 of 100, loss = 0.00568599684254056   Iteration 32 of 100, loss = 0.005730738332204055   Iteration 33 of 100, loss = 0.005823138332220189   Iteration 34 of 100, loss = 0.0058336885139236554   Iteration 35 of 100, loss = 0.005792264234540718   Iteration 36 of 100, loss = 0.0058926023322985405   Iteration 37 of 100, loss = 0.005841267150449189   Iteration 38 of 100, loss = 0.005824336714699473   Iteration 39 of 100, loss = 0.005896838507256829   Iteration 40 of 100, loss = 0.005826577369589359   Iteration 41 of 100, loss = 0.005767251069589359   Iteration 42 of 100, loss = 0.005801312769541428   Iteration 43 of 100, loss = 0.005769095946709777   Iteration 44 of 100, loss = 0.005824043521318923   Iteration 45 of 100, loss = 0.005770539502716727   Iteration 46 of 100, loss = 0.0057767299408821955   Iteration 47 of 100, loss = 0.00584723285221039   Iteration 48 of 100, loss = 0.00580689362444294   Iteration 49 of 100, loss = 0.005778013044322024   Iteration 50 of 100, loss = 0.005874531157314777   Iteration 51 of 100, loss = 0.005949052543762852   Iteration 52 of 100, loss = 0.005954643980098458   Iteration 53 of 100, loss = 0.005902053116170584   Iteration 54 of 100, loss = 0.005864238577756893   Iteration 55 of 100, loss = 0.005833696358075196   Iteration 56 of 100, loss = 0.005902266117378271   Iteration 57 of 100, loss = 0.0058932895404531765   Iteration 58 of 100, loss = 0.005924032250387144   Iteration 59 of 100, loss = 0.005907338582200266   Iteration 60 of 100, loss = 0.0059790742699988185   Iteration 61 of 100, loss = 0.005961952925674984   Iteration 62 of 100, loss = 0.005962225304345691   Iteration 63 of 100, loss = 0.005967802623109449   Iteration 64 of 100, loss = 0.005991912719764514   Iteration 65 of 100, loss = 0.005989753709246333   Iteration 66 of 100, loss = 0.005976297606883401   Iteration 67 of 100, loss = 0.0059639441662593115   Iteration 68 of 100, loss = 0.005981690322240705   Iteration 69 of 100, loss = 0.005965575349746623   Iteration 70 of 100, loss = 0.005970363814516791   Iteration 71 of 100, loss = 0.005957359589085403   Iteration 72 of 100, loss = 0.006015175277651805   Iteration 73 of 100, loss = 0.006054862437463582   Iteration 74 of 100, loss = 0.006035775874388983   Iteration 75 of 100, loss = 0.006038326437895497   Iteration 76 of 100, loss = 0.006049866276474572   Iteration 77 of 100, loss = 0.0060106046473631615   Iteration 78 of 100, loss = 0.005996973719447851   Iteration 79 of 100, loss = 0.0060370990275582185   Iteration 80 of 100, loss = 0.006021669338224456   Iteration 81 of 100, loss = 0.005967638463954683   Iteration 82 of 100, loss = 0.005959514894795309   Iteration 83 of 100, loss = 0.005990458542974778   Iteration 84 of 100, loss = 0.005967147545778148   Iteration 85 of 100, loss = 0.00598572306061054   Iteration 86 of 100, loss = 0.0060187087172295815   Iteration 87 of 100, loss = 0.0060645604222456274   Iteration 88 of 100, loss = 0.006068210527618331   Iteration 89 of 100, loss = 0.006041276234652052   Iteration 90 of 100, loss = 0.006039864945018457   Iteration 91 of 100, loss = 0.006094655352081735   Iteration 92 of 100, loss = 0.00611504859989509   Iteration 93 of 100, loss = 0.00610019480158645   Iteration 94 of 100, loss = 0.006076445684153983   Iteration 95 of 100, loss = 0.00606774840699999   Iteration 96 of 100, loss = 0.006081742239378703   Iteration 97 of 100, loss = 0.006069336120116035   Iteration 98 of 100, loss = 0.006036511562973717   Iteration 99 of 100, loss = 0.006004925699659971   Iteration 100 of 100, loss = 0.006001122598536313
   End of epoch 59; saving model... 

Epoch 60 of 2000
   Iteration 1 of 100, loss = 0.00201666122302413   Iteration 2 of 100, loss = 0.005983422277495265   Iteration 3 of 100, loss = 0.0057444193710883456   Iteration 4 of 100, loss = 0.005204315937589854   Iteration 5 of 100, loss = 0.005384257296100259   Iteration 6 of 100, loss = 0.004909809756403168   Iteration 7 of 100, loss = 0.004933438662971769   Iteration 8 of 100, loss = 0.004767327714944258   Iteration 9 of 100, loss = 0.004742235074647599   Iteration 10 of 100, loss = 0.004610482836142182   Iteration 11 of 100, loss = 0.00468276140534065   Iteration 12 of 100, loss = 0.005010989766257505   Iteration 13 of 100, loss = 0.00493400998843404   Iteration 14 of 100, loss = 0.0047925406501495415   Iteration 15 of 100, loss = 0.004887395057206353   Iteration 16 of 100, loss = 0.004915015349979512   Iteration 17 of 100, loss = 0.0048339971176841676   Iteration 18 of 100, loss = 0.004859046829450462   Iteration 19 of 100, loss = 0.00475963795753686   Iteration 20 of 100, loss = 0.004821720207110048   Iteration 21 of 100, loss = 0.004943185508073796   Iteration 22 of 100, loss = 0.004954099062491547   Iteration 23 of 100, loss = 0.004987870160814213   Iteration 24 of 100, loss = 0.005114851500062893   Iteration 25 of 100, loss = 0.005080834459513426   Iteration 26 of 100, loss = 0.005025401362217963   Iteration 27 of 100, loss = 0.005041913293233073   Iteration 28 of 100, loss = 0.004995405116850244   Iteration 29 of 100, loss = 0.0051101405125368255   Iteration 30 of 100, loss = 0.005051390182537337   Iteration 31 of 100, loss = 0.004987833893767769   Iteration 32 of 100, loss = 0.004923882930597756   Iteration 33 of 100, loss = 0.005093819355930795   Iteration 34 of 100, loss = 0.005015148733304266   Iteration 35 of 100, loss = 0.004959542776591011   Iteration 36 of 100, loss = 0.004961477159263773   Iteration 37 of 100, loss = 0.004982722048471506   Iteration 38 of 100, loss = 0.005182441036020846   Iteration 39 of 100, loss = 0.005155034178199294   Iteration 40 of 100, loss = 0.005192399496445432   Iteration 41 of 100, loss = 0.005183616272605411   Iteration 42 of 100, loss = 0.005316670723481192   Iteration 43 of 100, loss = 0.005358178303901886   Iteration 44 of 100, loss = 0.005303010841916231   Iteration 45 of 100, loss = 0.005286415862954325   Iteration 46 of 100, loss = 0.005413440936852408   Iteration 47 of 100, loss = 0.005411818564096664   Iteration 48 of 100, loss = 0.005460809014039114   Iteration 49 of 100, loss = 0.005503058471545881   Iteration 50 of 100, loss = 0.005511201284825802   Iteration 51 of 100, loss = 0.005638530989195786   Iteration 52 of 100, loss = 0.005590258085598739   Iteration 53 of 100, loss = 0.005653944876888451   Iteration 54 of 100, loss = 0.005700354179781344   Iteration 55 of 100, loss = 0.005722100253809582   Iteration 56 of 100, loss = 0.005695221205574593   Iteration 57 of 100, loss = 0.005750034257704229   Iteration 58 of 100, loss = 0.005764964759221365   Iteration 59 of 100, loss = 0.005748431450860985   Iteration 60 of 100, loss = 0.005813745378206173   Iteration 61 of 100, loss = 0.005828356454301564   Iteration 62 of 100, loss = 0.005912968220429555   Iteration 63 of 100, loss = 0.005897156657680633   Iteration 64 of 100, loss = 0.005882074525288772   Iteration 65 of 100, loss = 0.0059001075533720165   Iteration 66 of 100, loss = 0.005880781040160042   Iteration 67 of 100, loss = 0.005870200485102276   Iteration 68 of 100, loss = 0.0058806864065392055   Iteration 69 of 100, loss = 0.005912862022987742   Iteration 70 of 100, loss = 0.005903846012162311   Iteration 71 of 100, loss = 0.005989428767016236   Iteration 72 of 100, loss = 0.006035515650485952   Iteration 73 of 100, loss = 0.006033806143047875   Iteration 74 of 100, loss = 0.005982550521809104   Iteration 75 of 100, loss = 0.006057300524165233   Iteration 76 of 100, loss = 0.006058512905024384   Iteration 77 of 100, loss = 0.0061147463592615995   Iteration 78 of 100, loss = 0.006129144732720959   Iteration 79 of 100, loss = 0.006138129926086227   Iteration 80 of 100, loss = 0.006124037021072582   Iteration 81 of 100, loss = 0.0061225340023268885   Iteration 82 of 100, loss = 0.006097257307662469   Iteration 83 of 100, loss = 0.006052813049495579   Iteration 84 of 100, loss = 0.006011820093373812   Iteration 85 of 100, loss = 0.006003292896510924   Iteration 86 of 100, loss = 0.005997622255669083   Iteration 87 of 100, loss = 0.005965788837993282   Iteration 88 of 100, loss = 0.0060171116545627065   Iteration 89 of 100, loss = 0.006023462642026082   Iteration 90 of 100, loss = 0.006013364272399081   Iteration 91 of 100, loss = 0.0060124975107200855   Iteration 92 of 100, loss = 0.0059969090836365585   Iteration 93 of 100, loss = 0.0059790891915639886   Iteration 94 of 100, loss = 0.005982255696893689   Iteration 95 of 100, loss = 0.005963457120876563   Iteration 96 of 100, loss = 0.005961298481755269   Iteration 97 of 100, loss = 0.005977894241931205   Iteration 98 of 100, loss = 0.005994924139801641   Iteration 99 of 100, loss = 0.006011107837724866   Iteration 100 of 100, loss = 0.0060046068392694
   End of epoch 60; saving model... 

Epoch 61 of 2000
   Iteration 1 of 100, loss = 0.011057569645345211   Iteration 2 of 100, loss = 0.007354672299697995   Iteration 3 of 100, loss = 0.008890303938339153   Iteration 4 of 100, loss = 0.007970888051204383   Iteration 5 of 100, loss = 0.008842795249074697   Iteration 6 of 100, loss = 0.008038171799853444   Iteration 7 of 100, loss = 0.007405016704329422   Iteration 8 of 100, loss = 0.0072993659996427596   Iteration 9 of 100, loss = 0.007855518565823635   Iteration 10 of 100, loss = 0.007488491851836443   Iteration 11 of 100, loss = 0.007225206164135175   Iteration 12 of 100, loss = 0.007443780273509522   Iteration 13 of 100, loss = 0.007604020396963908   Iteration 14 of 100, loss = 0.00782973036569144   Iteration 15 of 100, loss = 0.0077831871497134365   Iteration 16 of 100, loss = 0.0075197200931143016   Iteration 17 of 100, loss = 0.007600434864049449   Iteration 18 of 100, loss = 0.00789175526652899   Iteration 19 of 100, loss = 0.00800268839750635   Iteration 20 of 100, loss = 0.00800324857700616   Iteration 21 of 100, loss = 0.00808680671755047   Iteration 22 of 100, loss = 0.007893018149347468   Iteration 23 of 100, loss = 0.007815149511494066   Iteration 24 of 100, loss = 0.0077498518900635345   Iteration 25 of 100, loss = 0.007557260906323791   Iteration 26 of 100, loss = 0.007517827737431686   Iteration 27 of 100, loss = 0.00734452367760241   Iteration 28 of 100, loss = 0.007593258940947375   Iteration 29 of 100, loss = 0.007512801912902245   Iteration 30 of 100, loss = 0.007507210217105846   Iteration 31 of 100, loss = 0.007530088919485288   Iteration 32 of 100, loss = 0.007610821245179977   Iteration 33 of 100, loss = 0.00759049189615656   Iteration 34 of 100, loss = 0.007570663336938357   Iteration 35 of 100, loss = 0.007590360094660095   Iteration 36 of 100, loss = 0.007493318453068948   Iteration 37 of 100, loss = 0.007516083288686098   Iteration 38 of 100, loss = 0.00750169134086096   Iteration 39 of 100, loss = 0.007498892424150537   Iteration 40 of 100, loss = 0.007430182333337143   Iteration 41 of 100, loss = 0.007436814462402608   Iteration 42 of 100, loss = 0.007563446931141827   Iteration 43 of 100, loss = 0.007564510202555116   Iteration 44 of 100, loss = 0.0075275449410334904   Iteration 45 of 100, loss = 0.007534257400160034   Iteration 46 of 100, loss = 0.0074891549707187905   Iteration 47 of 100, loss = 0.007419046435624044   Iteration 48 of 100, loss = 0.007451966215739958   Iteration 49 of 100, loss = 0.007410686534392286   Iteration 50 of 100, loss = 0.007364580095745623   Iteration 51 of 100, loss = 0.007436357443129607   Iteration 52 of 100, loss = 0.007495799912318874   Iteration 53 of 100, loss = 0.00740990097160047   Iteration 54 of 100, loss = 0.007513084690327998   Iteration 55 of 100, loss = 0.0074676657010885805   Iteration 56 of 100, loss = 0.007391381692806525   Iteration 57 of 100, loss = 0.007391274277643676   Iteration 58 of 100, loss = 0.007422878077767533   Iteration 59 of 100, loss = 0.007430956675276413   Iteration 60 of 100, loss = 0.007399521069601178   Iteration 61 of 100, loss = 0.0073444150601986976   Iteration 62 of 100, loss = 0.007342182625565798   Iteration 63 of 100, loss = 0.007271815039631393   Iteration 64 of 100, loss = 0.007243678752274718   Iteration 65 of 100, loss = 0.007239401741669729   Iteration 66 of 100, loss = 0.007176373295034423   Iteration 67 of 100, loss = 0.007136559600371923   Iteration 68 of 100, loss = 0.007109478629632469   Iteration 69 of 100, loss = 0.007038745145056991   Iteration 70 of 100, loss = 0.007047851290553808   Iteration 71 of 100, loss = 0.007028449129995326   Iteration 72 of 100, loss = 0.00696726911701262   Iteration 73 of 100, loss = 0.006908147672369872   Iteration 74 of 100, loss = 0.006928114220499992   Iteration 75 of 100, loss = 0.006989375340441863   Iteration 76 of 100, loss = 0.006977175111196151   Iteration 77 of 100, loss = 0.0069368336948433095   Iteration 78 of 100, loss = 0.006923897093376861   Iteration 79 of 100, loss = 0.006950884818724251   Iteration 80 of 100, loss = 0.006921397228143178   Iteration 81 of 100, loss = 0.006886618576920879   Iteration 82 of 100, loss = 0.006850656647257871   Iteration 83 of 100, loss = 0.006864160167457289   Iteration 84 of 100, loss = 0.006868293361982242   Iteration 85 of 100, loss = 0.00686762158978073   Iteration 86 of 100, loss = 0.006894824899148283